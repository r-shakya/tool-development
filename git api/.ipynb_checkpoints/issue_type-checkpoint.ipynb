{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "username=\"tensorflow\"\n",
    "repo=\"tensorflow\"\n",
    "url=f\"https://api.github.com/repos/{username}/{repo}/issues\"\n",
    "params = {\n",
    "    \"state\": \"open\",\n",
    "    \"per_page\": \"100\",\n",
    "}\n",
    "headers = {}\n",
    "response = requests.get(url,headers=headers, params=params)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': \"API rate limit exceeded for 157.34.225.80. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", 'documentation_url': 'https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting'}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "issues_list=response.json()\n",
    "print(len(issues_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_issue=issues_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://api.github.com/repos/tensorflow/tensorflow/issues/47310', 'repository_url': 'https://api.github.com/repos/tensorflow/tensorflow', 'labels_url': 'https://api.github.com/repos/tensorflow/tensorflow/issues/47310/labels{/name}', 'comments_url': 'https://api.github.com/repos/tensorflow/tensorflow/issues/47310/comments', 'events_url': 'https://api.github.com/repos/tensorflow/tensorflow/issues/47310/events', 'html_url': 'https://github.com/tensorflow/tensorflow/pull/47310', 'id': 813433053, 'node_id': 'MDExOlB1bGxSZXF1ZXN0NTc3NTgyMTE0', 'number': 47310, 'title': 'Update train.py', 'user': {'login': 'amahendrakar', 'id': 57165142, 'node_id': 'MDQ6VXNlcjU3MTY1MTQy', 'avatar_url': 'https://avatars.githubusercontent.com/u/57165142?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/amahendrakar', 'html_url': 'https://github.com/amahendrakar', 'followers_url': 'https://api.github.com/users/amahendrakar/followers', 'following_url': 'https://api.github.com/users/amahendrakar/following{/other_user}', 'gists_url': 'https://api.github.com/users/amahendrakar/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/amahendrakar/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/amahendrakar/subscriptions', 'organizations_url': 'https://api.github.com/users/amahendrakar/orgs', 'repos_url': 'https://api.github.com/users/amahendrakar/repos', 'events_url': 'https://api.github.com/users/amahendrakar/events{/privacy}', 'received_events_url': 'https://api.github.com/users/amahendrakar/received_events', 'type': 'User', 'site_admin': False}, 'labels': [{'id': 300136587, 'node_id': 'MDU6TGFiZWwzMDAxMzY1ODc=', 'url': 'https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes', 'name': 'cla: yes', 'color': '009800', 'default': False, 'description': None}, {'id': 1169364259, 'node_id': 'MDU6TGFiZWwxMTY5MzY0MjU5', 'url': 'https://api.github.com/repos/tensorflow/tensorflow/labels/size:XS', 'name': 'size:XS', 'color': 'adafea', 'default': False, 'description': 'CL Change Size: Extra Small'}, {'id': 284443156, 'node_id': 'MDU6TGFiZWwyODQ0NDMxNTY=', 'url': 'https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs-bug', 'name': 'type:docs-bug', 'color': '159b2e', 'default': False, 'description': 'Document issues'}], 'state': 'open', 'locked': False, 'assignee': {'login': 'gbaned', 'id': 48215717, 'node_id': 'MDQ6VXNlcjQ4MjE1NzE3', 'avatar_url': 'https://avatars.githubusercontent.com/u/48215717?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/gbaned', 'html_url': 'https://github.com/gbaned', 'followers_url': 'https://api.github.com/users/gbaned/followers', 'following_url': 'https://api.github.com/users/gbaned/following{/other_user}', 'gists_url': 'https://api.github.com/users/gbaned/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/gbaned/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/gbaned/subscriptions', 'organizations_url': 'https://api.github.com/users/gbaned/orgs', 'repos_url': 'https://api.github.com/users/gbaned/repos', 'events_url': 'https://api.github.com/users/gbaned/events{/privacy}', 'received_events_url': 'https://api.github.com/users/gbaned/received_events', 'type': 'User', 'site_admin': False}, 'assignees': [{'login': 'gbaned', 'id': 48215717, 'node_id': 'MDQ6VXNlcjQ4MjE1NzE3', 'avatar_url': 'https://avatars.githubusercontent.com/u/48215717?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/gbaned', 'html_url': 'https://github.com/gbaned', 'followers_url': 'https://api.github.com/users/gbaned/followers', 'following_url': 'https://api.github.com/users/gbaned/following{/other_user}', 'gists_url': 'https://api.github.com/users/gbaned/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/gbaned/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/gbaned/subscriptions', 'organizations_url': 'https://api.github.com/users/gbaned/orgs', 'repos_url': 'https://api.github.com/users/gbaned/repos', 'events_url': 'https://api.github.com/users/gbaned/events{/privacy}', 'received_events_url': 'https://api.github.com/users/gbaned/received_events', 'type': 'User', 'site_admin': False}], 'milestone': None, 'comments': 0, 'created_at': '2021-02-22T11:55:52Z', 'updated_at': '2021-02-22T12:05:46Z', 'closed_at': None, 'author_association': 'CONTRIBUTOR', 'active_lock_reason': None, 'pull_request': {'url': 'https://api.github.com/repos/tensorflow/tensorflow/pulls/47310', 'html_url': 'https://github.com/tensorflow/tensorflow/pull/47310', 'diff_url': 'https://github.com/tensorflow/tensorflow/pull/47310.diff', 'patch_url': 'https://github.com/tensorflow/tensorflow/pull/47310.patch'}, 'body': 'Updated audio recognition tutorial link.\\r\\n\\r\\nFixes issue [#47305](https://github.com/tensorflow/tensorflow/issues/47305)', 'performed_via_github_app': None}\n"
     ]
    }
   ],
   "source": [
    "print(first_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"import tensorflow\" configures Python logging if tensorboard is not installed\n"
     ]
    }
   ],
   "source": [
    "print(first_issue[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 473172988, 'node_id': 'MDU6TGFiZWw0NzMxNzI5ODg=', 'url': 'https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug', 'name': 'type:bug', 'color': '159b2e', 'default': False, 'description': 'Bug'}]\n"
     ]
    }
   ],
   "source": [
    "print(first_issue[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 473172988, 'node_id': 'MDU6TGFiZWw0NzMxNzI5ODg=', 'url': 'https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug', 'name': 'type:bug', 'color': '159b2e', 'default': False, 'description': 'Bug'}]\n"
     ]
    }
   ],
   "source": [
    "labels = first_issue[\"labels\"]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:bug\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels)):\n",
    "    label=labels[i]\n",
    "    label_name=label[\"name\"]\n",
    "    print(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"import tensorflow\" configures Python logging if tensorboard is not installed\n",
      "tf-nightly-gpu builds from February are crashing on 'tf.keras model.fit()' for Nvidia RTX 3090; January builds performance is slower than 2080ti on : 2Layer Bidirectional LSTM + 3 Dense Layers\n",
      "Addition of TanhExp activation function - issue #45929\n",
      "TFLM: Reduce memory usage for some types\n",
      "Large overhead when py_function returns tuple of lists\n",
      "Tensorflow WARNING: tensorflow:Gradients do not exist for variables\n",
      "Flatbuffers Checksum Issue Building With Make\n",
      "RuntimeError: Mixing different tf.distribute.Strategy objects while using tf.distribute.MirroredStrategy()\n",
      "Correct range of input values for MobileNet\n",
      "Suspected duplicate code in resize_bilinear_op.cc\n",
      "Problem with TensorFlow model example with custom Sin operator\n",
      "minimize total loss without step loss\n",
      "unable to train model by using TPU(free TPU)\n",
      "Error \"failed to connect to all addresses\" when iterating dataset on TPU with Colab or Kaggle\n",
      "issue with tf.data.experimental.rejection_resample method\n",
      "TF-TRT: batch dimension is failing in FasterRCNN\n",
      "how to set C++ standard version for tensenflow as another bazel project dependency\n",
      "Batch Normalization fails as kernel constraint for Conv layers when using mixed precision\n",
      "[_Derived_]RecvAsync is cancelled Error when training with LSTM on tf-gpu \n",
      "Empty Interpreter Input/Output Buffer Pointers\n",
      "Tensorflow Addons connected components not working properly\n",
      "Keras model saving erroring: TypeError: get_config() missing 1 required positional argument: 'self'\n",
      "Lr workaround for wrapped  optimizers\n",
      "custom op on gpu/dsp\n",
      "Quantize for pooling op\n",
      "Modify Transpose kernel to work in TFLu\n",
      "\"ValueError: No gradients provided \" error in TF v2.4.1, works fine on v2.3.1\n",
      "fix erroneous assign in Env::StartTransaction()\n",
      "First step towards prototyping v2 of TFLM integration with external IDEs.\n",
      "AttributeError: module 'tensorflow' has no attribute 'Session' with tensorflow 2.4.1\n",
      "tensorflow-gpu 2.2.0 doesn't recognize Nvidia MX130 GPU\n",
      "add MNIST training to `mnist_grad_test`\n",
      "Make the output for model summary wrap\n",
      "Correctly close file descriptors when loading saved models\n",
      "Building TensorFlow Lite - macos_arm64 support using cmake\n",
      "Distributed computing, extreme distribution latency \n",
      "Remove unnecessary model parsing from keras.model.load_model\n",
      "Add link to presentation, minor fixes\n",
      "Model.predict accepts tensors of incorrect rank\n",
      "Make libtensorflow_jni target compatible with Tensorflow Text\n",
      "Failed to run models with libtensorflow_jni and tensorflow text together\n",
      "Cannot import name 'boosted_trees_test' from 'tensorflow_estimator.python.estimator.canned' \n",
      "Simplify Huber Loss implementation\n",
      "Normalization layer supresses ValueError when model is called with bad input shape\n",
      "Pass for Dialect conversion from Tflite to TF  \n",
      "Disable unroll batch matmul pass\n",
      "SELU activation in TFlite micro\n",
      "Add thread name in the error message when thread creation fails.\n",
      "NotFoundError: It shows libcudart.so.8.0, but I am using CUDA 10.0.\n",
      "Support all fp types in GPU SparseTensorDenseMatMul\n",
      "Remove unit8 support from kernels prior to adding new optimized implementations\n",
      "Changes to MklConvFwdPrimitiveFactory to support Arm Compute Library backend\n",
      "TFLM project generation support (version 2)\n",
      "Add axis argument\n",
      "No algorithm worked on Ubuntu 20.04 LTS with CUDA 11.0 and Tensorflow 2.4.1\n",
      "Add support for probability/thresholds in meanIoU\n",
      "Different outputs from GradientTape and CropAndResizeGradImage \n",
      "How to run a model training command in redhat linux slurm file?\n",
      "Layer .input_shape and .output_shape wrongly claim \"The layer has never been called\"\n",
      "Tensorflow and flask has an error loading model.\n",
      "Compile TensorFlow Lite for iOS Simulator on Apple Silicon\n",
      "Unable to build TFLite for Microcontrollers on Mac OS \n",
      "[XLA:GPU] Updated hlo_to_llvm_ir to also emit PTX and re-enable tests using it.\n",
      "Add missing closing backtick\n",
      "BestExporter exports worse model when training tasks restart.\n",
      "EagerTensor implements `__len__` but not `len()`.\n",
      "Did not open image after detecting object using tensorflow2\n",
      "tf.errors.UnknownError should include __cause__\n",
      "TypeError: tensor_equals() missing 1 required positional argument: 'other'\n",
      "Libcudnn Major Version Variable attached\n",
      "[XLA:GPU] Build failure\n",
      "Port micro op EXPAND_DIMS for it to pass the tests\n",
      "ModifyGraphWithDelegate(delegate) running very slow (ubuntu with USB accelerator)\n",
      "Generating the descriptors of constant shape\n",
      "Fixed docstring formatting for api_docs\n",
      "tf_upgrade_v2: UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 385: character maps to <undefined>\n",
      "True loss values\n",
      "Tensorflow is ignoring `tf.config.set_soft_device_placement(True)`\n",
      "Add a status badge for Arduino examples\n",
      "metrics values don't match between custom metric function and model.fit callbacks\n",
      "Getting ERROR: Could not find a version that satisfies the requirement tensorflow==2.4.1\n",
      "Any suggestion to use tensorflow feasibly?\n",
      "Ampere bfloat16 support\n",
      "Support tf.IsFinite lowering\n",
      "The comparing with memory by 1080 ti and 3090\n",
      "tflite interpreter on android crashes on a model downloaded from tfhub\n",
      "[Kernel C API] Fix inplacement issue in C API\n",
      "ImportError traceback in VScode\n",
      "fix Windows build errors\n",
      "Custom objects in tf.keras have conflicting interface\n",
      "In-batch-negatives and distributed traning\n",
      "Assert if y_pred and y_true have same shape in categorical_accuracy()\n",
      "Give Grappler hints about function XLA compilation so it can selectively apply compatible optimizations\n",
      "Calling model.test_on_batch after model.evaluate returns corrupted values for the loss and the metrics\n",
      "SparseTensorDenseMatMul adjoint_a takes transpose, not adjoint\n",
      "Slower on a Nvidia 1080TI GPU than on CPU \n",
      "ERROR: Didn't find op for builtin opcode 'ADD' version '1'\n",
      "Adabound feature request \n",
      "memory increasing slowly and largely at the beginning of model.fit() in tf.keras\n",
      "tf.nn.depth_to_space with NCHW argument works in TF 2.3 but fails in TF 2.4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(issues_list)):\n",
    "    issue=issues_list[i]\n",
    "    issue_title=issue[\"title\"]\n",
    "    print(issue_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "issue title -  \"import tensorflow\" configures Python logging if tensorboard is not installed\n",
      "issue body -  **System information**\r\n",
      "\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.7, Python 3.8 from MacPorts, Python venv\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n",
      "- TensorFlow installed from (source or binary): binary wheel `tensorflow-2.4.1-cp38-cp38-macosx_10_11_x86_64.whl` from PyPI (using `python -m pip install tensorflow`) \r\n",
      "- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1\r\n",
      "- Python version: 3.8.8\r\n",
      "- Bazel version (if compiling from source): N/A\r\n",
      "- GCC/Compiler version (if compiling from source): N/A\r\n",
      "- CUDA/cuDNN version:  N/A\r\n",
      "- GPU model and memory: Radeon Pro 560X 4 GB, Intel UHD Graphics 630 1536 MB\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "\r\n",
      "After uninstalling `tensorboard` from the Python virtual environment with `pip uninstall tensorboard`, executing `import tensorflow` at the prompt causes logging to be configured: in particular, a `StreamHandler` handler is added to the root logger.\r\n",
      "\r\n",
      "As a result, in a large Python GUI (PyQt5) application, an `import tensorflow` at application startup time resulted in many log messages unrelated to tensorflow being printed to the console; without importing tensorflow, those log messages weren't visible. (Note that the application had set the level of the root logger to `logging.DEBUG`, and added its own root-level loggers, under the assumption that it would be the only part of the Python environment working with the configuration for the root-level logger.)\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "\r\n",
      "Following usual logging best practices (libraries should only emit log messages but not configure logging; log configuration should be left to the application using the library), `import tensorflow` does not affect the root logger.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "\r\n",
      "Here's an interpreter session demonstrating the issue\r\n",
      "\r\n",
      "```python\r\n",
      "Python 3.8.8 (default, Feb 22 2021, 09:21:28) \r\n",
      "[Clang 12.0.0 (clang-1200.0.32.28)] on darwin\r\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n",
      ">>> import logging\r\n",
      ">>> root_logger = logging.root\r\n",
      ">>> root_logger.handlers\r\n",
      "[]\r\n",
      ">>> import tensorflow\r\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\r\n",
      ">>> root_logger.handlers  # expected an empty list\r\n",
      "[<StreamHandler <stderr> (NOTSET)>]\r\n",
      "```\r\n",
      "\r\n",
      "**Additional information**\r\n",
      "\r\n",
      "This looks like a shallow bug and an easy fix. Here's the troublesome code: https://github.com/tensorflow/tensorflow/blob/c023a829167aa4a233a36479cd338ef9784b6990/tensorflow/compat_template.__init__.py#L43\r\n",
      "\r\n",
      "Diagnosis: because the Python logging system hadn't already been configured at the point of the `import tensorflow` execution, and because `tensorboard` wasn't available,`_logging.warning` was then called as above: that then implicitly configured logging by calling `logging.basicConfig`.\r\n",
      "\r\n",
      "A simple solution would be to set up a logger in the normal way (`logger = logging.getLogger(__name__)`) and use `logger.warning` instead of `logging.warning`; that way, implicit configuration of the logging machinery is avoided.\r\n",
      "\r\n",
      "We were able to work around this problem in our application by making sure that we configured logging (adding a null handler to the root logger) _before_ importing `tensorflow`, so that `logging.basicConfig` was no longer invoked.\r\n",
      "\r\n",
      "Another workaround was to ensure that `tensorboard` was installed, but since we don't generally need the functionality provided by `tensorboard`, our packaging system leaves `tensorboard` out as a explicit dependency of `tensorflow`. If the recommendation is that `tensorboard` should be treated as a required dependency of `tensorflow`, that would be good to know.\n",
      "issue labels - \n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  tf-nightly-gpu builds from February are crashing on 'tf.keras model.fit()' for Nvidia RTX 3090; January builds performance is slower than 2080ti on : 2Layer Bidirectional LSTM + 3 Dense Layers\n",
      "issue body -  **System information**\r\n",
      "OS Windows 10 Pro : 1909 18363.1379\r\n",
      "CUDA TOOLKIT : 11.1\r\n",
      "CUDNN: 8.1.0\r\n",
      "Latest GPU Driver 461.72\r\n",
      "\r\n",
      "GPU : MSI RTX 3090 Gaming X Trio\r\n",
      "CPU i7 3930k 32GB ram\r\n",
      "\r\n",
      "using Anaconda\r\n",
      "python 3.7.9\r\n",
      "tf-nightly-gpu 2.5.0.dev20210114\r\n",
      "tf-nightly 2.5.0.dev20210114\r\n",
      "\r\n",
      "**Describe the problem**\r\n",
      "\r\n",
      "=> The above config allows me to run my code LSTM code in tensor flow (extract below):\r\n",
      "However if i create an environment in Anaconda by cloning the above and pip --upgrade to a tf-nightly build more recent, including todays build\r\n",
      "of 2.5.0.dev20210228 ... when the code reaches tf.model.fit .. it crashes out with no error reporting at all.\r\n",
      "\r\n",
      "The reason why i tried upgrading the tf-nightly build : currently the model training time is about the same as on my RTX 2080ti and sometimes even slower which i thought was down to issues with the tf-nightly january Build and Ampere.\r\n",
      "\r\n",
      "\r\n",
      "**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n",
      "The code can be run from CMD conda command prompt or from a terminal in Visual Studio Code and it crashes as soon as the model.fit line is reached.\r\n",
      "\r\n",
      "\r\n",
      "**Any other info / logs**\r\n",
      "code block:\r\n",
      "\r\n",
      "model = tf.keras.models.Sequential([\r\n",
      "#input shape equals term points in curve\r\n",
      "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True),input_shape=(n_days,n_cols)),\r\n",
      "tf.keras.layers.Dropout(0.2),\r\n",
      "\r\n",
      "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n",
      "tf.keras.layers.Dropout(0.2),\r\n",
      "\r\n",
      "tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer),\r\n",
      "tf.keras.layers.BatchNormalization(),\r\n",
      "tf.keras.layers.Dropout(0.2),\r\n",
      "    \r\n",
      "tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer, bias_initializer=output_bias),\r\n",
      "tf.keras.layers.BatchNormalization(),\r\n",
      "tf.keras.layers.Dropout(0.2),\r\n",
      "\r\n",
      "tf.keras.layers.Dense(t_cols, activation='sigmoid', bias_initializer=output_bias)])\r\n",
      "#list of keras metrics to compute in model\r\n",
      "METRICS = [\r\n",
      "keras.metrics.BinaryAccuracy(name='binary_accuracy'),\r\n",
      "keras.metrics.Precision(name='precision'),\r\n",
      "keras.metrics.Recall(name='recall'),\r\n",
      "keras.metrics.AUC(name='auc'),\r\n",
      "]\r\n",
      "\r\n",
      "model.compile(optimizer=Adam(learning_rate=lng_rate),\r\n",
      "loss='binary_crossentropy',\r\n",
      "metrics=METRICS)\r\n",
      "\r\n",
      "history=model.fit(\r\n",
      "X_train,\r\n",
      "Y_train,\r\n",
      "epochs=training_epochs,\r\n",
      "batch_size=training_batch_size,\r\n",
      "verbose=1,\r\n",
      "class_weight=label_weights[0],\r\n",
      "validation_data=(X_validation,Y_validation))\n",
      "issue labels - \n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Addition of TanhExp activation function - issue #45929\n",
      "issue body -  Addition of TanhExp activation function based on issue #45929 that leads changes to tensorflow/python/keras/activations.py and tensorflow/python/ops/nn_impl.py\n",
      "issue labels - \n",
      "cla: yes\n",
      "size:M\n",
      "\n",
      "\n",
      "issue title -  TFLM: Reduce memory usage for some types\n",
      "issue body -  Reducing memory usage for non-int<8> types in conv and depthwise_conv\r\n",
      "kernels.\r\n",
      "\r\n",
      "This is a fix for: https://github.com/tensorflow/tensorflow/issues/42883\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:micro\n",
      "size:M\n",
      "\n",
      "\n",
      "issue title -  Large overhead when py_function returns tuple of lists\n",
      "issue body -  <em>Please make sure that this is an issue related to performance of TensorFlow.\r\n",
      "As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:performance_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n",
      "- TensorFlow installed from (source or binary): binary\r\n",
      "- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1\r\n",
      "- Python version: 3.8.8 (verified in 3.6.9 as well)\r\n",
      "- Bazel version (if compiling from source):\r\n",
      "- GCC/Compiler version (if compiling from source):\r\n",
      "- CUDA/cuDNN version: N/A\r\n",
      "- GPU model and memory: N/A\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "Given the code in the gist https://gist.github.com/kretes/02dc479ab7a63a8b5a559c5e7df89598 - I see that the version of the `py_function` that return a tuple of lists with data is introducing some large overhead on top of the actual operation. It takes ~10 seconds to finish the iteration in this code, while the other two versions (returning just tuple, or returning tuple of ndarrays) is done within ~2 secs.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "There should be no difference between returning a tuple with data, or wrapping them up with one more nesting level.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "https://gist.github.com/kretes/02dc479ab7a63a8b5a559c5e7df89598 - code and logs from run on my side. I verified this in multiple installations, the recent one in jupyter/tensorflow docker image\n",
      "issue labels - \n",
      "type:performance\n",
      "\n",
      "\n",
      "issue title -  Tensorflow WARNING: tensorflow:Gradients do not exist for variables\n",
      "issue body -  I am trying to implement the VQ-VAE using TensorFlow 2.X. \r\n",
      "I borrow the code of the VQ-VAE training from [this github][1] which is written in TF 2x. and I'm working on merging the Keras code of PixelCNN training & sampling from [this tutorial][2] to the VQ-VAE TF 2.X code.\r\n",
      "\r\n",
      "\r\n",
      "For the training of VQ-VAE, I think it was fine. But when I want to get the quantization vectors from the trained VQ-VAE and use the quantization vectors to further train the PixelCNN. I always get a warning:\r\n",
      "\r\n",
      "    \r\n",
      "\r\n",
      "> WARNING:tensorflow:Gradients do not exist for variables\r\n",
      "> ['conv2d_block/batch_normalization/gamma:0',\r\n",
      "> 'conv2d_block/batch_normalization/beta:0',\r\n",
      "> 'conv2d_block/conv2d/kernel:0', 'conv2d_block/conv2d/bias:0',\r\n",
      "> 'conv2d_block_1/batch_normalization_1/gamma:0',\r\n",
      "> 'conv2d_block_1/batch_normalization_1/beta:0',\r\n",
      "> 'conv2d_block_1/conv2d_1/kernel:0', 'conv2d_block_1/conv2d_1/bias:0',\r\n",
      "> 'conv2d_block_2/batch_normalization_2/gamma:0',\r\n",
      "> 'conv2d_block_2/batch_normalization_2/beta:0',\r\n",
      "> 'conv2d_block_2/conv2d_2/kernel:0', 'conv2d_block_2/conv2d_2/bias:0',\r\n",
      "> 'conv2d_block_3/batch_normalization_3/gamma:0',\r\n",
      "> 'conv2d_block_3/batch_normalization_3/beta:0',\r\n",
      "> 'conv2d_block_3/conv2d_3/kernel:0', 'conv2d_block_3/conv2d_3/bias:0',\r\n",
      "> 'conv2d_block_4/batch_normalization_4/gamma:0',\r\n",
      "> 'conv2d_block_4/batch_normalization_4/beta:0',\r\n",
      "> 'conv2d_block_4/conv2d_4/kernel:0', 'conv2d_block_4/conv2d_4/bias:0',\r\n",
      "> 'conv2d_block_5/batch_normalization_5/gamma:0',\r\n",
      "> 'conv2d_block_5/batch_normalization_5/beta:0',\r\n",
      "> 'conv2d_block_5/conv2d_5/kernel:0', 'conv2d_block_5/conv2d_5/bias:0',\r\n",
      "> 'conv2d_block_6/batch_normalization_6/gamma:0',\r\n",
      "> 'conv2d_block_6/batch_normalization_6/beta:0',\r\n",
      "> 'conv2d_block_6/conv2d_6/kernel:0', 'conv2d_block_6/conv2d_6/bias:0',\r\n",
      "> 'conv2d_block_7/batch_normalization_7/gamma:0',\r\n",
      "> 'conv2d_block_7/batch_normalization_7/beta:0',\r\n",
      "> 'conv2d_block_7/conv2d_7/kernel:0', 'conv2d_block_7/conv2d_7/bias:0',\r\n",
      "> 'conv2d_block_8/batch_normalization_8/gamma:0',\r\n",
      "> 'conv2d_block_8/batch_normalization_8/beta:0',\r\n",
      "> 'conv2d_block_8/conv2d_8/kernel:0', 'conv2d_block_8/conv2d_8/bias:0',\r\n",
      "> 'conv2d_block_9/batch_normalization_9/gamma:0',\r\n",
      "> 'conv2d_block_9/batch_normalization_9/beta:0',\r\n",
      "> 'conv2d_block_9/conv2d_9/kernel:0', 'conv2d_block_9/conv2d_9/bias:0',\r\n",
      "> 'conv2d_block_10/instance_normalization/scale:0',\r\n",
      "> 'conv2d_block_10/instance_normalization/offset:0',\r\n",
      "> 'conv2d_block_10/conv2d_10/kernel:0',\r\n",
      "> 'conv2d_block_10/conv2d_10/bias:0',\r\n",
      "> 'conv2d_block_11/instance_normalization_1/scale:0',\r\n",
      "> 'conv2d_block_11/instance_normalization_1/offset:0',\r\n",
      "> 'conv2d_block_11/conv2d_11/kernel:0',\r\n",
      "> 'conv2d_block_11/conv2d_11/bias:0',\r\n",
      "> 'conv2d_block_12/instance_normalization_2/scale:0',\r\n",
      "> 'conv2d_block_12/instance_normalization_2/offset:0',\r\n",
      "> 'conv2d_block_12/conv2d_12/kernel:0',\r\n",
      "> 'conv2d_block_12/conv2d_12/bias:0',\r\n",
      "> 'conv2d_block_13/instance_normalization_3/scale:0',\r\n",
      "> 'conv2d_block_13/instance_normalization_3/offset:0',\r\n",
      "> 'conv2d_block_13/conv2d_13/kernel:0',\r\n",
      "> 'conv2d_block_13/conv2d_13/bias:0',\r\n",
      "> 'conv2d_block_14/instance_normalization_4/scale:0',\r\n",
      "> 'conv2d_block_14/instance_normalization_4/offset:0',\r\n",
      "> 'conv2d_block_14/conv2d_14/kernel:0',\r\n",
      "> 'conv2d_block_14/conv2d_14/bias:0',\r\n",
      "> 'conv2d_block_15/instance_normalization_5/scale:0',\r\n",
      "> 'conv2d_block_15/instance_normalization_5/offset:0',\r\n",
      "> 'conv2d_block_15/conv2d_15/kernel:0',\r\n",
      "> 'conv2d_block_15/conv2d_15/bias:0',\r\n",
      "> 'conv2d_block_16/instance_normalization_6/scale:0',\r\n",
      "> 'conv2d_block_16/instance_normalization_6/offset:0',\r\n",
      "> 'conv2d_block_16/conv2d_16/kernel:0',\r\n",
      "> 'conv2d_block_16/conv2d_16/bias:0',\r\n",
      "> 'conv2d_block_17/instance_normalization_7/scale:0',\r\n",
      "> 'conv2d_block_17/instance_normalization_7/offset:0',\r\n",
      "> 'conv2d_block_17/conv2d_17/kernel:0',\r\n",
      "> 'conv2d_block_17/conv2d_17/bias:0',\r\n",
      "> 'conv2d_block_18/instance_normalization_8/scale:0',\r\n",
      "> 'conv2d_block_18/instance_normalization_8/offset:0',\r\n",
      "> 'conv2d_block_18/conv2d_18/kernel:0',\r\n",
      "> 'conv2d_block_18/conv2d_18/bias:0',\r\n",
      "> 'conv2d_block_19/conv2d_19/kernel:0',\r\n",
      "> 'conv2d_block_19/conv2d_19/bias:0', 'conv2d_20/kernel:0',\r\n",
      "> 'conv2d_20/bias:0', 'v_masked_conv_1/W_v:0', 'h_masked_conv_1/W_h:0',\r\n",
      "> 'v_masked_conv_2/W_v:0', 'h_masked_conv_2/W_h:0',\r\n",
      "> 'v_masked_conv_3/W_v:0', 'h_masked_conv_3/W_h:0',\r\n",
      "> 'v_masked_conv_4/W_v:0', 'h_masked_conv_4/W_h:0',\r\n",
      "> 'v_masked_conv_5/W_v:0', 'h_masked_conv_5/W_h:0',\r\n",
      "> 'v_masked_conv_6/W_v:0', 'h_masked_conv_6/W_h:0',\r\n",
      "> 'v_masked_conv_7/W_v:0', 'h_masked_conv_7/W_h:0',\r\n",
      "> 'v_masked_conv_8/W_v:0', 'h_masked_conv_8/W_h:0',\r\n",
      "> 'v_masked_conv_9/W_v:0', 'h_masked_conv_9/W_h:0',\r\n",
      "> 'v_masked_conv_10/W_v:0', 'h_masked_conv_10/W_h:0',\r\n",
      "> 'v_masked_conv_11/W_v:0', 'h_masked_conv_11/W_h:0',\r\n",
      "> 'v_masked_conv_12/W_v:0', 'h_masked_conv_12/W_h:0'] when minimizing\r\n",
      "> the loss.\r\n",
      "\r\n",
      "  The following is what I have for my codes.\r\n",
      "\r\n",
      "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()  \r\n",
      "        x_train = (x_train[:200]/ 255.).astype(\"float32\")\r\n",
      "        x_test = (x_test[:200] / 255.).astype(\"float32\")\r\n",
      "        \r\n",
      "        #training vqvae \r\n",
      "        model = Autoencoder(config)\r\n",
      "        model.fit(x_train, config)\r\n",
      "        _, vq_return = model.call(x_train, training=False)\r\n",
      "        quantize = vq_return['quantize']\r\n",
      "\r\n",
      "where the `fit` function is I newly defined for the Autoencoder model (actually it should be the VQ-VAE mode), the rests are the same as what it has in [the git][3]. \r\n",
      "\r\n",
      "For the PixelCNN part, I modified the above Keras tutorial to have Lambda layer as classes:\r\n",
      "\r\n",
      "    class SamplingLayer(tf.keras.layers.Layer):\r\n",
      "        def __init__(self, model, **kwargs):  \r\n",
      "            super(SamplingLayer, self).__init__()\r\n",
      "            self.model = model\r\n",
      "        def call(self, encoding_indices, training=False):\r\n",
      "            vq = self.model.vq\r\n",
      "            return vq.quantize(encoding_indices)\r\n",
      "    \r\n",
      "    class CodesSampler(tf.keras.Model):\r\n",
      "        def __init__(self, **kwargs):\r\n",
      "            super(CodesSampler, self).__init__()\r\n",
      "    \r\n",
      "        def call(self, model, size, training=False):\r\n",
      "            sampling_layer = SamplingLayer(model)\r\n",
      "            indices = tf.keras.layers.Input(shape=(size, size), name='codes_sampler_inputs', dtype='int32')\r\n",
      "            z_q = sampling_layer(indices)\r\n",
      "            codes_sampler = tf.keras.Model(inputs=indices, outputs=z_q, name=\"codes_sampler\")\r\n",
      "            return codes_sampler\r\n",
      "and the rest of Pixel CNN model is basically the same as the tutorial \r\n",
      "\r\n",
      "    '''Learning a prior over the latent space'''\r\n",
      "    class GateLayer(tf.keras.layers.Layer):\r\n",
      "        def __init__(self, **kwargs):\r\n",
      "            super(GateLayer, self).__init__()\r\n",
      "            # self.name = name\r\n",
      "        def call(self, inputs):\r\n",
      "            \"\"\"Gated activations\"\"\"\r\n",
      "            x, y = tf.split(inputs, 2, axis=-1)\r\n",
      "            return Kb.tanh(x) * Kb.sigmoid(y)\r\n",
      "    \r\n",
      "    \r\n",
      "    class MaskedConv2D(tf.keras.layers.Layer):\r\n",
      "        \"\"\"Masked convolution\"\"\"\r\n",
      "        def __init__(self, kernel_size, out_dim, direction, mode, **kwargs):\r\n",
      "            self.direction = direction     # Horizontal or vertical\r\n",
      "            self.mode = mode               # Mask type \"a\" or \"b\"\r\n",
      "            self.kernel_size = kernel_size\r\n",
      "            self.out_dim = out_dim\r\n",
      "            super(MaskedConv2D, self).__init__(**kwargs)\r\n",
      "        \r\n",
      "        def build(self, input_shape):   \r\n",
      "            filter_mid_y = self.kernel_size[0] // 2\r\n",
      "            filter_mid_x = self.kernel_size[1] // 2        \r\n",
      "            in_dim = int(input_shape[-1])\r\n",
      "            w_shape = [self.kernel_size[0], self.kernel_size[1], in_dim, self.out_dim]\r\n",
      "            mask_filter = np.ones(w_shape, dtype=np.float32)\r\n",
      "            # Build the mask\r\n",
      "            if self.direction == \"h\":\r\n",
      "                mask_filter[filter_mid_y + 1:, :, :, :] = 0.\r\n",
      "                mask_filter[filter_mid_y, filter_mid_x + 1:, :, :] = 0.\r\n",
      "            elif self.direction == \"v\":\r\n",
      "                if self.mode == 'a':\r\n",
      "                    mask_filter[filter_mid_y:, :, :, :] = 0.\r\n",
      "                elif self.mode == 'b':\r\n",
      "                    mask_filter[filter_mid_y+1:, :, :, :] = 0.0\r\n",
      "            if self.mode == 'a':\r\n",
      "                mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.0\r\n",
      "            # Create convolution layer parameters with masked kernel\r\n",
      "            self.W = mask_filter * self.add_weight(\"W_{}\".format(self.direction), w_shape, trainable=True)\r\n",
      "            self.b = self.add_weight(\"v_b\", [self.out_dim,], trainable=True)\r\n",
      "        \r\n",
      "        def call(self, inputs):\r\n",
      "            return tf.keras.backend.conv2d(inputs, self.W, strides=(1, 1)) + self.b\r\n",
      "    \r\n",
      "        \r\n",
      "    def gated_masked_conv2d(v_stack_in, h_stack_in, out_dim, kernel, mask='b', residual=True, i=0):\r\n",
      "        \"\"\"Basic Gated-PixelCNN block. \r\n",
      "           This is an improvement over PixelRNN to avoid \"blind spots\", i.e. pixels missingt from the\r\n",
      "           field of view. It works by having two parallel stacks, for the vertical and horizontal direction, \r\n",
      "           each being masked  to only see the appropriate context pixels.\r\n",
      "        \"\"\"\r\n",
      "        kernel_size = (kernel // 2 + 1, kernel)\r\n",
      "        padding = (kernel // 2, kernel // 2)\r\n",
      "        v_gate = GateLayer(name=\"v_gate_{}\".format(i))\r\n",
      "        v_stack = tf.keras.layers.ZeroPadding2D(padding=padding, name=\"v_pad_{}\".format(i))(v_stack_in)\r\n",
      "        v_stack = MaskedConv2D(kernel_size, out_dim * 2, \"v\", mask, name=\"v_masked_conv_{}\".format(i))(v_stack)\r\n",
      "        v_stack = v_stack[:, :int(v_stack_in.get_shape()[-3]), :, :]\r\n",
      "        v_stack_out = v_gate(v_stack)\r\n",
      "        \r\n",
      "        kernel_size = (1, kernel // 2 + 1)\r\n",
      "        padding = (0, kernel // 2)\r\n",
      "        h_gate = GateLayer(name=\"h_gate_{}\".format(i))\r\n",
      "        h_stack = tf.keras.layers.ZeroPadding2D(padding=padding, name=\"h_pad_{}\".format(i))(h_stack_in)\r\n",
      "        h_stack = MaskedConv2D(kernel_size, out_dim * 2, \"h\", mask, name=\"h_masked_conv_{}\".format(i))(h_stack)\r\n",
      "        h_stack = h_stack[:, :, :int(h_stack_in.get_shape()[-2]), :]\r\n",
      "        h_stack_1 = tf.keras.layers.Conv2D(filters=out_dim * 2, kernel_size=1, strides=(1, 1), name=\"v_to_h_{}\".format(i))(v_stack)\r\n",
      "        h_stack_out = h_gate(h_stack + h_stack_1)\r\n",
      "        \r\n",
      "        h_stack_out =  tf.keras.layers.Conv2D(filters=out_dim, kernel_size=1, strides=(1, 1), name=\"res_conv_{}\".format(i))(h_stack_out)\r\n",
      "        if residual:\r\n",
      "            h_stack_out += h_stack_in\r\n",
      "        return v_stack_out, h_stack_out\r\n",
      "    \r\n",
      "    \r\n",
      "    def build_pixelcnn(codes_sampler, k, size, num_layers, num_feature_maps=32):\r\n",
      "        pixelcnn_prior_inputs = tf.keras.layers.Input(shape=(size, size), name='pixelcnn_prior_inputs', dtype=tf.int32)\r\n",
      "        z_q = codes_sampler(pixelcnn_prior_inputs, size) # maps indices (z_train in the implementation) to the actual codebook\r\n",
      "        \r\n",
      "        v_stack_in, h_stack_in = z_q, z_q\r\n",
      "        for i in range(num_layers):\r\n",
      "            mask = 'b' if i > 0 else 'a'\r\n",
      "            kernel_size = 3 if i > 0 else 7\r\n",
      "            residual = True if i > 0 else False\r\n",
      "            v_stack_in, h_stack_in = gated_masked_conv2d(v_stack_in, h_stack_in, num_feature_maps,\r\n",
      "                                                         kernel=kernel_size, residual=residual, i=i + 1)\r\n",
      "    \r\n",
      "        fc1 = tf.keras.layers.Conv2D(filters=num_feature_maps, kernel_size=1, name=\"fc1\")(h_stack_in)\r\n",
      "        fc2 = tf.keras.layers.Conv2D(filters=k, kernel_size=1, name=\"fc2\")(fc1) \r\n",
      "        # outputs logits for probabilities of codebook indices for each cell\r\n",
      "    \r\n",
      "        pixelcnn_prior = tf.keras.Model(inputs=pixelcnn_prior_inputs, outputs=fc2, name='pixelcnn-prior')\r\n",
      "    \r\n",
      "        # Distribution to sample from the pixelcnn\r\n",
      "        dist = tfp.distributions.Categorical(logits=fc2)\r\n",
      "        sampled = dist.sample()\r\n",
      "        prior_sampler = tf.keras.Model(inputs=pixelcnn_prior_inputs, outputs=sampled, name='pixelcnn-prior-sampler')\r\n",
      "        return pixelcnn_prior, prior_sampler\r\n",
      "    \r\n",
      "    \r\n",
      "    ##%%time\r\n",
      "    # Train the PixelCNN and monitor prediction accuracy\r\n",
      "    def accuracy(y_true, y_pred):\r\n",
      "        size = int(y_pred.get_shape()[-2])\r\n",
      "        k = int(y_pred.get_shape()[-1])\r\n",
      "        y_true = tf.reshape(y_true, (-1, size * size))\r\n",
      "        y_pred = tf.reshape(y_pred, (-1, size * size, k))\r\n",
      "        return Kb.cast(Kb.equal(y_true, Kb.cast(Kb.argmax(y_pred, axis=-1), Kb.floatx())), Kb.floatx())\r\n",
      "\r\n",
      "The last is training PixelCNN using the quantized vectors:\r\n",
      "\r\n",
      "    z_train = model.call(x_train, training=False)[1]['encoding_indices']\r\n",
      "    pixelcnn_prior, prior_sampler = build_pixelcnn(codes_sampler, NUM_LATENT_K, SIZE, \r\n",
      "                                                   PIXELCNN_NUM_BLOCKS, PIXELCNN_NUM_FEATURE_MAPS)\r\n",
      "    pixelcnn_prior.summary()\r\n",
      "    pixelcnn_prior.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[accuracy],\r\n",
      "                           optimizer=tf.keras.optimizers.Adam(PIXELCNN_LEARNING_RATE))\r\n",
      "    prior_history = pixelcnn_prior.fit(z_train, z_train, epochs=PIXELCNN_NUM_EPOCHS, \r\n",
      "                                       batch_size=PIXELCNN_BATCH_SIZE, verbose=1)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "It's also weird that when I plot the summary tables of the Keras tutorial and my modified TF2.X codes, there are different in: `codes_sampler` and `Non-trainable params: 8,064`.\r\n",
      "\r\n",
      "The top is the summary of the Keras tutorial with most of the common parts omitted:\r\n",
      "\r\n",
      "    Model: \"pixelcnn-prior\"\r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    Layer (type)                    Output Shape         Param #     Connected to                     \r\n",
      "    ==================================================================================================\r\n",
      "    pixelcnn_prior_inputs (InputLay [(None, 8, 8)]       0                                            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    codes_sampler (Model)           (None, 8, 8, 256)    0           pixelcnn_prior_inputs[0][0]      \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_pad_1 (ZeroPadding2D)         (None, 14, 14, 256)  0           codes_sampler[1][0]              \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    h_pad_1 (ZeroPadding2D)         (None, 8, 14, 256)   0           codes_sampler[1][0]              \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_masked_conv_1 (MaskedConv2D)  (None, 11, 8, 64)    458816      v_pad_1[0][0]                    \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    h_masked_conv_1 (MaskedConv2D)  (None, 8, 11, 64)    65600       h_pad_1[0][0]                    \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    tf_op_layer_strided_slice_4 (Te [(None, 8, 8, 64)]   0           v_masked_conv_1[0][0]            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    tf_op_layer_strided_slice_5 (Te [(None, 8, 8, 64)]   0           h_masked_conv_1[0][0]            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_to_h_1 (Conv2D)               (None, 8, 8, 64)     4160        tf_op_layer_strided_slice_4[0][0]\r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    tf_op_layer_add (TensorFlowOpLa [(None, 8, 8, 64)]   0           tf_op_layer_strided_slice_5[0][0]\r\n",
      "                                                                     v_to_h_1[0][0]                   \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    h_gate_1 (Lambda)               (None, 8, 8, 32)     0           tf_op_layer_add[0][0]            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_gate_1 (Lambda)               (None, 8, 8, 32)     0           tf_op_layer_strided_slice_4[0][0]\r\n",
      "\r\n",
      "\r\n",
      "and \r\n",
      "\r\n",
      "    ==================================================================================================\r\n",
      "    Total params: 786,592\r\n",
      "    Trainable params: 786,592\r\n",
      "    Non-trainable params: 0\r\n",
      "\r\n",
      "For my modified TF2.X code, \r\n",
      "\r\n",
      "    Model: \"pixelcnn-prior\"\r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    Layer (type)                    Output Shape         Param #     Connected to                     \r\n",
      "    ==================================================================================================\r\n",
      "    pixelcnn_prior_inputs (InputLay [(None, 4, 4)]       0                                            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    codes_sampler (Functional)      (None, 4, 4, 256)    21824387    pixelcnn_prior_inputs[0][0]      \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_pad_1 (ZeroPadding2D)         (None, 10, 10, 256)  0           codes_sampler[0][0]              \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    h_pad_1 (ZeroPadding2D)         (None, 4, 10, 256)   0           codes_sampler[0][0]              \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_masked_conv_1 (MaskedConv2D)  (None, 7, 4, 64)     458816      v_pad_1[0][0]                    \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    h_masked_conv_1 (MaskedConv2D)  (None, 4, 7, 64)     65600       h_pad_1[0][0]                    \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    tf.__operators__.getitem (Slici (None, 4, 4, 64)     0           v_masked_conv_1[0][0]            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    tf.__operators__.getitem_1 (Sli (None, 4, 4, 64)     0           h_masked_conv_1[0][0]            \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    v_to_h_1 (Conv2D)               (None, 4, 4, 64)     4160        tf.__operators__.getitem[0][0]   \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    tf.__operators__.add (TFOpLambd (None, 4, 4, 64)     0           tf.__operators__.getitem_1[0][0] \r\n",
      "                                                                     v_to_h_1[0][0]                   \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    gate_layer_1 (GateLayer)        (None, 4, 4, 32)     0           tf.__operators__.add[0][0]       \r\n",
      "    __________________________________________________________________________________________________\r\n",
      "    gate_layer (GateLayer)          (None, 4, 4, 32)     0           tf.__operators__.getitem[0][0]   \r\n",
      "\r\n",
      "and \r\n",
      "\r\n",
      "    ==================================================================================================\r\n",
      "    Total params: 22,610,979\r\n",
      "    Trainable params: 22,602,915\r\n",
      "    Non-trainable params: 8,064\r\n",
      "\r\n",
      "\r\n",
      "Could you please let me know where I did wrong? I've been tried with different things but they cannot sort things out... \r\n",
      "\r\n",
      "  [1]: https://github.com/iomanker/VQVAE-TF2\r\n",
      "  [2]: https://www.kaggle.com/ameroyer/keras-vq-vae-for-image-generation/comments\r\n",
      "  [3]: https://github.com/iomanker/VQVAE-TF2/blob/master/vqvae.py\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "type:others\n",
      "\n",
      "\n",
      "issue title -  Flatbuffers Checksum Issue Building With Make\n",
      "issue body -  **System information**\r\n",
      "- No custom code\r\n",
      "- Windows 10 \r\n",
      "- TensorFlow installed from source\r\n",
      "- TensorFlow current version\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "\r\n",
      "Using make to build Tensorflow Lite example projects fails using make for several projects. On Windows, setting command prompt to the tensorflow repository directory, and following the README for tensorflow\\lite\\micro\\examples\\magic_wand:\r\n",
      "\r\n",
      "`make -f tensorflow/lite/micro/tools/make/Makefile test_magic_wand_test`\r\n",
      "\r\n",
      "That produces the following results:\r\n",
      "\r\n",
      "\r\n",
      "```\r\n",
      "C:\\Users\\jtork\\CMake\\tensorflow_src>make -f tensorflow/lite/micro/tools/make/Makefile test_magic_wand_test\r\n",
      "FIND: Parameter format not correct\r\n",
      "FIND: Parameter format not correct\r\n",
      "--2021-02-28 19:42:41--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\r\n",
      "Resolving mirror.tensorflow.org (mirror.tensorflow.org)... 142.250.113.128, 2607:f8b0:4023:1000::80\r\n",
      "Connecting to mirror.tensorflow.org (mirror.tensorflow.org)|142.250.113.128|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1760478 (1.7M) [application/zip]\r\n",
      "Saving to: '/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip'\r\n",
      "\r\n",
      "/tmp/dca12522a9f9e37f126ab925 100%[=================================================>]   1.68M  8.87MB/s    in 0.2s\r\n",
      "\r\n",
      "2021-02-28 19:42:41 (8.87 MB/s) - '/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip' saved [1760478/1760478]\r\n",
      "\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 1: $'PK\\003\\004': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 2: nL8Q5: command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 3: nL8Q?: command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 4: $'\\bnL8Qw\\030B\\005\\352\\002\\304\\005V': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 4: $'\\367\\257XY': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'\\002T': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'v\\355\\236\\215\\265M4\\036w]\\027\\262\\036p\\250t5\\256\\367\\245f': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'\\225L\\347\\313l\\036\\020\\350\\341\\320\\265\\254\\3218\\002~\\264B\\323\\302\\371\\016XC\\2408\\313': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'@\\244\\315\\217\\v\\2105': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'\\301\\2173H2\\037.\\342,\\311N\\223\\233d}\\231^\\257\\341': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'^\\255\\342\\345:\\231g\\220\\256': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: $'m\\237\\220Q7\\037\\324\\242\\304R\\234R\\372T\\235\\317k\\347T\\347\\316\\334\\235\\353F\\352\\217g\\317q': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 5: 6□m@0□cs/d□□ □j☼□4□E)8□&□□□z@-i#hPo□q□→☻X□6□□\r\n",
      "□l□□▼{□□A♂y+□□□→□□□Ff□‼%□□3⌂2□□܇□5□s□□D%→k<□Ȃ§J□□□↔W♣□9□►□0□ub♦OO□□□_□ɕ□@□□Y→□0□!□↓□m□□b□Ѫh□R□(K□H□2@L□90j□□63J□^%,□G□□j-\\□□↓♦☺liW□□□A♀□27/□1□□□∟U□e☺'□j♀Yk§□u9□□□#□3□(lඤ□d7□□□Z4K▬□Ez□□y}□]O□□,□m⌂'>!□(□}□□□□►□W□t§□□⌂|^□□□8□□Zu□↕□∟v{♫□♠□Jt+{ߐ%^□□k<~.□ـ□Z46♦□□v9□□   ↕□□v□□Z□Ԋ□ݏܲ{7□oȽ♦□⌂)♀‼H\\□/     □e▼□C□w□□@□□□□□☼□□B2□#-{♥□□0□□□□□l>9�□t)□□s↓↑_□□P2□     PK♥♦\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 11: $'OO\\337\\367\\312\\262\\204\\0365\\3341P]\\034\\327\\025ZL4\\237t\\364]r\\363\\024c\\020\\202\\216\\214?h\\210\\254N\\326\\b\\a\\275\\221z]P\\022\\301c\\177\\346\\2608\\274\\350\\234\\3230tl4y\\006\\244\\272h.y\\371\\214i\\201,': command not found\r\n",
      "nL8Q>   flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.bazelci/UT♣☺□□l_PK♥♦\r\n",
      "nL8Q=□!X□K      flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.bazelci/presubmit.ymlUT♣☺□□l_□□□□J*□□I□L□L-□R□I,I-.□*□i□E□□V\r\n",
      "□I□y%□□f♠& □□☻X}|IbQzjI1DHWAIOOO        □♠↓□K▬j□♣§□□ML□/□□¶PK♥♦\r\n",
      "nL8Q□4%_□0☺B    flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.clang-formatUT♣☺□□l_m□Mn□@♀□□>♣↨)[v►□□*RP□♣\\p♠+□y□n□Q⌂□E□: No such file or directory\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 11: $'\\034Z\\303\\211\\346\\236\\223\\377\\b\\277\\211\\215l\\270\\247\\326\\b\\257ot[\\005\\235:\\232\\004\\235\\243\\246\\277\\231\\304m\\242\\3711\\277\\356\\361\\235$\\235\\264\\031Y\\363\\351\\2365\\363\\334\\356\\004\\343\\232-_\\346_\\332+\\355[\\264\\371\\021\\324J\\234\\256\\377B\\252\\252\\002\\370\\004PK\\003\\004': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 12: $'\\bnL8Q\\33088\\322\\236\\337B': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 13: $'\\302@\\020D\\373': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: $'\\021\\301\\336\\316\\322?\\020': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: r□□□□▲T↑□bLl□XN□□□QtK*◄4: No such file or directory\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: $'\\202\\v%Q\\256\\253\\333\\341^\\211ulh': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 17: $'f\\345eey\\206\\310?S\\336\\253wZ\\270pF\\223\\304\\2026\\306\\3236\\375{\\351\\003PK\\003\\004': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 18: $'\\bnL8Q\\324\\240P3\\211\\375A': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: command substitution: line 19: syntax error near unexpected token `)'\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: command substitution: line 19: `☻1♀D□□□□▬▬□□□□⌂□▲d□mJ□□.□□[□^ĝ3o↕=☻&♦9bxB □0j□<□□□□k$□♦↨x)(b\"1 □□P□x□□l'\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 16: $'\\305\\202\\205\\270\\312\\0261\\315\\274\\304RT\\373t\\363\\206\\036t\\371\\261\\204d\\340V\\327\\257v\\230\\036\\236\\332\\300U0\\330_\\246\\345\\f\\343L\\336\\027\\027mg\\252\\333\\256\\230\\235g\\376\\201I\\275\\317\\037PK\\003\\004': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 17: $'\\bnL8Q\\026\\345\\365\\275OUC': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 18: $'\\200': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 18: $'\\365\\370\\243\\371PK\\003\\004': command not found\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 19: flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.github/UT♣☺□□l_PK♥♦: No such file or directory\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 20: syntax error near unexpected token `('\r\n",
      "/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: line 20: nL8Q}□□□B☻N flatbuffers-dca12522a9f9e37f126ab925fd385c807ab4f84e/.github/ISSUE_TEMPLATE.mdUT♣☺□□l_U□AO□0♀□□□§o□□(□□v@∟ABp☻  ♫H□♫^□□□Ҥ□]`□▲□C□I□!□□□=□□□□□!□hr□□□>□□Ԃ↕□□□♂□^#□0zڳU¶□□C□q□↓□1↕□,□□|□□a□\\#RjGj□B.+□□☼!r□'↨     9͏y□B□□∟D□?KR□□↑I□GkX□$g□‼B9☻B□F^9□□♣A□q►□□□u□□□¶□1□□□bj□↓1□=HO□□□□□□,□□□!▲-□9□G□s□→☼□□□W□      □=□L□□□□<\\]Uh□□zu[□□▼□□□□□□□S□7□dvT@↑JּeY□      ∟□      q)Z□□r□□□♦□;□□򑱡 ↑□♠,□٠nV□□sϿ□□6□□□□{4=;□I♫%□▲□f□□□□☺PK♥♦'\r\n",
      "tensorflow/lite/micro/tools/make/Makefile:525: *** Something went wrong with the flatbuffers download: Bad checksum. Expected: aa9adc93eb9b33fa1a2a90969e48baee, Got: .  Stop.\r\n",
      "```\r\n",
      "\r\n",
      "I believe this same issue occurs for all make options I have tried.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "\r\n",
      "All dependencies should be resolved and the project should build. \r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "comp:micro\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  RuntimeError: Mixing different tf.distribute.Strategy objects while using tf.distribute.MirroredStrategy()\n",
      "issue body -  \r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04)\r\n",
      "- TensorFlow installed from (source or binary):binary\r\n",
      "- TensorFlow version (use command below): 1.15\r\n",
      "- Python version:3.6.9\r\n",
      "- CUDA/cuDNN version: 10\r\n",
      "- GPU model and memory: TitanXP\r\n",
      "\r\n",
      "TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`: v1.15.4-39-g3db52be 1.15.\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "Referring to : https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/bin/train.py, I was trying to create a code and also converting it to multi-GPU with tf.distribute.MirroredStrategy(). The code works with out tf.distribute.MirroredStrategy() in single Titan XP, but once I use the below code its shows error as shown below. \r\n",
      "**Describe the expected behavior**\r\n",
      "Using the tf.distribute.MirroredStrategy()\r\n",
      "\r\n",
      "`strategy=tf.distribute.MirroredStrategy()\r\n",
      "    with strategy.scope():\r\n",
      "           model....\r\n",
      "           model.compile`\r\n",
      "\r\n",
      "The above structure should run with multi-gpu\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "Provide a reproducible test case that is the bare minimum necessary to generate\r\n",
      "the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n",
      "Referring to https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/bin/train.py#L107, replaced with the above code. \r\n",
      "\r\n",
      "But error `RuntimeError: Mixing different tf.distribute.Strategy objects: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1 object at 0x7f36a44f72e8> is not <tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1 object at 0x7f36247d0128>`\n",
      "issue labels - \n",
      "TF 1.15\n",
      "comp:dist-strat\n",
      "stat:awaiting response\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Correct range of input values for MobileNet\n",
      "issue body -  Hello,\r\n",
      "\r\n",
      "I want to use the implementation of MobileNetV3 (either the MobileNet_large or MobileNet_small version) in my project. I'm using the TensorFlow v2.4.1.\r\n",
      "\r\n",
      " I get confused when I read the documentation about the range of input values for MobileNet-based models. According to this [link](https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5)  the expected range of values for the model is [0,1]. However, according to this other [link](https://www.tensorflow.org/tutorials/images/transfer_learning), the correct range of values is [-1, 1]. A similar issue was already reported at this [link](https://github.com/tensorflow/hub/issues/637).\r\n",
      "\r\n",
      "On the other hand, to my surprise, the function preprocess_input of the module [MobileNetV3](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/applications/mobilenet_v3.py#L556-L558) does not apply any change over the input; i.e. the function is returning directly the input.\r\n",
      "\r\n",
      "```\r\n",
      "@keras_export('keras.applications.mobilenet_v3.preprocess_input')\r\n",
      "def preprocess_input(x, data_format=None):  # pylint: disable=unused-argument\r\n",
      "  return x\r\n",
      "\r\n",
      "```\r\n",
      "\r\n",
      "So, what should be the correct range of input values for MobileNetV3?\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:docs-bug\n",
      "\n",
      "\n",
      "issue title -  Suspected duplicate code in resize_bilinear_op.cc\n",
      "issue body -  I suspect these two code blocks are doing very similar tasks and can potentially be merged: \r\n",
      "\r\n",
      "- [Code block 1](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/kernels/image/resize_bilinear_op.cc;l=254;drc=9e274c0b2ff75f64a97c9aec57aa59b030c5a01b;bpv=1;bpt=0)\r\n",
      "- [Code block 2](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/kernels/image/resize_bilinear_op.cc;l=265-283;drc=9e274c0b2ff75f64a97c9aec57aa59b030c5a01b;bpv=1;bpt=0)\r\n",
      "\r\n",
      "The only difference which I can notice is that the code block 1 **might** benefit from sequential cache read. But I think the compiler should assist to achieve the same efficiency for the code block 2. If so, we should merge these two blocks to eliminate duplicate code. \n",
      "issue labels - \n",
      "type:others\n",
      "\n",
      "\n",
      "issue title -  Problem with TensorFlow model example with custom Sin operator\n",
      "issue body -  Hi,\r\n",
      "\r\n",
      "I would like to practice with the TensorFlow model example with custom Sin operator (https://www.tensorflow.org/lite/guide/ops_custom#create_a_tensorflow_model). In particular, I'm interested to repeat the error \r\n",
      "\"Error: Some of the operators in the model are not supported by the standard TensorFlow Lite runtime...... Here is\r\n",
      "a list of operators for which you will need custom implementations: Sin.\" \r\n",
      "\r\n",
      "How can I do this using, for example, tf.lite.TFLiteConverter.from_concrete_functions()?\r\n",
      "Thanks in advance.\r\n",
      "\n",
      "issue labels - \n",
      "comp:lite\n",
      "stat:awaiting response\n",
      "type:docs-bug\n",
      "\n",
      "\n",
      "issue title -  minimize total loss without step loss\n",
      "issue body -  I want to minimize total loss without step loss (each loss no back-propagation), how to implement it?    \r\n",
      "total_loss = 0\r\n",
      "idx = 0\r\n",
      "for data in train_datas:\r\n",
      "       pre = model(data)\r\n",
      "       loss = metric(pre, gt)\r\n",
      "       total_loss = total_loss + loss\r\n",
      "       idx = idx + 1\r\n",
      "       if idx %10 == 0:\r\n",
      "              train_ops = optimizer(total_loss)\r\n",
      "              sess.run(train_ops)\n",
      "issue labels - \n",
      "stat:awaiting response\n",
      "type:others\n",
      "\n",
      "\n",
      "issue title -  unable to train model by using TPU(free TPU)\n",
      "issue body -  I have prepared pipe line to train x-rays image classification model, train dataset is not balanced so did balance it by using resampling methods see the below link for more information:\r\n",
      "https://www.tensorflow.org/guide/data#resampling\r\n",
      "\r\n",
      "please see the error msg I got when fit the model:\r\n",
      "_\"\"UnavailableError: 2 root error(s) found.\r\n",
      "  (0) Unavailable: Socket closed\r\n",
      "  (1) Unavailable: Unable to find a context_id matching the specified one (12465293436922014039). Perhaps the worker was restarted, or the context was GC'd?\r\n",
      "0 successful operations.\r\n",
      "0 derived errors ignored._\r\n",
      "\r\n",
      "Please advise?\n",
      "issue labels - \n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Error \"failed to connect to all addresses\" when iterating dataset on TPU with Colab or Kaggle\n",
      "issue body -  <em>Please make sure that this is a bug. As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:bug_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I'm currently testing out this example [EfficientDet_TPU](https://www.kaggle.com/davidtong/efficientdet-tpu-train-1-epoch-in-4-min)\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Kaggle and Google Colab\r\n",
      "- TensorFlow version (use command below): 2.4\r\n",
      "- Python version: 3.7\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "Unable to iterate dataset\r\n",
      "![Screenshot from 2021-02-28 16-35-06](https://user-images.githubusercontent.com/19550237/109412442-f8e10b80-79e2-11eb-9822-c07aa298818a.png)\r\n",
      "\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "Able to iterate dataset\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      " You can directly try this example, the tfrecords is provided as well. [EfficientDet_TPU](https://www.kaggle.com/davidtong/efficientdet-tpu-train-1-epoch-in-4-min)\r\n",
      "\r\n",
      "**Other info / logs** \r\n",
      "`UnavailableError                          Traceback (most recent call last)\r\n",
      "<ipython-input-33-15ac5583c702> in <module>\r\n",
      "----> 1 for batch_x, (batch_regression, batch_classification) in train_dataset_encode:\r\n",
      "      2     print(batch_x)\r\n",
      "      3     break\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)\r\n",
      "    745   def __next__(self):\r\n",
      "    746     try:\r\n",
      "--> 747       return self._next_internal()\r\n",
      "    748     except errors.OutOfRangeError:\r\n",
      "    749       raise StopIteration\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)\r\n",
      "    737         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access\r\n",
      "    738       except AttributeError:\r\n",
      "--> 739         return structure.from_compatible_tensor_list(self._element_spec, ret)\r\n",
      "    740 \r\n",
      "    741   @property\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/contextlib.py in __exit__(self, type, value, traceback)\r\n",
      "    117         if type is None:\r\n",
      "    118             try:\r\n",
      "--> 119                 next(self.gen)\r\n",
      "    120             except StopIteration:\r\n",
      "    121                 return False\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py in execution_mode(mode)\r\n",
      "   2114     finally:\r\n",
      "   2115       ctx.executor = executor_old\r\n",
      "-> 2116       executor_new.wait()\r\n",
      "   2117 \r\n",
      "   2118 \r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/executor.py in wait(self)\r\n",
      "     67   def wait(self):\r\n",
      "     68     \"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\r\n",
      "---> 69     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\n",
      "     70 \r\n",
      "     71   def clear_error(self):\r\n",
      "\r\n",
      "UnavailableError: failed to connect to all addresses\r\n",
      "Additional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n",
      ":{\"created\":\"@1614500451.196304845\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1614500451.108464009\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n",
      "`\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:data\n",
      "stat:awaiting response\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  issue with tf.data.experimental.rejection_resample method\n",
      "issue body -  when I run the below block of code i got this error:\r\n",
      "\"Shape must be rank 3 but is rank 2 for '{{node Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](ExpandDims, Tile/multiples)' with input shapes: [1,11,11], [2].\"\r\n",
      "\r\n",
      "I need to balance the \"train_dataset\" which has 11 labels by using the follwoing line of codes:\r\n",
      "\r\n",
      "1) create class_fun:\r\n",
      "```\r\n",
      "def class_func(features, label):\r\n",
      "  return label\r\n",
      "```\r\n",
      "\r\n",
      "2)create resampler object with targer_dist:\r\n",
      "```\r\n",
      "resampler = tf.data.experimental.rejection_resample(\r\n",
      "    class_func, target_dist=[0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.1])\r\n",
      "\r\n",
      "```\r\n",
      "When run the below line of code I got the error which I have mentioned it above :\r\n",
      "\r\n",
      "`resample_ds = train_dataset.unbatch().apply(resampler)\r\n",
      "`\r\n",
      "Please advise?\n",
      "issue labels - \n",
      "comp:data\n",
      "stat:awaiting response\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  TF-TRT: batch dimension is failing in FasterRCNN\n",
      "issue body -  <em>Please make sure that this is a bug. As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:bug_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n",
      "- TensorFlow installed from (source or binary): Nvidia docker image  `nvcr.io/nvidia/tensorflow:20.11-tf1-py3`\r\n",
      "- TensorFlow version (use command below): 1.15.4\r\n",
      "- Python version: 3.6\r\n",
      "- Bazel version (if compiling from source):\r\n",
      "- GCC/Compiler version (if compiling from source):\r\n",
      "- CUDA/cuDNN version:  10.2 / 7.6.5 \r\n",
      "- GPU model and memory: T4\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "I am using the script `https://github.com/tensorflow/tensorrt/tree/r1.14%2B/tftrt/examples/object_detection` to optimize the model faster_rcnn_inception_v2, although the test was completed successfully I got the below warning about` incomplete shapes`: \r\n",
      "```\r\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\r\n",
      "**1752 ops no flops stats due to incomplete shapes.\r\n",
      "Parsing Inputs...\r\n",
      "Incomplete shape.**\r\n",
      ".\r\n",
      ".\r\n",
      ".\r\n",
      "orm/default/dso_loader.cc:49] Successfully opened dynamic library libnvinfer.so.7\r\n",
      "WARNING:tensorflow:INT8 precision mode with calibration is supported with dynamic TRT ops only. Disregarding is_dynamic_op parameter.\r\n",
      ".\r\n",
      ".\r\n",
      ".\r\n",
      "DONE (t=1.91s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.390\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553\r\n",
      "{\r\n",
      "    \"avg_latency_ms\": 246.9332789430524,\r\n",
      "    \"avg_throughput_fps\": 32.397415343295854,\r\n",
      "    \"map\": 0.24546921626010776\r\n",
      "}\r\n",
      "ASSERTION PASSED: statistics['map'] > (0.243 - 0.01)\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "The test was completed successfully; however, when I tried to deploy the model with Nvidia DeepStream I got the below input shape errors, even though the engine was created with max batch size 8, it seems the object_detection.py script didn't assign the parameter input_shape for some operations\r\n",
      "```\r\n",
      "  (0) Invalid argument: Input shape axis 0 must equal 8, got shape [5,600,1024,3]\r\n",
      "         [[{{node Preprocessor/unstack}}]]\r\n",
      "         [[SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression_4/unstack/_2859]]\r\n",
      "  (1) I**nvalid argument: Input shape axis 0 must equal 8, got shape [5,600,1024,3]**\r\n",
      "         [[{{node Preprocessor/unstack}}]]\r\n",
      "```\r\n",
      "\r\n",
      "Hi @samikama / @trevor-m , could you please suggest how to solve this input shapes issue?, also it seems to be related to `NMS` custom ops . A similar case was reported [here](https://github.com/tensorflow/tensorflow/issues/21081)\r\n",
      "\n",
      "issue labels - \n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  how to set C++ standard version for tensenflow as another bazel project dependency\n",
      "issue body -  **System information**\r\n",
      "- ubuntu20.04\r\n",
      "- TensorFlow version:2.4.0\r\n",
      "- Python version:3.8\r\n",
      "- Bazel version (if compiling from source):3.7.2\r\n",
      "- GCC/Compiler version (if compiling from source):9.3\r\n",
      "\r\n",
      "**Describe the problem**\r\n",
      "my project depend on tensorflow, compile tensorflow need std=c++14 and above, I set --cxxopt=\"-std=c++14\" in bazel build command for my project, but this option doesn't work for tensorflow repository, I notice -std=c++14 effective for my own project and some other external repository\r\n",
      "\r\n",
      "**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n",
      "\r\n",
      "\r\n",
      "**Any other info / logs**\r\n",
      "external/org_tensorflow/tensorflow/core/platform/default/port.cc:360:46: error: could not convert '{9223372036854775807, 9223372036854775807}' from '<brace-enclosed initializer list>' to 'tensorflow::port::MemoryInfo'\r\n",
      "  360 |   MemoryInfo mem_info = {INT64_MAX, INT64_MAX};\r\n",
      "      |                                              ^\r\n",
      "      |                                              |\r\n",
      "      |                                              <brace-enclosed initializer list>\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "stat:awaiting response\n",
      "subtype: ubuntu/linux\n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  Batch Normalization fails as kernel constraint for Conv layers when using mixed precision\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n",
      "- TensorFlow installed from (source or binary): source\r\n",
      "- TensorFlow version (use command below): 2.4.1\r\n",
      "- Python version: 3.7\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "When using `tf.keras.layers.BatchNormalization()` as a constraint in a conv layer using mixed precision, the model cannot train\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "Using `tf.keras.layers.BatchNormalization()` as a constraint in a conv layer behaves the same regardless of using mixed precision or not.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "Provide a reproducible test case that is the bare minimum necessary to generate\r\n",
      "the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n",
      "[Colab link](https://colab.research.google.com/drive/1IFWFwRrYUQx7Kw0I_KdtrKtVhvZbI7hy?usp=sharing).\r\n",
      "\r\n",
      "I've included a few notes in comments to show that this issue is isolated to conv layers when using mixed precision.\r\n",
      "\r\n",
      "**Other info / logs** Include any logs or source code that would be helpful to\r\n",
      "diagnose the problem. If including tracebacks, please include the full\r\n",
      "traceback. Large logs and files should be attached.\r\n",
      "\r\n",
      "It looks like the issue is in the loss_scale_optimizer.\r\n",
      "\r\n",
      "```txt\r\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n",
      "        return step_function(self, iterator)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\r\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n",
      "        return fn(*args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n",
      "        outputs = model.train_step(data)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:757 train_step\r\n",
      "        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize\r\n",
      "        return self.apply_gradients(grads_and_vars, name=name)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py:712 apply_gradients\r\n",
      "        args=(grads_and_vars, name, experimental_aggregate_gradients))\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2941 merge_call\r\n",
      "        return self._merge_call(merge_fn, args, kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2948 _merge_call\r\n",
      "        return merge_fn(self._strategy, *args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py:745 _apply_gradients_cross_replica  **\r\n",
      "        do_not_apply_fn)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py:59 smart_cond\r\n",
      "        name=name)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\r\n",
      "        return target(*args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:538 new_func\r\n",
      "        return func(*args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:1180 cond\r\n",
      "        return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py:89 cond_v2\r\n",
      "        op_return_value=pred)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:990 func_graph_from_py_func\r\n",
      "        func_outputs = python_func(*func_args, **func_kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py:732 apply_fn\r\n",
      "        args=(grads, wrapped_vars, name, experimental_aggregate_gradients))\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n",
      "        return fn(*args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py:755 _apply_gradients\r\n",
      "        experimental_aggregate_gradients=experimental_aggregate_gradients)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:635 apply_gradients\r\n",
      "        \"name\": name,\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2941 merge_call\r\n",
      "        return self._merge_call(merge_fn, args, kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2948 _merge_call\r\n",
      "        return merge_fn(self._strategy, *args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:683 _distributed_apply  **\r\n",
      "        var, apply_grad_to_update_var, args=(grad,), group=False))\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2494 update\r\n",
      "        return self._update(var, fn, args, kwargs, group)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3431 _update\r\n",
      "        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3437 _update_non_slot\r\n",
      "        result = fn(*args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:661 apply_grad_to_update_var  **\r\n",
      "        return var.assign(var.constraint(var))\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/autocast_variable.py:237 assign\r\n",
      "        name, read_value)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/autocast_variable.py:209 _apply_assign_update\r\n",
      "        assign_op = update_fn(value, use_locking, name, False)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:882 assign\r\n",
      "        value_tensor = ops.convert_to_tensor(value, dtype=self.dtype)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\r\n",
      "        return func(*args, **kwargs)\r\n",
      "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1509 convert_to_tensor\r\n",
      "        (dtype.name, value.dtype.name, value))\r\n",
      "\r\n",
      "    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: <tf.Tensor 'cond_1/SGD/SGD/update/batch_normalization_2/FusedBatchNormV3:0' shape=(3, 3, 1, 32) dtype=float16>\r\n",
      "```\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  [_Derived_]RecvAsync is cancelled Error when training with LSTM on tf-gpu \n",
      "issue body -  <em>Please make sure that this is a bug. As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:bug_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n",
      "```\r\n",
      "model = tf.keras.Sequential([\r\n",
      "        tf.keras.layers.Embedding(vocab_size, store.embedding_dim,\r\n",
      "                                  batch_input_shape=[batch_size, None]),\r\n",
      "        tf.keras.layers.Dropout(store.dropout_rate),\r\n",
      "        tf.keras.layers.LSTM(store.rnn_units,\r\n",
      "                             return_sequences=True,\r\n",
      "                             stateful=True,\r\n",
      "                             recurrent_initializer=store.rnn_initializer),\r\n",
      "        tf.keras.layers.Dropout(store.dropout_rate),\r\n",
      "        tf.keras.layers.LSTM(store.rnn_units,\r\n",
      "                             return_sequences=True,\r\n",
      "                             stateful=True,\r\n",
      "                             recurrent_initializer=store.rnn_initializer),\r\n",
      "        tf.keras.layers.Dropout(store.dropout_rate),\r\n",
      "        tf.keras.layers.Dense(vocab_size)\r\n",
      "    ])\r\n",
      "    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\r\n",
      "\r\n",
      "```\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n",
      "- TensorFlow version (use command below):  v2.4.0-49-g85c8b2a817f 2.4.1\r\n",
      "- Python version: 3.8.8\r\n",
      "- CUDA/cuDNN version: CUDA 11.0.3 / CUDNN 8.0.5.77\r\n",
      "- GPU model and memory: GTX 1070 (8GB)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "I've been working on a LSTM model, when training with $ `model.fit()` , it runs for 6 epochs and then gives this error \r\n",
      "\r\n",
      "```\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1100, in fit\r\n",
      "    tmp_logs = self.train_function(iterator)\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n",
      "    result = self._call(*args, **kwds)\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 855, in _call\r\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2942, in __call__\r\n",
      "    return graph_function._call_flat(\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\r\n",
      "    return self._build_call_outputs(self._inference_function.call(\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\r\n",
      "    outputs = execute.execute(\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu24\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n",
      "tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n",
      "         [[{{node gradient_tape/sequential/embedding/embedding_lookup/Reshape/_20}}]] [Op:__inference_train_function_4800]\r\n",
      "\r\n",
      "Function call stack:\r\n",
      "train_function\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "Model should complete training without issue.\r\n",
      "I know the code is fine because I trained on the same code with no issue in an old environment I was using 2 months ago. It also runs fine in a CPU only tensorflow environment.  \r\n",
      "\r\n",
      "\r\n",
      "**Other info / logs** Include any logs or source code that would be helpful to\r\n",
      "diagnose the problem.\r\n",
      "\r\n",
      "```\r\n",
      "Epoch 1/50\r\n",
      "2021-02-27 14:50:38.552734: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n",
      "2021-02-27 14:50:38.882403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n",
      "2021-02-27 14:50:39.546250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n",
      "2021-02-27 14:50:39.794953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n",
      "37/37 [==============================] - 7s 55ms/step - loss: 7.0684 - accuracy: 0.1270\r\n",
      "Epoch 2/50\r\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 4.8889 - accuracy: 0.1828\r\n",
      "Epoch 3/50\r\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 4.7884 - accuracy: 0.1666\r\n",
      "Epoch 4/50\r\n",
      "37/37 [==============================] - 2s 54ms/step - loss: 4.6866 - accuracy: 0.1480\r\n",
      "Epoch 5/50\r\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 4.5179 - accuracy: 0.1630\r\n",
      "Epoch 6/50\r\n",
      "17/37 [============>.................] - ETA: 1s - loss: 4.2505 - accuracy: 0.14842021-02-27 14:50:55.955000: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR\r\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(2004): 'cudnnRNNBackwardWeights( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), output_desc.handles(), output_data.opaque(), workspace.opaque(), workspace.size(), rnn_desc.params_handle(), params_backprop_data->opaque(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n",
      "2021-02-27 14:50:55.955194: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cudnn_rnn_ops.cc:1926 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 256, 1, 100, 64, 256]\r\n",
      "2021-02-27 14:50:55,957 : MainThread : INFO : Saving model history to model_history.csv\r\n",
      "2021-02-27 14:50:55,961 : MainThread : INFO : Saving model to D:\\project\\project_engine\\fftest_checkpoints\\batch_0\\synthetic\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"runTrain.py\", line 65, in <module>\r\n",
      "    model.train()\r\n",
      "  ...\r\n",
      "  ... \r\n",
      "  ...\r\n",
      "  File \"D:\\project\\project_engine\\runTrain.py\", line 201, in train_rnn\r\n",
      "    model.fit(dataset, epochs=store.epochs, callbacks=_callbacks)\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1100, in fit\r\n",
      "    tmp_logs = self.train_function(iterator)\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n",
      "    result = self._call(*args, **kwds)\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 855, in _call\r\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2942, in __call__\r\n",
      "    return graph_function._call_flat(\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\r\n",
      "    return self._build_call_outputs(self._inference_function.call(\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\r\n",
      "    outputs = execute.execute(\r\n",
      "  File \"C:\\Users\\Me\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n",
      "tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n",
      "         [[{{node gradient_tape/sequential/embedding/embedding_lookup/Reshape/_20}}]] [Op:__inference_train_function_4800]\r\n",
      "\r\n",
      "Function call stack:\r\n",
      "train_function\r\n",
      "```\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:gpu\n",
      "stat:awaiting response\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Empty Interpreter Input/Output Buffer Pointers\n",
      "issue body -  ### 1. System information\r\n",
      "\r\n",
      "- OS Platform and Distribution: Windows 10, building in Visual Studio\r\n",
      "- TensorFlow installation: Model trained from PIP package (Tensorflow 2.4.1). TFLite interpreter building 2.0.0 (haven't been able to build TFLite 2.4.1 in Visual Studio yet)\r\n",
      "- TensorFlow library: 2.4.1 (Train, conversion) and 2.0.0 (inference)\r\n",
      "\r\n",
      "### 2. Code\r\n",
      "\r\n",
      "My model uses the following layers: \r\n",
      "First stage, the stage I'm having problems:\r\n",
      "TimeDistributed(Conv2D), TimeDistributed(MaxPooling2D), TimeDistributed(BatchNormalization), TimeDistributed(Flatten), TimeDistributed(Dense), \r\n",
      "\r\n",
      "Second stage (evaluated independently, haven't gotten to it yet):\r\n",
      "Bidirectional(GRU), Reshape, Dense, Dropout.\r\n",
      "\r\n",
      "I am quantizing this model. The inference code is shown below.\r\n",
      "\r\n",
      "`\tFS_FILE* pModelFile;\r\n",
      "\tchar ModelStage1Filename[] = \"\\\\Models\\\\cls_stg1.tflite\";\r\n",
      "\tchar ModelStage2Filename[] = \"\\\\Models\\\\cls_stg2.tflite\";\r\n",
      "\tint BytesRead;\r\n",
      "\r\n",
      "\tpModelFile = fs_fopen(ModelStage1Filename, \"r\");\r\n",
      "\tif (pModelFile != 0)\r\n",
      "\t{\r\n",
      "\t\tStage1ModelSize = fs_fread(ModelStage1ModelBinary, 1, sizeof(ModelStage1ModelBinary), pModelFile);\r\n",
      "\t\tfs_fclose(pModelFile);\r\n",
      "\t}\r\n",
      "\tpModelFile = fs_fopen(ModelStage2Filename, \"r\");\r\n",
      "\tif (pModelFile != 0)\r\n",
      "\t{\r\n",
      "\t\tStage1ModelSize = fs_fread(ModelStage2ModelBinary, 1, sizeof(ModelStage2ModelBinary), pModelFile);\r\n",
      "\t\tfs_fclose(pModelFile);\r\n",
      "\t}\r\n",
      "\r\n",
      "\tpMicroErrorReporter = new tflite::MicroErrorReporter();\r\n",
      "\tpErrorReporter = pMicroErrorReporter;\r\n",
      "\r\n",
      "\r\n",
      "\tif (Stage1ModelSize > 0)\r\n",
      "\t{\r\n",
      "\t\tStage1Model = tflite::GetModel(ModelStage1ModelBinary);\r\n",
      "\t\tif (Stage1Model->version() != TFLITE_SCHEMA_VERSION)\r\n",
      "\t\t{\r\n",
      "\t\t\t/*TF_LITE_REPORT_ERROR(error_reporter,\r\n",
      "\t\t\t\t\"Model provided is schema version %d not equal \"\r\n",
      "\t\t\t\t\"to supported version %d.\\n\",\r\n",
      "\t\t\t\tmodel->version(), TFLITE_SCHEMA_VERSION);*/\r\n",
      "\t\t}\r\n",
      "\t\telse\r\n",
      "\t\t{\r\n",
      "\t\t\tpStage1Interpreter = new tflite::MicroInterpreter(Stage1Model, resolver, stage_1_tensor_arena, stage_1_tensor_arena_size, pErrorReporter);\r\n",
      "\t\t\tif (pStage1Interpreter != 0)\r\n",
      "\t\t\t{\r\n",
      "\t\t\t\tpStage1Interpreter->AllocateTensors();\r\n",
      "\t\t\t\t// Obtain a pointer to the model's input tensor\r\n",
      "\t\t\t\tTfLiteTensor* input = pStage1Interpreter->input(0);\r\n",
      "\t\t\t\tif (input != 0)\r\n",
      "\t\t\t\t{\r\n",
      "\t\t\t\t\tif (input->dims->size == 4 &&\r\n",
      "\t\t\t\t\t\tinput->type == kTfLiteUInt8 &&\r\n",
      "\t\t\t\t\t\tinput->dims->data[0] == 1 &&\r\n",
      "\t\t\t\t\t\tinput->dims->data[1] == 37 &&\r\n",
      "\t\t\t\t\t\tinput->dims->data[2] == 256 &&\r\n",
      "\t\t\t\t\t\tinput->dims->data[3] == 1)\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\tTfLiteTensor* output = pStage1Interpreter->output(0);\r\n",
      "\t\t\t\t\t\tif (output != 0)\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\tif (output->dims->size == 2 &&\r\n",
      "\t\t\t\t\t\t\t\toutput->type == kTfLiteUInt8 &&\r\n",
      "\t\t\t\t\t\t\t\toutput->dims->data[0] == 1 &&\r\n",
      "\t\t\t\t\t\t\t\toutput->dims->data[1] == 64)\r\n",
      "\t\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\t// All Good!\r\n",
      "\t\t\t\t\t\t\t\tStage1Good = 1;\r\n",
      "\t\t\t\t\t\t\t\tpStage1Input = pStage1Interpreter->typed_input_tensor<unsigned char>(0);\r\n",
      "\t\t\t\t\t\t\t\tpStage1Output = pStage1Interpreter->typed_output_tensor<unsigned char>(0);\r\n",
      "\t\t\t\t\t\t\t}\r\n",
      "\t\t\t\t\t\t}\r\n",
      "\t\t\t\t\t}\r\n",
      "\t\t\t\t}\r\n",
      "\t\t\t}\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "\telse\r\n",
      "\t{\r\n",
      "\t}`\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "### 3. Failure after conversion\r\n",
      "\r\n",
      "My fully trained model is split into two parts, a non-RNN first stage and an RNN second stage. When I run the inference code above to prepare to do inference on the first stage, everything looks good, the input and output tensor shapes and sizes are correct. But executing the lines below, I get null pointers, so I am unable to perform inference.\r\n",
      "\r\n",
      "pStage1Input = pStage1Interpreter->typed_input_tensor<unsigned char>(0);\r\n",
      "pStage1Output = pStage1Interpreter->typed_output_tensor<unsigned char>(0);\r\n",
      "\r\n",
      "When I use this code and setup with a simple model with a single dense layer, I get valid pointers. \r\n",
      "\r\n",
      "### 4. (optional) RNN conversion support\r\n",
      "This first stage does not include the RNN (the Bidirectional(GRU) ) parts of the full model.\r\n",
      "\r\n",
      "### 5. (optional) Any other info / logs\r\n",
      "I have tried to pull in Tensorflow Lite 2.4.1 into my Visual Studio project, however I am currently unable to resolve all of the dependencies, as the Windows make process seemed to work before in version 2.0.0 but not now in 2.4.1. There is a failure getting flatbuffers. So I don't know for sure if there is an issue with the difference in training/converting in 2.4.1 and performing inference using 2.0.0.\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:lite\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Tensorflow Addons connected components not working properly\n",
      "issue body -  <em>Please make sure that this is a bug. As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:bug_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n",
      "- TensorFlow installed from (source or binary): binary\r\n",
      "- TensorFlow version (use command below): 2.4.0\r\n",
      "- Python version: 3.8.5\r\n",
      "- Bazel version (if compiling from source):\r\n",
      "- GCC/Compiler version (if compiling from source):\r\n",
      "- CUDA/cuDNN version: Cuda compilation tools, release 10.1, V10.1.243\r\n",
      "- GPU model and memory: GEForce GTX 1080 Ti, 11264 MB Dedicated Video Memory (I'm using CPU)\r\n",
      "\r\n",
      "You can collect some of this information using our environment capture\r\n",
      "[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n",
      "You can also obtain the TensorFlow version with:\r\n",
      "1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n",
      "2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "TFA connected components should produce 2 components with the attached script. It is not.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "TFA result should show same number of components as Scipy.ndimage.measurements.label, as claimed in the documentation\r\n",
      "\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "Provide a reproducible test case that is the bare minimum necessary to generate\r\n",
      "the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n",
      "\r\n",
      "\"\"\"\r\n",
      "    TFA Addons Connected Components check\r\n",
      "\r\n",
      "    Using:\r\n",
      "    TensorFlow 2.4.0\r\n",
      "    Python 3.8.5\r\n",
      "    TFA 0.12.1\r\n",
      "    Scipy 1.6.1\r\n",
      "\"\"\"\r\n",
      "\r\n",
      "import tensorflow\r\n",
      "import numpy as np\r\n",
      "import tensorflow_addons as tfa\r\n",
      "import matplotlib.pyplot as plt\r\n",
      "import scipy.ndimage.measurements as meas\r\n",
      "\r\n",
      "\r\n",
      "with tensorflow.device('/CPU:0'):\r\n",
      "\r\n",
      "    M = 500\r\n",
      "    img = np.zeros((M, M))\r\n",
      "\r\n",
      "    # One square\r\n",
      "    top = 50\r\n",
      "    bottom = 270\r\n",
      "    left = 300\r\n",
      "    right = 450\r\n",
      "    img[np.ix_(np.arange(top, bottom + 1), np.arange(left, right + 1))] = 1\r\n",
      "\r\n",
      "    # Second one\r\n",
      "    top = 100\r\n",
      "    bottom = 150\r\n",
      "    left = 200\r\n",
      "    right = 250\r\n",
      "    img[np.ix_(np.arange(top, bottom + 1), np.arange(left, right + 1))] = 1\r\n",
      "\r\n",
      "    # Convert image to tensor\r\n",
      "    img = tensorflow.convert_to_tensor(img)\r\n",
      "    imgtf = tensorflow.expand_dims(img, -1)\r\n",
      "\r\n",
      "    # Connected components with TFA\r\n",
      "    d_img_tfa = tfa.image.connected_components(imgtf).numpy()\r\n",
      "\r\n",
      "    # Plot it\r\n",
      "    plt.figure()\r\n",
      "    plt.title('TFA Connected Components Image')\r\n",
      "    _ = plt.imshow(d_img_tfa)\r\n",
      "    plt.show(block=False)\r\n",
      "\r\n",
      "    # Connected components with scipy\r\n",
      "    d_img_scipy, _ = meas.label(imgtf)\r\n",
      "\r\n",
      "    # Count number of non-background components (subtract 1 for background)\r\n",
      "    num_comp_tfa = np.unique(d_img_tfa.flatten()).size - 1\r\n",
      "    num_comp_scipy = np.unique(d_img_scipy.flatten()).size - 1\r\n",
      "\r\n",
      "    # These images should be the same\r\n",
      "    print(\"\\nTFA connected components has %d components.\" % num_comp_tfa)\r\n",
      "    print(\"Scipy connected components has %d components.\\n\" % num_comp_scipy)\r\n",
      "\r\n",
      "    # Plot\r\n",
      "    plt.figure()\r\n",
      "    plt.title('Scipy Connected Components Image')\r\n",
      "    _ = plt.imshow(d_img_scipy)\r\n",
      "    plt.show(block=True)\r\n",
      "\r\n",
      "\r\n",
      "**Other info / logs** Include any logs or source code that would be helpful to\r\n",
      "diagnose the problem. If including tracebacks, please include the full\r\n",
      "traceback. Large logs and files should be attached.\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "stat:awaiting response\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Keras model saving erroring: TypeError: get_config() missing 1 required positional argument: 'self'\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: unknown\r\n",
      "- TensorFlow installed from (source or binary): binary, conda\r\n",
      "- TensorFlow version (use command below): 2.2\r\n",
      "- Python version: 3.8\r\n",
      "- CUDA/cuDNN version: 7.6\r\n",
      "\r\n",
      "Bug demonstrated here:\r\n",
      "https://stackoverflow.com/questions/57154799/keras-model-saving-erroring-typeerror-get-config-missing-1-required-position\r\n",
      "\r\n",
      "Saving model that has weights initialized by tf.keras.initializers.zeros instead of tf.keras.initializers.Zeros() does not work because tf.keras.initializers.zeros is a class while tf.keras.initializers.Zeros() is an instance. Tf tries to look at fields of class but can't because it is not an instance. I cannot save my own model like this, and instead, have to save the weights and python code to construct it.\r\n",
      "\r\n",
      "I get the following error after calling model.save(filename) on my tf.keras Model:\r\n",
      "\r\n",
      "```\r\n",
      "---------------------------------------------------------------------------\r\n",
      "TypeError                                 Traceback (most recent call last)\r\n",
      "<ipython-input-52-4285f74de661> in <module>\r\n",
      "----> 1 ae.save(\r\n",
      "      2     os.path.join(folder, 'model'),\r\n",
      "      3     include_optimizer=False\r\n",
      "      4 )\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n",
      "   1049     ```\r\n",
      "   1050     \"\"\"\r\n",
      "-> 1051     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n",
      "   1052                     signatures, options)\r\n",
      "   1053 \r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n",
      "    135         model, filepath, overwrite, include_optimizer)\r\n",
      "    136   else:\r\n",
      "--> 137     saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n",
      "    138                           signatures, options)\r\n",
      "    139 \r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)\r\n",
      "     76     # we use the default replica context here.\r\n",
      "     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access\r\n",
      "---> 78       save_lib.save(model, filepath, signatures, options)\r\n",
      "     79 \r\n",
      "     80   if not include_optimizer:\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)\r\n",
      "    948   meta_graph_def = saved_model.meta_graphs.add()\r\n",
      "    949 \r\n",
      "--> 950   _, exported_graph, object_saver, asset_info = _build_meta_graph(\r\n",
      "    951       obj, export_dir, signatures, options, meta_graph_def)\r\n",
      "    952   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)\r\n",
      "   1034         function_aliases[fdef.name] = alias\r\n",
      "   1035 \r\n",
      "-> 1036   object_graph_proto = _serialize_object_graph(saveable_view,\r\n",
      "   1037                                                asset_info.asset_index)\r\n",
      "   1038   meta_graph_def.object_graph_def.CopyFrom(object_graph_proto)\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _serialize_object_graph(saveable_view, asset_file_def_index)\r\n",
      "    694 \r\n",
      "    695   for obj, obj_proto in zip(saveable_view.nodes, proto.nodes):\r\n",
      "--> 696     _write_object_proto(obj, obj_proto, asset_file_def_index,\r\n",
      "    697                         saveable_view.function_name_map)\r\n",
      "    698   return proto\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _write_object_proto(obj, proto, asset_file_def_index, function_name_map)\r\n",
      "    735           version=versions_pb2.VersionDef(\r\n",
      "    736               producer=1, min_consumer=1, bad_consumers=[]),\r\n",
      "--> 737           metadata=obj._tracking_metadata)\r\n",
      "    738       # pylint:enable=protected-access\r\n",
      "    739     proto.user_object.CopyFrom(registered_type_proto)\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _tracking_metadata(self)\r\n",
      "   2740   @property\r\n",
      "   2741   def _tracking_metadata(self):\r\n",
      "-> 2742     return self._trackable_saved_model_saver.tracking_metadata\r\n",
      "   2743 \r\n",
      "   2744   def _list_extra_dependencies_for_serialization(self, serialization_cache):\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py in tracking_metadata(self)\r\n",
      "     52     # TODO(kathywu): check that serialized JSON can be loaded (e.g., if an\r\n",
      "     53     # object is in the python property)\r\n",
      "---> 54     return json_utils.Encoder().encode(self.python_properties)\r\n",
      "     55 \r\n",
      "     56   def list_extra_dependencies_for_serialization(self, serialization_cache):\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in python_properties(self)\r\n",
      "     39   def python_properties(self):\r\n",
      "     40     # TODO(kathywu): Add python property validator\r\n",
      "---> 41     return self._python_properties_internal()\r\n",
      "     42 \r\n",
      "     43   def _python_properties_internal(self):\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py in _python_properties_internal(self)\r\n",
      "     33 \r\n",
      "     34   def _python_properties_internal(self):\r\n",
      "---> 35     metadata = super(ModelSavedModelSaver, self)._python_properties_internal()\r\n",
      "     36     metadata.update(\r\n",
      "     37         saving_utils.model_metadata(\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/network_serialization.py in _python_properties_internal(self)\r\n",
      "     31 \r\n",
      "     32   def _python_properties_internal(self):\r\n",
      "---> 33     metadata = super(NetworkSavedModelSaver, self)._python_properties_internal()\r\n",
      "     34 \r\n",
      "     35     # Network stateful property is dependent on the child layers.\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _python_properties_internal(self)\r\n",
      "     55         stateful=self.obj.stateful)\r\n",
      "     56 \r\n",
      "---> 57     metadata.update(get_config(self.obj))\r\n",
      "     58     if self.obj.input_spec is not None:\r\n",
      "     59       # Layer's input_spec has already been type-checked in the property setter.\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in get_config(obj)\r\n",
      "    113     # When loading, the program will attempt to revive the object from config,\r\n",
      "    114     # and if that fails, the object will be revived from the SavedModel.\r\n",
      "--> 115     config = generic_utils.serialize_keras_object(obj)['config']\r\n",
      "    116 \r\n",
      "    117   if config is not None:\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in serialize_keras_object(instance)\r\n",
      "    268     name = get_registered_name(instance.__class__)\r\n",
      "    269     try:\r\n",
      "--> 270       config = instance.get_config()\r\n",
      "    271     except NotImplementedError as e:\r\n",
      "    272       if _SKIP_FAILED_SERIALIZATION:\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py in get_config(self)\r\n",
      "    966     if not self._is_graph_network:\r\n",
      "    967       raise NotImplementedError\r\n",
      "--> 968     return copy.deepcopy(get_network_config(self))\r\n",
      "    969 \r\n",
      "    970   @classmethod\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py in get_network_config(network, serialize_layer_fn)\r\n",
      "   2117           filtered_inbound_nodes.append(node_data)\r\n",
      "   2118 \r\n",
      "-> 2119     layer_config = serialize_layer_fn(layer)\r\n",
      "   2120     layer_config['name'] = layer.name\r\n",
      "   2121     layer_config['inbound_nodes'] = filtered_inbound_nodes\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in serialize_keras_object(instance)\r\n",
      "    268     name = get_registered_name(instance.__class__)\r\n",
      "    269     try:\r\n",
      "--> 270       config = instance.get_config()\r\n",
      "    271     except NotImplementedError as e:\r\n",
      "    272       if _SKIP_FAILED_SERIALIZATION:\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py in get_config(self)\r\n",
      "    261         'activation': activations.serialize(self.activation),\r\n",
      "    262         'use_bias': self.use_bias,\r\n",
      "--> 263         'kernel_initializer': initializers.serialize(self.kernel_initializer),\r\n",
      "    264         'bias_initializer': initializers.serialize(self.bias_initializer),\r\n",
      "    265         'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/initializers.py in serialize(initializer)\r\n",
      "    164 @keras_export('keras.initializers.serialize')\r\n",
      "    165 def serialize(initializer):\r\n",
      "--> 166   return serialize_keras_object(initializer)\r\n",
      "    167 \r\n",
      "    168 \r\n",
      "\r\n",
      "~/anaconda3/envs/tf-2.2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in serialize_keras_object(instance)\r\n",
      "    268     name = get_registered_name(instance.__class__)\r\n",
      "    269     try:\r\n",
      "--> 270       config = instance.get_config()\r\n",
      "    271     except NotImplementedError as e:\r\n",
      "    272       if _SKIP_FAILED_SERIALIZATION:\r\n",
      "\r\n",
      "TypeError: get_config() missing 1 required positional argument: 'self'\r\n",
      "```\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.2\n",
      "comp:keras\n",
      "stat:awaiting response\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Lr workaround for wrapped  optimizers\n",
      "issue body -  Investigate side effects in CI tests with a Workaround for mixed precision hyper access with wrapped optimizers.\r\n",
      "\r\n",
      "See:\r\n",
      "https://github.com/tensorflow/addons/pull/2404\r\n",
      "\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  custom op on gpu/dsp\n",
      "issue body -  The official website just tell me how to custom ops on CPU, i wonder if there‘s something could teach me how to do this on GPU/DSP.\r\n",
      "And we need  **_“libhexagon_nn_skel.*.so\"_** to use DSP. If i custom ops on hexagon delegate, do i have to compile new  ”.so“ through hexagon SDK ,or just build AAR and use the old .so files?\r\n",
      "Thanks a lot!!!😭😭😭\n",
      "issue labels - \n",
      "comp:lite\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Quantize for pooling op\n",
      "issue body -  The int8 pooling(avg and max) does not have rescale because operators have the same scale and zero point for\r\n",
      "input and output tensors. \r\n",
      "I'm wondering how to keep same scale, since distributions for different for intput and output tensors after max or avg operation.\r\n",
      "![image](https://user-images.githubusercontent.com/19774920/109381833-97a03600-7917-11eb-8d9d-c87d2d6be964.png)\r\n",
      "\n",
      "issue labels - \n",
      "\n",
      "\n",
      "issue title -  Modify Transpose kernel to work in TFLu\n",
      "issue body -  Modifications to the transpose kernel necessary to make it run in micro. This is PR 4/5 in delivering #45695\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:micro\n",
      "comp:micro:arm\n",
      "prtype:bugfix\n",
      "size:M\n",
      "\n",
      "\n",
      "issue title -  \"ValueError: No gradients provided \" error in TF v2.4.1, works fine on v2.3.1\n",
      "issue body -  **System information**\r\n",
      "Python : 3.6.3, TF: 2.4.1, TF probability: 0.12.1\r\n",
      "Python : 3.6.9, TF: 2.3.1, TF probability: 0.11.1\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu and CentOS\r\n",
      "- TensorFlow installed from (source or binary): Pip\r\n",
      "- TensorFlow version (use command below): 2.4.1 and 2.3.1\r\n",
      "- Python version: 3.6.9 and 3.6.3\r\n",
      "- GPU model and memory: None\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "I have copied simple Gaussian process example from the tensorflow probability site. It works fine on version 2.3.1 but yields \r\n",
      "`ValueError: No gradients provided for any variable:` error on tensorflow 2.4.1\r\n",
      "\r\n",
      "The example file  colab has been attached alongwith.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "Both shall result in identical behaviour. And should produce gradients.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "Reproduced here:\r\n",
      "\r\n",
      "https://colab.research.google.com/drive/1Tx-46aoF4i5mHMuJ7Et13B1km7u6i7YV#scrollTo=RXrq442mMGJD\r\n",
      "\r\n",
      "Example adapted from here:\r\n",
      "\r\n",
      "https://www.tensorflow.org/probability/examples/Gaussian_Process_Regression_In_TFP\r\n",
      "\r\n",
      "**Other info / logs** Include any logs or source code that would be helpful to\r\n",
      "diagnose the problem. If including tracebacks, please include the full\r\n",
      "traceback. Large logs and files should be attached.\r\n",
      "\r\n",
      "Error:\r\n",
      "\r\n",
      "```\r\n",
      "---------------------------------------------------------------------------\r\n",
      "\r\n",
      "ValueError                                Traceback (most recent call last)\r\n",
      "\r\n",
      "<ipython-input-1-6493a18eac89> in <module>()\r\n",
      "    116                             observation_noise_variance_var)\r\n",
      "    117   grads = tape.gradient(loss, trainable_variables)\r\n",
      "--> 118   optimizer.apply_gradients(zip(grads, trainable_variables))\r\n",
      "    119   lls_[i] = loss\r\n",
      "    120 \r\n",
      "\r\n",
      "1 frames\r\n",
      "\r\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name, experimental_aggregate_gradients)\r\n",
      "    596       RuntimeError: If called in a cross-replica context.\r\n",
      "    597     \"\"\"\r\n",
      "--> 598     grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\r\n",
      "    599     var_list = [v for (_, v) in grads_and_vars]\r\n",
      "    600 \r\n",
      "\r\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/utils.py in filter_empty_gradients(grads_and_vars)\r\n",
      "     77   if not filtered:\r\n",
      "     78     raise ValueError(\"No gradients provided for any variable: %s.\" %\r\n",
      "---> 79                      ([v.name for _, v in grads_and_vars],))\r\n",
      "     80   if vars_with_empty_grads:\r\n",
      "     81     logging.warning(\r\n",
      "\r\n",
      "ValueError: No gradients provided for any variable: ['amplitude:0', 'length_scale:0', 'observation_noise_variance_var:0'].\r\n",
      "```\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:ops\n",
      "regression issue\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  fix erroneous assign in Env::StartTransaction()\n",
      "issue body -  env.h StartTransaction(), token isn't being properly null'd (in master)\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:core\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  First step towards prototyping v2 of TFLM integration with external IDEs.\n",
      "issue body -  With this change we can create an output directory containing all the sources and headers (including third_party) needed to build the TFLM static library.\r\n",
      "\r\n",
      "See tools/ci_build/test_project_generation.sh for some sample commands.\r\n",
      "\r\n",
      "A next step will be to add the sources for the examples as well.\r\n",
      "\r\n",
      "Progress towards: #47413\r\n",
      "\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:micro\n",
      "size:L\n",
      "\n",
      "\n",
      "issue title -  AttributeError: module 'tensorflow' has no attribute 'Session' with tensorflow 2.4.1\n",
      "issue body -  \r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **windows 10**\r\n",
      "- TensorFlow installed from (source or binary): installed from source\r\n",
      "- TensorFlow version (use command below): **2.4.1**\r\n",
      "- Python version: **3.8.5**\r\n",
      "- CUDA/cuDNN version: Cuda 11.2/11.1\r\n",
      "- GPU model and memory: **Intel(R) UHD Graphics 630\r\n",
      "NVIDIA GeForce GTX 1050**\r\n",
      "\r\n",
      "You can collect some of this information using our environment capture\r\n",
      "[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n",
      "You can also obtain the TensorFlow version with:\r\n",
      "1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n",
      "2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n",
      "\r\n",
      "\r\n",
      "v2.4.0-49-g85c8b2a817f 2.4.1\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "\r\n",
      "I installed the tensorflow-gpu:\r\n",
      "```\r\n",
      "conda create -n tensorflow-gpu\r\n",
      "activate tensorflow-gpu\r\n",
      "pip install tensorflow-gpu\r\n",
      "\r\n",
      "activate tensorflow-gpu\r\n",
      "\r\n",
      "python\r\n",
      "import tensorflow as tf\r\n",
      "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n",
      "\r\n",
      "I got this error: AttributeError: module 'tensorflow' has no attribute 'Session'\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "\r\n",
      "The Session() should be executed correctly.\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:apis\n",
      "stat:awaiting response\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  tensorflow-gpu 2.2.0 doesn't recognize Nvidia MX130 GPU\n",
      "issue body -  <em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- OS Platform and Distribution: Windows 10 Build 19042\r\n",
      "- TensorFlow installed from (source or binary): `pip install tensorflow-gpu==2.2.0` in conda environment.\r\n",
      "- TensorFlow version: 2.2.0\r\n",
      "- Python version: 3.7.9\r\n",
      "- Installed using pip.\r\n",
      "- CUDA/cuDNN version: `CUDA 10.1.243`, `cuDNN 7.6.5`\r\n",
      "- GPU model and memory: GeForce MX130, 2GB\r\n",
      "\r\n",
      "**Problem Description:**\r\n",
      "TensorFlow 2.2.0 doesn't recognize my GPU.\r\n",
      "\r\n",
      "**Provide the exact sequence of commands / steps that you executed before running into the problem:**\r\n",
      "\r\n",
      "1. Installed [CUDA 10.1 (Update 2)](https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal) to `D:\\Program Files\\CUDA\\v10.1`.\r\n",
      "2. Extracted [cuDNN 7.6.5](https://developer.nvidia.com/rdp/cudnn-archive#a-collapse765-101) to `D:\\cuda`.\r\n",
      "3. Set the correct path, as instructed in [https://www.tensorflow.org/install/gpu for TensorFlow 2.2.0](https://web.archive.org/web/20200603082035if_/https://www.tensorflow.org/install/gpu#software_requirements).\r\n",
      "```batch\r\n",
      "SET PATH=D:\\Program Files\\CUDA\\v10.1\\bin;%PATH%\r\n",
      "SET PATH=D:\\Program Files\\CUDA\\v10.1\\extras\\CUPTI\\lib64;%PATH%\r\n",
      "SET PATH=D:\\Program Files\\CUDA\\v10.1\\include;%PATH%\r\n",
      "SET PATH=D:\\cuda\\bin;%PATH%\r\n",
      "```\r\n",
      "\r\n",
      "4. In Python, imported TensorFlow and tried to check for the GPU:\r\n",
      "```python\r\n",
      "import tensorflow as tf\r\n",
      "tf.test.is_built_with_cuda()\r\n",
      "tf.config.experimental.list_physical_devices('gpu')\r\n",
      "```\r\n",
      "Output is:\r\n",
      "```python\r\n",
      ">>> import tensorflow as tf\r\n",
      "2021-02-26 19:58:38.967202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n",
      "\r\n",
      ">>> tf.test.is_built_with_cuda()\r\n",
      "True\r\n",
      "\r\n",
      ">>> tf.config.experimental.list_physical_devices('gpu')\r\n",
      "2021-02-26 21:14:53.525272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n",
      "2021-02-26 21:14:54.056784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\n",
      "pciBusID: 0000:02:00.0 name: GeForce MX130 computeCapability: 5.0\r\n",
      "coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s\r\n",
      "2021-02-26 21:14:54.057159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n",
      "2021-02-26 21:14:54.068576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n",
      "2021-02-26 21:14:54.076899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n",
      "2021-02-26 21:14:54.079739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n",
      "2021-02-26 21:14:54.090196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n",
      "2021-02-26 21:14:54.095665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n",
      "2021-02-26 21:14:55.099130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n",
      "2021-02-26 21:14:55.300935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n",
      "[]\r\n",
      "```\r\n",
      "\r\n",
      "Not a duplicate of [issue #41892](https://github.com/tensorflow/tensorflow/issues/41892), as I use Windows 10.\r\n",
      "\r\n",
      "Edit:\r\n",
      "As @ymodak suggested:\r\n",
      "```python\r\n",
      "import tensorflow as tf\r\n",
      "tf.config.list_logical_devices('GPU')\r\n",
      "```\r\n",
      "does return:\r\n",
      "```python\r\n",
      ">>> import tensorflow as tf\r\n",
      "2021-02-27 14:21:36.675965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n",
      "\r\n",
      ">>> tf.config.list_logical_devices('GPU')\r\n",
      "2021-02-27 14:26:59.304811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n",
      "2021-02-27 14:26:59.803139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\n",
      "pciBusID: 0000:02:00.0 name: GeForce MX130 computeCapability: 5.0\r\n",
      "coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s\r\n",
      "2021-02-27 14:26:59.803491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n",
      "2021-02-27 14:27:00.179875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n",
      "2021-02-27 14:27:00.224576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n",
      "2021-02-27 14:27:00.247267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n",
      "2021-02-27 14:27:00.290612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n",
      "2021-02-27 14:27:00.313676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n",
      "2021-02-27 14:27:00.834454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n",
      "2021-02-27 14:27:01.102483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n",
      "2021-02-27 14:27:01.111434: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n",
      "2021-02-27 14:27:01.160065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e9c1582e60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n",
      "2021-02-27 14:27:01.160517: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n",
      "2021-02-27 14:27:01.207202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\n",
      "pciBusID: 0000:02:00.0 name: GeForce MX130 computeCapability: 5.0\r\n",
      "coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s\r\n",
      "2021-02-27 14:27:01.207683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n",
      "2021-02-27 14:27:01.212166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n",
      "2021-02-27 14:27:01.215100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n",
      "2021-02-27 14:27:01.216437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n",
      "2021-02-27 14:27:01.219085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n",
      "2021-02-27 14:27:01.220720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n",
      "2021-02-27 14:27:01.221751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n",
      "2021-02-27 14:27:01.223134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n",
      "2021-02-27 14:27:16.215597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2021-02-27 14:27:16.216163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n",
      "2021-02-27 14:27:16.221461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n",
      "2021-02-27 14:27:16.304146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1377 MB memory) -> physical GPU (device: 0, name: GeForce MX130, pci bus id: 0000:02:00.0, compute capability: 5.0)\r\n",
      "2021-02-27 14:27:16.432698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e9dec28fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n",
      "2021-02-27 14:27:16.433279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce MX130, Compute Capability 5.0\r\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\r\n",
      "```\r\n",
      "_but_ in Jupyter notebook it returns:\r\n",
      "```python\r\n",
      "[]\r\n",
      "```\r\n",
      "_AND_ it still does not train my model using the GPU.\n",
      "issue labels - \n",
      "TF 2.2\n",
      "comp:gpu\n",
      "stat:awaiting response\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  add MNIST training to `mnist_grad_test`\n",
      "issue body -  @saxenasaurabh \r\n",
      "\r\n",
      "One last PR for the cleanup process. I ran the test 500 times and the accuracy is around 92% - 95%. I think it's because we don't have any validation set yet. Please take a look at this PR ! Thank you !\n",
      "issue labels - \n",
      "cla: yes\n",
      "size:L\n",
      "\n",
      "\n",
      "issue title -  Make the output for model summary wrap\n",
      "issue body -  This is just a small alteration to the printing logic of the model summary to allow the cells to wrap, this is useful for model with long outputs/inputs (such as BERT, which is what motivated me to do this). Useful for rigorous storage of model summaries.\r\n",
      "\r\n",
      "[x] Read contributing guidelines.\r\n",
      "[x] Read Code of Conduct.\r\n",
      "[x] Ensure you have signed the Contributor License Agreement (CLA).\r\n",
      "[x] Check if my changes are consistent with the guidelines. (I think they are)\r\n",
      "[x] Changes are consistent with the Coding Style. (File's pylint score unchanged from 8.56)\r\n",
      "[ ] Run Unit Tests.\r\n",
      "\r\n",
      "I am really struggling to be able to run these tests, been trying for a good 4/5 hours, I am on Ubuntu 20.04, I have:\r\n",
      "1. Tried running `tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...` from repo root, this consistently errors due to `tensorflow/tools/ci_build/install/install_pip_packages.sh` not seeing the correct python version (which weirdly is trying to use python3.6 even though the git blame for the changes to line 26 suggest the purpose was to migrate to python 3.7)\r\n",
      "2. Tried changing the docker file to some other one, I have tried the `tensorflow/tools/ci_build/Dockerfile.pi-python38` (which i now realise is for raspberry pi's - derp!) and `tensorflow/tools/ci_build/Dockerfile.local-toolchain-ubuntu18.04-manylinux2010`. Neither worked.\r\n",
      "3. Ultimately, I have pulled `tensorflow/tensorflow   latest-devel   a4c4b6decc02` and exec'd into the container and tried to run `bazel test //tensorflow/python/keras` but that has errored due to:\r\n",
      "```\r\n",
      "ERROR: /tensorflow_src/tensorflow/core/kernels/BUILD:2736:18: C++ compilation of rule '//tensorflow/core/kernels:resource_variable_ops' failed (Exit 4): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 240 argument(s) skipped)\r\n",
      "gcc: internal compiler error: Killed (program cc1plus)\r\n",
      "```\r\n",
      "\r\n",
      "I am really keen to try and get these tests running to verify my changes haven't affected anything (although searching the repo for tests using `model.summary()` suggests everything should still pass.\r\n",
      "\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  Correctly close file descriptors when loading saved models\n",
      "issue body -  This PR uses the `FileIO` contextmanager in order to ensure that filedescriptors are correctly closed after use when loading saved models.\n",
      "issue labels - \n",
      "cla: yes\n",
      "ready to pull\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  Building TensorFlow Lite - macos_arm64 support using cmake\n",
      "issue body -  with respect to this [issue](https://github.com/google/XNNPACK/issues/1302) in the XNNPACK repository:  `bazel` builds for macos_arm64 platform are not yet supported.\r\n",
      "however building with cmake works successfully.\r\n",
      "\r\n",
      "this change allows to build the `TensorFlow Lite library` and the `benchmark_model` on a macos_arm64 host platform when using `-DTFLITE_ENABLE_XNNPACK=ON` (default). see [instructions](https://www.tensorflow.org/lite/guide/build_cmake).\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:lite\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  Distributed computing, extreme distribution latency \n",
      "issue body -  tf 2.2\r\n",
      "python 3.7\r\n",
      "\r\n",
      "I'm trying to distribute a training step over multiple GPU and although I'm not shown any error and the memory seems to be correctly allocated to all the GPUs.\r\n",
      "I am experiencing extreme latency in the distribution and collection:\r\n",
      "```\r\n",
      "@tf.function\r\n",
      "def distributed_train_step(dist_inputs):\r\n",
      "    per_replica_losses = mirrored_strategy.run(model._train_step, args=(dist_inputs,))\r\n",
      "    return mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\r\n",
      "                                    axis=None)\r\n",
      "dist_dataset = mirrored_strategy.experimental_distribute_dataset(train_dataset.dataset)\r\n",
      "for dist_input in dist_dataset:\r\n",
      "    output = distributed_train_step(dist_input)\r\n",
      "    print(f'\\r{output}')\r\n",
      "```\r\n",
      "Specifically it seems that a lot of time is spent for this operation (~5 seconds)\r\n",
      "```\r\n",
      "mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\r\n",
      "                                    axis=None)\r\n",
      "```\r\n",
      "as well as between calls of \r\n",
      "```\r\n",
      "mirrored_strategy.run(model._train_step, args=(dist_inputs,))\r\n",
      "```\r\n",
      "where I very rudimentally print \"inside train step\" at the beginning of model._train_step and I see a print every ~ 1s per GPU (sequentially), so ~3s in total.\r\n",
      "In a single GPU settings this train step (with the same total batch size) is performed in less than a second. \r\n",
      "\r\n",
      "When starting training everything seems fine\r\n",
      "\r\n",
      "```\r\n",
      "2021-02-26 13:31:14.658769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n",
      "2021-02-26 13:31:14.714487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 5000 computeCapability: 7.5\r\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\r\n",
      "2021-02-26 13:31:14.715401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:\r\n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 5000 computeCapability: 7.5\r\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\r\n",
      "2021-02-26 13:31:14.715624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "2021-02-26 13:31:14.717261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n",
      "2021-02-26 13:31:14.718644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n",
      "2021-02-26 13:31:14.718874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n",
      "2021-02-26 13:31:14.720288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n",
      "2021-02-26 13:31:14.721085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n",
      "2021-02-26 13:31:14.724158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n",
      "2021-02-26 13:31:14.727302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\r\n",
      "2021-02-26 13:31:14.727631: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\n",
      "2021-02-26 13:31:14.734379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3200000000 Hz\r\n",
      "2021-02-26 13:31:14.736749: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56099e0aead0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n",
      "2021-02-26 13:31:14.736805: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n",
      "2021-02-26 13:31:14.933093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 5000 computeCapability: 7.5\r\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\r\n",
      "2021-02-26 13:31:14.933919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:\r\n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 5000 computeCapability: 7.5\r\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\r\n",
      "2021-02-26 13:31:14.933976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "2021-02-26 13:31:14.933988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n",
      "2021-02-26 13:31:14.933999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n",
      "2021-02-26 13:31:14.934009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n",
      "2021-02-26 13:31:14.934019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n",
      "2021-02-26 13:31:14.934029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n",
      "2021-02-26 13:31:14.934040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n",
      "2021-02-26 13:31:14.937073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\r\n",
      "2021-02-26 13:31:14.937121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "2021-02-26 13:31:14.938810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2021-02-26 13:31:14.938835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1\r\n",
      "2021-02-26 13:31:14.938840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y\r\n",
      "2021-02-26 13:31:14.938843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N\r\n",
      "2021-02-26 13:31:14.941865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15037 MB memory) -> physical GPU (device: 0, name: Quadro RTX 5000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\r\n",
      "2021-02-26 13:31:14.943851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15037 MB memory) -> physical GPU (device: 1, name: Quadro RTX 5000, pci bus id: 0000:af:00.0, compute capability: 7.5)\r\n",
      "2021-02-26 13:31:14.945733: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56099d69c690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n",
      "2021-02-26 13:31:14.945750: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\r\n",
      "2021-02-26 13:31:14.945754: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Quadro RTX 5000, Compute Capability 7.5\r\n",
      "2021-02-26 13:31:40.674717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n",
      "```\r\n",
      "Loss is actually decreasing so backprop seems to work just fine.\r\n",
      "\r\n",
      "Here are the relevant code snippets:\r\n",
      "```\r\n",
      "mirrored_strategy = tf.distribute.MirroredStrategy()\r\n",
      "with mirrored_strategy.scope():\r\n",
      "    opt = tf.keras.optimizers.Adam(0.0001,\r\n",
      "                                   beta_1=0.9,\r\n",
      "                                   beta_2=0.98,\r\n",
      "                                   epsilon=1e-9)\r\n",
      "    model = config_manager.get_model()\r\n",
      "    model.loss_weights = [1., 1.]\r\n",
      "    model.compile(loss=[masked_mean_absolute_error,\r\n",
      "                        new_scaled_crossentropy(index=2, scaling=8)],\r\n",
      "                  loss_weights=model.loss_weights,\r\n",
      "                  optimizer=opt)\r\n",
      "```\r\n",
      "all the loss functions have a SUM  reduction strategy\r\n",
      "\r\n",
      "where train_dataset.dataset is this binned_data\r\n",
      "```\r\n",
      "dataset = tf.data.Dataset.from_generator(lambda: self._datagen(shuffle),\r\n",
      "                                                 output_types=output_types)\r\n",
      "\r\n",
      "binned_data = dataset.apply(\r\n",
      "    tf.data.experimental.bucket_by_sequence_length(\r\n",
      "        len_function,\r\n",
      "        bucket_boundaries=bucket_boundaries,\r\n",
      "        bucket_batch_sizes=bucket_batch_sizes,\r\n",
      "        padded_shapes=padded_shapes,\r\n",
      "        drop_remainder=drop_remainder,\r\n",
      "        padding_values=padding_values\r\n",
      "    ))\r\n",
      "```\r\n",
      "\r\n",
      "and model._train_step is\r\n",
      "```\r\n",
      "    def _train_step(self, dist_inputs):\r\n",
      "        mel, phonemes, stop, sample_name = dist_inputs\r\n",
      "        tar_inp = mel[:, :-1]\r\n",
      "        tar_real = mel[:, 1:]\r\n",
      "        tar_stop_prob = stop[:, 1:]\r\n",
      "\r\n",
      "        mel_len = int(tf.shape(tar_inp)[1])\r\n",
      "        tar_mel = tar_inp[:, 0::self.r, :]\r\n",
      "\r\n",
      "        with tf.GradientTape() as tape:\r\n",
      "            model_out = self.__call__(inputs=phonemes,\r\n",
      "                                      targets=tar_mel,\r\n",
      "                                      training=True)\r\n",
      "            loss, loss_vals = weighted_sum_losses((tar_real,\r\n",
      "                                                   tar_stop_prob),\r\n",
      "                                                  (model_out['mel'][:, :mel_len, :],\r\n",
      "                                                   model_out['stop_prob'][:, :mel_len, :]),\r\n",
      "                                                  self.loss,\r\n",
      "                                                  self.loss_weights)\r\n",
      "            loss = loss / 64.\r\n",
      "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
      "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
      "        return loss\r\n",
      "```\r\n",
      "\r\n",
      "Everything seems according to the guide https://www.tensorflow.org/guide/distributed_training \n",
      "issue labels - \n",
      "TF 2.2\n",
      "comp:dist-strat\n",
      "stat:awaiting response\n",
      "type:performance\n",
      "\n",
      "\n",
      "issue title -  Remove unnecessary model parsing from keras.model.load_model\n",
      "issue body -  This PR removes duplicated SavedModel parsing from `keras.model.load_model`. The result of parsing was never used and it is also not needed for error handling either since the same function will be called at the start of `saved_model_load.load`:\r\n",
      "https://github.com/tensorflow/tensorflow/blob/7e1c942100039dc0a9adda5d0d45c7e1d2e3b76c/tensorflow/python/keras/saving/saved_model/load.py#L124\r\n",
      "\r\n",
      "This removes the need to read the file content and parse the saved model twice which can improve performance when loading models from a remote file system like GCS.\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  Add link to presentation, minor fixes\n",
      "issue body -  Signed-off-by: Michael Gielda <mgielda@antmicro.com>\r\n",
      "\r\n",
      "Adding link to slides as proposed by TF Lite Micro team\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:micro\n",
      "ready to pull\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  Model.predict accepts tensors of incorrect rank\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab (Ubuntu 18.04)\r\n",
      "- TensorFlow installed from (source or binary): Colab\r\n",
      "- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1\r\n",
      "- Python version: 3.7.10\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "* When defining a model with `tf.keras.Input(shape=[1])`, `model.predict` should only accept a tensor of shape `[batch,1]`, but it incorrectly accepts a tensor of shape `[batch]` (and appears to reshape it to `[batch, 1]`).\r\n",
      "* When defining a model with `tf.keras.Input(shape=[2])`, `model.predict` should only accept a tensor of shape `[batch,2]`, but it incorrectly accepts a tensor of shape `[1, batch, 2]`. The erroneous extra dimension is retained in the value returned by `model.predict`.\r\n",
      "\r\n",
      "(These two bugs feel closely related, which is why I'm reporting them together. If not, I can file two separate issues.)\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "When defining a model with `tf.keras.Input(shape=[d1,d2,...,dn])`, `model.predict` should only accept a tensor of shape `[batch,d1,d2,...,dn]`. All other shapes should raise an exception.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "[The issues are shown in this Colab notebook.](https://colab.research.google.com/drive/1qP7wa2b7-8Sb5Z5ODNEXWZeQ0cDc-ttY?usp=sharing)\r\n",
      "\r\n",
      "**Other info / logs**\r\n",
      "If this is expected behavior, [it should be documented here](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict). It is not. And I hope it is not expected behavior.\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Make libtensorflow_jni target compatible with Tensorflow Text\n",
      "issue body -  Export tensorflow symbols to solve global static variable lookup issue.\r\n",
      "\r\n",
      "Fix #47431 \n",
      "issue labels - \n",
      "awaiting review\n",
      "cla: yes\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  Failed to run models with libtensorflow_jni and tensorflow text together\n",
      "issue body -  <em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n",
      "- TensorFlow installed from (source or binary): source\r\n",
      "- TensorFlow version: 2.3.1\r\n",
      "- Python version:  n/a\r\n",
      "- Installed using virtualenv? pip? conda?: n/a\r\n",
      "- Bazel version (if compiling from source): 3.1.0\r\n",
      "- GCC/Compiler version (if compiling from source): gcc7\r\n",
      "- CUDA/cuDNN version: n/a\r\n",
      "- GPU model and memory: n/a\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the problem**\r\n",
      "\r\n",
      "**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n",
      "When using [libtensorflow_jni.so](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/BUILD#L437) with [tensorflow text](https://github.com/tensorflow/text), it crashes.\r\n",
      "\r\n",
      "Same issue: https://github.com/tensorflow/java/issues/82\r\n",
      "\r\n",
      "**Any other info / logs**\r\n",
      "```\r\n",
      "2021-02-17 19:20:45.283001: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at wordpiece_kernel.cc:204 : Invalid argument: Trying to access resource using the wrong type. Expected N10tensorflow6lookup15LookupInterfaceE got N10tensorflow6lookup15LookupInterfaceE\r\n",
      "```\n",
      "issue labels - \n",
      "TF 2.3\n",
      "comp:apis\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Cannot import name 'boosted_trees_test' from 'tensorflow_estimator.python.estimator.canned' \n",
      "issue body -  When I am trying to import boosted_trees_test, I face the following error:\r\n",
      "\r\n",
      "\r\n",
      "`cannot import name 'boosted_trees_test' from 'tensorflow_estimator.python.estimator.canned' (C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\__init__.py)\r\n",
      "`\r\n",
      "\r\n",
      "\r\n",
      "Also, I could not find the boosted_trees_test in the latest TF package (2.4)\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:apis\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Simplify Huber Loss implementation\n",
      "issue body -  This PR simplifies the Huber Loss implementation and also updates the docstring to use a more readable formulation matching the one on Wikipedia.\r\n",
      "\r\n",
      "This PR does not change the mathematics, but removes the need for one operation in the code path that cannot be constant folded away which should improve performance.\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  Normalization layer supresses ValueError when model is called with bad input shape\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab notebook, and everywhere else tested\r\n",
      "- TensorFlow installed from (source or binary):  Colab notebook, and everywhere else tested\r\n",
      "- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1\r\n",
      "- Python version: 3.7.10\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "After adding a `tf.keras.layers.experimental.preprocessing.Normalization` layer to a model, badly shaped input is accepted by the model's `.predict`, generating only a warning log line, and returning some nonsense output.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "After adding a `tf.keras.layers.experimental.preprocessing.Normalization` layer to a model, badly shaped input should be rejected by the model's `.predict`, raising a `ValueError`.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "[Here is a Colab notebook that shows the issue](https://colab.research.google.com/drive/1ud_9UtZaTwmlL6WTnJkWMXG162DJ57kr?usp=sharing)\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Pass for Dialect conversion from Tflite to TF  \n",
      "issue body -  Does there exists a Pass that can take back for Dialect conversion from Tflite to TF, TFlite->TF\r\n",
      "We need something which preserves the quantization info generated during Tflite and detours back to TF where we can lower it down to HLO and Linalg thereon.\r\n",
      "We don't need a new Dialect but just a Pass that can visit the Tflite IR and reconvert it back to TF getting back the Quantization info.\r\n",
      "                CustomPass\r\n",
      "TF->TFlite->TF->HLO->Linalg\r\n",
      "What would be the other available ways to achieve this.\n",
      "issue labels - \n",
      "TFLiteConverter\n",
      "comp:lite\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  Disable unroll batch matmul pass\n",
      "issue body -  ### 1. System information\r\n",
      "\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n",
      "- TensorFlow installation (pip package or built from source): pip\r\n",
      "- TensorFlow library (version, if pip package or github SHA, if built from source): nightly\r\n",
      "\r\n",
      "### 2. Code\r\n",
      "\r\n",
      "https://colab.research.google.com/drive/1VxiMyDs5B_Oxcg29EmPSu9qgvPejCWqx?usp=sharing\r\n",
      "\r\n",
      "### 3. Failure after conversion\r\n",
      "\r\n",
      "It's all successful. But with unrolling (large batch dim), the model will be significant larger, and probably decrease the performance. I suppose it's just a workaround when tflite does not have batch matmul kernel, but we have it now.\n",
      "issue labels - \n",
      "TFLiteConverter\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  SELU activation in TFlite micro\n",
      "issue body -  <em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n",
      "\r\n",
      "\r\n",
      "**System information**\r\n",
      "- TensorFlow version (you are using): **2.5**\r\n",
      "- Are you willing to contribute it (Yes/No): Yes\r\n",
      "\r\n",
      "**Describe the feature and the current behavior/state.** Currently no good alternative exists for deployment if micro. Batch Norm for micros seem to have som issues in certain Cortex M4 platforms.\r\n",
      "\r\n",
      "**Will this change the current api? How?** It will add SELU activation to the supported ops in TF Lite Micro\r\n",
      "\r\n",
      "**Who will benefit with this feature?** Embedded developers, interested in building NN's with multple layers.\r\n",
      "\r\n",
      "**Any Other info.**\r\n",
      "SELU activation as per [Klaumbauer et.al](https://arxiv.org/abs/1706.02515) provides self normalising, similar to Batch Normalisation, but requiring less compute, as it is an activation function. \r\n",
      "At the time of writing we haven't found alternatives, to running self normalising on microprocessor implementations. \r\n",
      "\r\n",
      "The application on wich the operator is desired is a predicitive maintainence system we are developing.\r\n",
      "Our model is trained on field data captured from a large number of rotating machines, where the data mean and variance differs a lot, from from machine to machine, caused by mechanical tolerances and different mechanical transfer functions. Thus a degree of normalisation through the network is required, if we are to use identical models for detecting emerging defect in rotating components. \r\n",
      "We are using a convolutional model, fed with raw data, to be able to capture transient events, as opposed to traditional FFT based feature extraction, based on [this proposal](https://www.researchgate.net/publication/314247372_A_New_Deep_Learning_Model_for_Fault_Diagnosis_with_Good_Anti-Noise_and_Domain_Adaptation_Ability_on_Raw_Vibration_Signals) \r\n",
      "\r\n",
      "From what i can see the SELU could be implemented similarily to the ELU `/lite/kernels/elu.cc` that uses a lookuptable when performing inference, and the selu itself, works as sketched below  :\r\n",
      "\r\n",
      "\r\n",
      "```\r\n",
      "#define ALPHA   1.6733f\r\n",
      "#define LAMBDA  1.0507f\r\n",
      "\r\n",
      "inline void Selu(const RuntimeShape& input_shape, const float* input_data,\r\n",
      "                const RuntimeShape& output_shape, float* output_data) {\r\n",
      "  const int flat_size = MatchingFlatSize(input_shape, output_shape);\r\n",
      "  for (int i = 0; i < flat_size; ++i) {\r\n",
      "    const float val = input_data[i];\r\n",
      "    output_data[i] = val < 0.0f ? LAMBDA * (ALPHA * std::expm1(val) - ALPHA) : LAMBDA * val;\r\n",
      "  }\r\n",
      "}\r\n",
      "```\r\n",
      "\n",
      "issue labels - \n",
      "comp:micro\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  Add thread name in the error message when thread creation fails.\n",
      "issue body -  This PR adds thread name in the error message when thread creation fails. It helps with debugging when thread creation fails.\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:core\n",
      "size:XS\n",
      "stat:awaiting tensorflower\n",
      "\n",
      "\n",
      "issue title -  NotFoundError: It shows libcudart.so.8.0, but I am using CUDA 10.0.\n",
      "issue body -  Hello everyone.\r\n",
      "I wanted to use TensorFlow 1.13.1, so I installed it in the following environment.\r\n",
      "-----system information-----\r\n",
      "OS:Ubuntu18.04.5 64bit\r\n",
      "CPU:Intel Core  i7-10700 @2.90Ghz x 16\r\n",
      "RAM:16GB\r\n",
      "GPU:Gefoce RTX2060\r\n",
      "CUDA:10.0.130\r\n",
      "cuDNN:7.4\r\n",
      "GPU driver:460.32.03\r\n",
      "python2.7\r\n",
      "-----------------------------------\r\n",
      "\r\n",
      "-----The following error message will be displayed-----\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: libcudart.so.8.0: cannot open shared object file: No such file or directory\r\n",
      "-------------------------------------------------\r\n",
      "The TensorFlow website describes it as compatible with Python 2.7, 3.3 to 3.7 GCC 4.8 Bazel 0.19.2 cuDNN7.4 CUDA10.0. Why am I being suggested a CUDA 8.0 environment?\r\n",
      "I have tried to install other versions of TensorFlow, but they all give me the same error.\r\n",
      "Can someone please help me?\r\n",
      "Thank you\r\n",
      "\n",
      "issue labels - \n",
      "stat:awaiting response\n",
      "subtype: ubuntu/linux\n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  Support all fp types in GPU SparseTensorDenseMatMul\n",
      "issue body -  Adds Eigen::half for CPU, and Eigen::half, double, and complex for GPU.\r\n",
      "\r\n",
      "cc @nluehr \n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:core\n",
      "ready to pull\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  Remove unit8 support from kernels prior to adding new optimized implementations\n",
      "issue body -  We would like TFLM to drop support for asymmetric quantization and uint8 support (see https://github.com/tensorflow/tensorflow/issues/44912).\r\n",
      "\r\n",
      "As a result, for new optimized implementations (such as https://github.com/tensorflow/tensorflow/pull/46500) we need to `ifdef` the uint8 test cases in a way that is not scalable:\r\n",
      "https://github.com/tensorflow/tensorflow/pull/46500/files?file-filters%5B%5D=.cc#diff-8fb35117d2592a6f74def12c8b12e4d19cec0e9a05f2cd64fcceb84c22d93faaR336-R343\r\n",
      "\r\n",
      "Instead of such ifdefs, we should remove uint8 support from the existing kernel implementations prior to adding in new optimized kernels.\r\n",
      "\r\n",
      "More generally, as we start adding int16 support, it is possible that while the reference kernel has support for int16, some of the optimized implementations will not. In order to keep the tests passing, we will need a more scalable way to filter out specific test cases.\r\n",
      "\r\n",
      "A (potentially sufficient) solution would be to ifdef based on supported types (e.g. DISABLE_INT16). However, this can be a slippery path since there are other 'features' that the optimized kernels may not support, so we will want to limit such ifdefs if we do go down this path.\r\n",
      "\r\n",
      "Already, it is the case that the xtensa kernels only support `int8` and not `float`. As we have other such examples (potentially with the work that the folks at CEVA are currently doing), we should figure out what we want to do here.\n",
      "issue labels - \n",
      "comp:micro\n",
      "\n",
      "\n",
      "issue title -  Changes to MklConvFwdPrimitiveFactory to support Arm Compute Library backend\n",
      "issue body -  **System information**\r\n",
      "- TensorFlow version (you are using): 2.4.1\r\n",
      "- Are you willing to contribute it (Yes/No): Yes\r\n",
      "\r\n",
      "**Describe the feature and the current behavior/state.**\r\n",
      "At the moment MklConvFwdPrimitiveFactory reuses already created oneDNN primitives, stored in the vector `fwd_primitives`, with the help of [GetConvFwd](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L401-L404) function which creates a key from convolution parameters stored in MklConvFwdParams and compares this key with the keys of existing primitives. However, when oneDNN is built with [Arm Compute Library](https://github.com/ARM-software/ComputeLibrary) (ACL, see also oneDNN [build options](https://oneapi-src.github.io/oneDNN/dev_guide_build_options.html)) there is specific requirement to create a separate primitive per constant weights tensor, this is a restriction implied by ACL code design which does not allow to use primitive caching mechanism in MklConvFwdPrimitiveFactory as it is. The solution may be to add a new entry, `void* filter_address`, to [MklConvFwdParams](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L58-L93) struct and to include the address of weights to the key in [CreateKey](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L361-L399) function:\r\n",
      "\r\n",
      "    ...\r\n",
      "    key_creator.AddAsKey(convFwdDims.filter_dims);\r\n",
      "    #ifdef DNNL_AARCH64_USE_ACL\r\n",
      "    key_creator.AddAsKey(convFwdDims.filter_address);\r\n",
      "    #endif\r\n",
      "    key_creator.AddAsKey(convFwdDims.bias_dims);\r\n",
      "    ...\r\n",
      "\r\n",
      "**Will this change the current api? How?**\r\n",
      "The only API change is the addition of a new field to [CreateKey](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L361-L399) and [MklConvFwdParams](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L58-L93) in `mkl_conv_ops.cc`, this is related to the limitations of ACL which is designed to create a separate primitive per weights tensor.\r\n",
      "\r\n",
      "**Who will benefit with this feature?**\r\n",
      "The users who run inference regime with TensorFlow on AArch64-based machines.\r\n",
      "\r\n",
      "**Any Other info.**\r\n",
      "This Issue is raised mainly to get feedback from maintainers of the oneDNN to TensorFlow integration.\n",
      "issue labels - \n",
      "comp:mkl\n",
      "stat:awaiting tensorflower\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  TFLM project generation support (version 2)\n",
      "issue body -  Similar to https://github.com/tensorflow/tensorflow/issues/45086 and https://github.com/tensorflow/tensorflow/issues/44909, but broader in scope.\r\n",
      "\r\n",
      "Some high level goals for project generation v2 are:\r\n",
      " * Having the bulk of the project generation logic moved out of the TFLM Makefiles.\r\n",
      " * Having TFLM support a Python interface that can be used for project generation\r\n",
      " * Moving the specific logic for project generation out of the Tensorflow repository and into platform/IDE specific github repos.\r\n",
      "\r\n",
      "This work is currently at the early prototyping stage and this github issue will be used to track progress.\n",
      "issue labels - \n",
      "comp:micro\n",
      "\n",
      "\n",
      "issue title -  Add axis argument\n",
      "issue body -  Fix /issues/39230.\r\n",
      "This pull request will add the axis argument in tensorflow.keras.losses.categorical_crossentropy() and in tensorflow.keras.losses.binary_crossentropy() as in tensorflow.keras.losses.sparse_categorical_crossentropy().\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  No algorithm worked on Ubuntu 20.04 LTS with CUDA 11.0 and Tensorflow 2.4.1\n",
      "issue body -  Please go to Stack Overflow for help and support:\r\n",
      "\r\n",
      "https://stackoverflow.com/questions/tagged/tensorflow\r\n",
      "\r\n",
      "If you open a GitHub issue, here is our policy:\r\n",
      "\r\n",
      "1.  It must be a bug, a feature request, or a significant problem with the\r\n",
      "    documentation (for small docs fixes please send a PR instead).\r\n",
      "2.  The form below must be filled out.\r\n",
      "3.  It shouldn't be a TensorBoard issue. Those go\r\n",
      "    [here](https://github.com/tensorflow/tensorboard/issues).\r\n",
      "\r\n",
      "**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n",
      "\r\n",
      "------------------------\r\n",
      "\r\n",
      "### System information\r\n",
      "\r\n",
      "-   **Have I written custom code (as opposed to using a stock example script\r\n",
      "    provided in TensorFlow)**: Yes. It's the tensorflow.keras version of [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/)\r\n",
      "-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04 LTS\r\n",
      "-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n",
      "    happens on a mobile device**: N/A\r\n",
      "-   **TensorFlow installed from (source or binary)**: installed via pip inside conda environment\r\n",
      "-   **TensorFlow version (use command below)**: 2.4.1\r\n",
      "-   **Python version**: 3.8.8\r\n",
      "-   **Bazel version (if compiling from source)**: N/A\r\n",
      "-   **GCC/Compiler version (if compiling from source)**: N/A\r\n",
      "-   **CUDA/cuDNN version**: 11.0/8.04\r\n",
      "-   **GPU model and memory**: Nvidia RTX 2080 Super Max-Q, 8G\r\n",
      "-   **Exact command to reproduce**: See [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) (in which I have replaced all keras with tensorflow.keras)\r\n",
      "\r\n",
      "### Describe the problem\r\n",
      "\r\n",
      "I have installed tensorflow inside the conda base environment via `pip install --upgrade pip` and `pip install --upgrade tensorflow`, and the latter version is 2.4.1 (which should support CUDA 11.0). But as I tested the code from [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) (in which I have replaced all keras with tensorflow.keras), the code doesn't work and showed\r\n",
      "```\r\n",
      "NotFoundError:  No algorithm worked!\r\n",
      "\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-4-e30d719c0a87>:6) ]] [Op:__inference_train_function_728]\r\n",
      "\r\n",
      "Function call stack:\r\n",
      "train_function\r\n",
      "```\r\n",
      "\r\n",
      "Here are some strange things about it. \r\n",
      "1. I have no problem with running a dense neural network, as shown in [keras_example](https://www.tensorflow.org/datasets/keras_example). The training was smooth and fast.\r\n",
      "2. I have no problem with CUDA 10.1. I mean after uninstall ingCUDA 11.0 and all associated CUDNN, and installing CUDA 10.1 and corresponding CUDNN, then the code in [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) worked.\r\n",
      "\r\n",
      "### Source code / logs\r\n",
      "```python\r\n",
      "import numpy as np\r\n",
      "from tensorflow import keras\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.keras import layers\r\n",
      "\r\n",
      "\r\n",
      "# Model / data parameters\r\n",
      "num_classes = 10\r\n",
      "input_shape = (28, 28, 1)\r\n",
      "\r\n",
      "# the data, split between train and test sets\r\n",
      "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n",
      "\r\n",
      "# Scale images to the [0, 1] range\r\n",
      "x_train = x_train.astype(\"float32\") / 255\r\n",
      "x_test = x_test.astype(\"float32\") / 255\r\n",
      "# Make sure images have shape (28, 28, 1)\r\n",
      "x_train = np.expand_dims(x_train, -1)\r\n",
      "x_test = np.expand_dims(x_test, -1)\r\n",
      "\r\n",
      "# convert class vectors to binary class matrices\r\n",
      "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
      "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
      "\r\n",
      "model = keras.Sequential(\r\n",
      "    [\r\n",
      "        keras.Input(shape=input_shape),\r\n",
      "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\r\n",
      "        layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
      "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\r\n",
      "        layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
      "        layers.Flatten(),\r\n",
      "        layers.Dropout(0.5),\r\n",
      "        layers.Dense(num_classes, activation=\"softmax\"),\r\n",
      "    ]\r\n",
      ")\r\n",
      "model.summary()\r\n",
      "\r\n",
      "batch_size = 128\r\n",
      "epochs = 15\r\n",
      "\r\n",
      "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
      "\r\n",
      "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\r\n",
      "```\r\n",
      "Then the error came:\r\n",
      "```\r\n",
      "NotFoundError                             Traceback (most recent call last)\r\n",
      "<ipython-input-4-e30d719c0a87> in <module>\r\n",
      "      4 model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
      "      5 \r\n",
      "----> 6 model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n",
      "   1098                 _r=1):\r\n",
      "   1099               callbacks.on_train_batch_begin(step)\r\n",
      "-> 1100               tmp_logs = self.train_function(iterator)\r\n",
      "   1101               if data_handler.should_sync:\r\n",
      "   1102                 context.async_wait()\r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n",
      "    826     tracing_count = self.experimental_get_tracing_count()\r\n",
      "    827     with trace.Trace(self._name) as tm:\r\n",
      "--> 828       result = self._call(*args, **kwds)\r\n",
      "    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n",
      "    830       new_tracing_count = self.experimental_get_tracing_count()\r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n",
      "    886         # Lifting succeeded, so variables are initialized and we can run the\r\n",
      "    887         # stateless function.\r\n",
      "--> 888         return self._stateless_fn(*args, **kwds)\r\n",
      "    889     else:\r\n",
      "    890       _, _, _, filtered_flat_args = \\\r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n",
      "   2940       (graph_function,\r\n",
      "   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n",
      "-> 2942     return graph_function._call_flat(\r\n",
      "   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n",
      "   2944 \r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n",
      "   1916         and executing_eagerly):\r\n",
      "   1917       # No tape is watching; skip to running the function.\r\n",
      "-> 1918       return self._build_call_outputs(self._inference_function.call(\r\n",
      "   1919           ctx, args, cancellation_manager=cancellation_manager))\r\n",
      "   1920     forward_backward = self._select_forward_and_backward_functions(\r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n",
      "    553       with _InterpolateFunctionError(self):\r\n",
      "    554         if cancellation_manager is None:\r\n",
      "--> 555           outputs = execute.execute(\r\n",
      "    556               str(self.signature.name),\r\n",
      "    557               num_outputs=self._num_outputs,\r\n",
      "\r\n",
      "~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n",
      "     57   try:\r\n",
      "     58     ctx.ensure_initialized()\r\n",
      "---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n",
      "     60                                         inputs, attrs, num_outputs)\r\n",
      "     61   except core._NotOkStatusException as e:\r\n",
      "\r\n",
      "NotFoundError:  No algorithm worked!\r\n",
      "\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-4-e30d719c0a87>:6) ]] [Op:__inference_train_function_728]\r\n",
      "\r\n",
      "Function call stack:\r\n",
      "train_function\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:gpu\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Add support for probability/thresholds in meanIoU\n",
      "issue body -  Fixes #39173\r\n",
      "\r\n",
      "Currently the meanIoU function requires that if there are `num_classes` in the model's output, each value in `y_pred` must be an integer in the range `[0, num_classes-1]`. This is a problem because most ML models will generate outputs of `num_classes` probabilities in the range `[0-1]` (shape `[dim1, dim2, ..., num_classes]` or `[dim1, dim2, ..., num_classes -1 ]`) , not outputs of shape `[dim1, dim2, ...]` with integer class values. #39173 discusses this further. \r\n",
      "\r\n",
      "Adding support for probabilities and thresholding will require changes to the API, and I would love to hear your thoughts on the best way to accomplish this.\r\n",
      "\r\n",
      "## This PR adds the following:\r\n",
      "* New optional `threshold` argument in the `meanIoU` initializer. Single configurable threshold shared across all predicted classes, used to turn 0-1 probabilities into 0 or 1 integer predictions\r\n",
      "* Support for passing in probabilities instead of integer class labels\r\n",
      "* New tests\r\n",
      "\r\n",
      "\r\n",
      "## TODO:\r\n",
      "* Add some sort of toggle to select between `classID` mode and `probability` mode. This is needed because if there are more than two classes and `y_pred` is in the current format, values will include integers `[0, 1, 2, ... n]`, and the probability mode would turn all values over the threshold to `1`, giving incorrect results\r\n",
      "    * What is the best way to do this? One option would just be to add a `from_probability` field to `meanIoU` that defaults to false, but I'm not sure if there's a better way. #45690 is working towards adding support for logits, so we may need a way to switch between class labels, probabilities, and logins.\r\n",
      "* Ensure that results are correct when `num_classes > 2` (no tests at present)\r\n",
      "* When in probability mode, ensure that the last dimension of `y_pred` and `y_true` is either `num_classes` or `num_classes - 1`\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:M\n",
      "\n",
      "\n",
      "issue title -  Different outputs from GradientTape and CropAndResizeGradImage \n",
      "issue body -  **System information**\r\n",
      "== tensorflow installed from info ==================\r\n",
      "Name: tensorflow\r\n",
      "Version: 2.4.1\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /home/user/.venv/lib/python3.6/site-packages\r\n",
      "Required-by: \r\n",
      "\r\n",
      "== python version  ==============================================\r\n",
      "(major, minor, micro, releaselevel, serial)\r\n",
      "(3, 6, 8, 'final', 0)\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "I am calculating gradients using GradientTape.gradient() and comparing those against CropAndResizeGradImage().\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "This check passes for some configurations (like one given on https://www.tensorflow.org/api_docs/python/tf/image/crop_and_resize#example) not always.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "```\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "\r\n",
      "def test_crop_and_resize(BATCH_SIZE=1, NUM_BOXES=41, IMAGE_DIM=15, CHANNELS=6, CROP_SIZE=8):\r\n",
      "\r\n",
      "    image = tf.random.normal(shape=(BATCH_SIZE, IMAGE_DIM, IMAGE_DIM, CHANNELS) )\r\n",
      "    boxes = tf.random.uniform(shape=(NUM_BOXES, 4))\r\n",
      "\r\n",
      "    box_indices = tf.random.uniform(shape=(NUM_BOXES,), minval=0, maxval=BATCH_SIZE, dtype=tf.int32)\r\n",
      "\r\n",
      "    with tf.GradientTape() as g:\r\n",
      "        g.watch(image)\r\n",
      "        output = tf.image.crop_and_resize(image, boxes, box_indices, (CROP_SIZE, CROP_SIZE))\r\n",
      "\r\n",
      "    grad_in = tf.random.normal(output.shape)\r\n",
      "    grad_out = g.gradient(output, image, grad_in)\r\n",
      "    grad_out_raw = tf.raw_ops.CropAndResizeGradImage(grads=grad_in, boxes=boxes, box_ind=box_indices, image_size=image.shape, T=tf.float32, method='bilinear')\r\n",
      "    np.testing.assert_array_equal(grad_out.numpy(), grad_out_raw.numpy())\r\n",
      "\r\n",
      "test_crop_and_resize()\r\n",
      "```\r\n",
      "\r\n",
      "```\r\n",
      "E       AssertionError: \r\n",
      "E       Arrays are not equal\r\n",
      "E       \r\n",
      "E       Mismatched elements: 962 / 1350 (71.3%)\r\n",
      "E       Max absolute difference: 3.6710215\r\n",
      "E       Max relative difference: 320.43555\r\n",
      "E        x: array([[[[ 4.556600e-01,  3.979062e-01,  1.036789e-01,  4.944029e-01,\r\n",
      "E                  2.423330e-01,  1.300183e-01],\r\n",
      "E                [ 5.906850e-01,  3.972412e-01,  2.205431e-01,  1.333644e+00,...\r\n",
      "E        y: array([[[[ 4.556600e-01,  3.979062e-01,  1.036789e-01,  4.944029e-01,\r\n",
      "E                  2.423330e-01,  1.300183e-01],\r\n",
      "E                [ 5.906850e-01,  3.972412e-01,  2.205431e-01,  1.333644e+00,...\r\n",
      "```\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:ops\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  How to run a model training command in redhat linux slurm file?\n",
      "issue body -  <em>Hello , I am trying to run a model training command  for object detection in cluster server. For this reason, I need to run a final command in a particular directory . As I am working on a cluster server, I am creating a slurm file. After the basic instructions, I  wrote the directory where the training command will be executed and now I am unable to connect the training command with the slurm file.</em>\r\n",
      "\r\n",
      "![Slurrm _ssd](https://user-images.githubusercontent.com/68661510/109196179-ff605080-7760-11eb-963d-8e46fbb6fcd7.png)\r\n",
      "\n",
      "issue labels - \n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  Layer .input_shape and .output_shape wrongly claim \"The layer has never been called\"\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 11.2\r\n",
      "- TensorFlow installed from (source or binary): https://github.com/apple/tensorflow_macos\r\n",
      "- TensorFlow version (use command below): v1.12.1-44680-gc3fea33a21 2.4.0-rc0\r\n",
      "- Python version: 3.8.6\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "For a layer `l`, `l.input_shape` and `l.output_shape` raise the error \"AttributeError: The layer has never been called and thus has no defined input shape\", even though the layer has definitely been called.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "After a layer `l` has been called, `l.input_shape` and `l.output_shape` return shapes.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "```python\r\n",
      "import tensorflow as tf\r\n",
      "l = tf.keras.layers.Dense(units=2)\r\n",
      "l(tf.ones((5,3)))  # Call the layer, defining the input shape\r\n",
      "print(l.input_shape)  # Expected: (None, 3)\r\n",
      "print(l.output_shape)  # Expected: (None, 2)\r\n",
      "```\r\n",
      "\r\n",
      "**Other info / logs**\r\n",
      "* It's possible I'm using the API wrongly. But I'm pretty sure the claim \"The layer has never been called\" is false.\r\n",
      "* This works as expected if I wrap the layer in a `tf.keras.Sequential`. Is there an assumption that the layer is inside a `tf.keras.Model`?\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Tensorflow and flask has an error loading model.\n",
      "issue body -  Hello \r\n",
      "According to this closed issue, https://github.com/tensorflow/tensorflow/issues/44467\r\n",
      "I tried to install h5py == 2.10.0 version on my venv\r\n",
      "But still got same error\r\n",
      "\r\n",
      "![image](https://user-images.githubusercontent.com/75870530/109180833-46346180-77c6-11eb-9988-8925782f5bc8.png)\r\n",
      "![image](https://user-images.githubusercontent.com/75870530/109180849-4cc2d900-77c6-11eb-83a7-0c35caad603b.png)\r\n",
      "![image](https://user-images.githubusercontent.com/75870530/109180894-54827d80-77c6-11eb-9629-c21b75c8b590.png)\r\n",
      "\r\n",
      "Please help me\r\n",
      "Thanks All!\n",
      "issue labels - \n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Compile TensorFlow Lite for iOS Simulator on Apple Silicon\n",
      "issue body -  TensorFlowLite isn't available for iOS Simulator running on Apple Silicon.\r\n",
      "\r\n",
      "It seems that this depends on [Bazel supporting this](https://github.com/bazelbuild/rules_apple/issues/980), as well as on TensorFlowLite being built as a .xcframework (fat frameworks have an arm64 slice, but cannot have an arm64-mac slice).\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "comp:lite\n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  Unable to build TFLite for Microcontrollers on Mac OS \n",
      "issue body -  @tensorflow/micro\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac OS Mojave (version: 10.14.6)\r\n",
      "- TensorFlow installed from (source or binary): from source \r\n",
      "- Tensorflow version (commit SHA if source):\r\n",
      "- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): zephyr_vexriscv (from [this tutorial](https://blog.tensorflow.org/2020/06/running-and-testing-tf-lite-on-microcontrollers.html)\r\n",
      "\r\n",
      "**Describe the problem**\r\n",
      "I have created my own test project base on [this tutorial](https://blog.tensorflow.org/2020/06/running-and-testing-tf-lite-on-microcontrollers.html), but when I build it using the following command: \r\n",
      "**make -f tensorflow/lite/micro/tools/make/Makefile TARGET=\"zephyr_vexriscv\" ruby1_bin**\r\n",
      " \r\n",
      "I have got this error message:\r\n",
      "tensorflow/lite/micro/tools/make/Makefile:417: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\n",
      "tensorflow/lite/micro/tools/make/Makefile:417: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\n",
      "g++ -std=c++11 -fno-rtti -fno-exceptions -fno-threadsafe-statics -fno-unwind-tables -ffunction-sections -fdata-sections -fmessage-length=0 -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -O3 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wswitch -Wvla -Wall -Wextra -Wstrict-aliasing -Wno-unused-parameter  -I. -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/kissfft -o tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/bin/ruby1 tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/obj/tensorflow/lite/micro/examples/ruby1/main.o tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/obj/tensorflow/lite/micro/examples/ruby1/model_28.o tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/lib/libtensorflow-microlite.a  -lm\r\n",
      "Undefined symbols for architecture x86_64:\r\n",
      "  \"_stbi_load\", referenced from:\r\n",
      "      _main in main.o\r\n",
      "ld: symbol(s) not found for architecture x86_64\r\n",
      "clang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n",
      "make: *** [tensorflow/lite/micro/examples//ruby1/Makefile.inc:13: tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/bin/ruby1] Error 1\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "comp:lite\n",
      "comp:micro\n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  [XLA:GPU] Updated hlo_to_llvm_ir to also emit PTX and re-enable tests using it.\n",
      "issue body -  @sanjoy \n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:xla\n",
      "size:L\n",
      "\n",
      "\n",
      "issue title -  Add missing closing backtick\n",
      "issue body -  \n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  BestExporter exports worse model when training tasks restart.\n",
      "issue body -  BestExporter is widely used in my company to avoid model degradation with time. But BestExporter exports worse model when training task restart.\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n",
      "- OS Platform and Distribution: Distributed training.\r\n",
      "- TensorFlow installed from (source or binary):binary.\r\n",
      "- TensorFlow version (use command below): All versions(TF1.14, TF1.15, TF2.x).\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "\r\n",
      "There are scenes for example we need to restart training tasks: \r\n",
      "\r\n",
      "1. continuous training(not online streaming training): Training with new data and check if its satisfies the best exporter condition.\r\n",
      "2. Failure restart: In local or distributed training, worker failure is common, thanks to the checkpoint, we can restart failed task.\r\n",
      "\r\n",
      "For example, old best AUC is 0.85, but when we restart training task,  [self._has_exported](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/exporter.py#L295) in BestExporter is False, and TF will export new saved model ignoring whether current eval_result(for example AUC=0.79) is better than best_result(AUC=0.80)  loaded from event files created by last running task or not. And next all eval_results(for example AUC=0.80, AUC=0.81) are worse than old AUC=0.85 unfortunately which means all newer saved_models are worse than old one and may cause worse online business metrics.\r\n",
      "\r\n",
      "This bug was imported in [issue](https://github.com/tensorflow/estimator/pull/41)  and  [this commit](https://github.com/tensorflow/estimator/commit/43921b4552d1c30acc31d3b5989112cb397383e0#diff-5e0426432b8f40323ca256ef0d11b27ec3a7b4cc9d4042d228b17d0b13d73cfb).\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "\r\n",
      "Export REAL best model.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "\r\n",
      "Has been proved in production environment.\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "stat:awaiting response\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  EagerTensor implements `__len__` but not `len()`.\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux merry 5.8.0-43-generic #49~20.04.1-Ubuntu SMP Fri Feb 5 09:57:56 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux`\r\n",
      "- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n",
      "- TensorFlow version (use command below): `v2.4.0-49-g85c8b2a817f 2.4.1`\r\n",
      "- Python version: `3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0]`\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "The EagerTensor implements `__len__` but does not provide the `len(.)` function.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "If `__len__` is a attribute, the `len(.)` function should work.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "```\r\n",
      "import tensorflow as tf\r\n",
      "import numpy as np\r\n",
      "import sys\r\n",
      "\r\n",
      "print(tf.version.GIT_VERSION, tf.version.VERSION) # v2.4.0-49-g85c8b2a817f 2.4.1\r\n",
      "print(sys.version) # 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0]\r\n",
      "x = np.dtype('float32').type(3.0)\r\n",
      "\r\n",
      "sigmoid = tf.keras.layers.Activation(activation=\"sigmoid\")\r\n",
      "actX = sigmoid(x)\r\n",
      "\r\n",
      "print(type(x)) # <class 'numpy.float32'>\r\n",
      "print(type(actX)) # <class 'tensorflow.python.framework.ops.EagerTensor'>\r\n",
      "\r\n",
      "if hasattr(actX, \"__len__\"):\r\n",
      "    print(len(actX))\r\n",
      "else:\r\n",
      "    print(\"Has no length\")\r\n",
      "```\r\n",
      "yield the following error:\r\n",
      "```\r\n",
      "---------------------------------------------------------------------------\r\n",
      "TypeError                                 Traceback (most recent call last)\r\n",
      "<ipython-input-5-a34ef039f8c4> in <module>\r\n",
      "      9 \r\n",
      "     10 if hasattr(actX, \"__len__\"):\r\n",
      "---> 11     print(len(actX))\r\n",
      "     12 else:\r\n",
      "     13     print(\"Has no length\")\r\n",
      "\r\n",
      "~/Projects/NotebooksEnvs/py38Env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __len__(self)\r\n",
      "   1020     \"\"\"Returns the length of the first dimension in the Tensor.\"\"\"\r\n",
      "   1021     if not self.shape.ndims:\r\n",
      "-> 1022       raise TypeError(\"Scalar tensor has no `len()`\")\r\n",
      "   1023     # pylint: disable=protected-access\r\n",
      "   1024     try:\r\n",
      "\r\n",
      "TypeError: Scalar tensor has no `len()`\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "stat:awaiting tensorflower\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Did not open image after detecting object using tensorflow2\n",
      "issue body -  I am learning object [detetction with tensorflow2](https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model) and my model trained successfully.\r\n",
      "\r\n",
      "But whenever I trying to [Test trained model on test images](https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb#scrollTo=5tGVwzpLxvSv) in my _VScode_, image doesn't open.\r\n",
      "\r\n",
      "### Here is my code:\r\n",
      "\r\n",
      "```\r\n",
      "import io\r\n",
      "import os\r\n",
      "import cv2\r\n",
      "import scipy.misc\r\n",
      "import numpy as np\r\n",
      "import six\r\n",
      "import time\r\n",
      "import glob\r\n",
      "from IPython.display import display\r\n",
      "\r\n",
      "from six import BytesIO\r\n",
      "\r\n",
      "import matplotlib\r\n",
      "import matplotlib.pyplot as plt\r\n",
      "from PIL import Image, ImageDraw, ImageFont\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "from object_detection.utils import ops as utils_ops\r\n",
      "from object_detection.utils import label_map_util\r\n",
      "from object_detection.utils import visualization_utils as vis_util\r\n",
      "\r\n",
      "def load_image_into_numpy_array(path):\r\n",
      "  \"\"\"Load an image from file into a numpy array.\r\n",
      "\r\n",
      "  Puts image into numpy array to feed into tensorflow graph.\r\n",
      "  Note that by convention we put it into a numpy array with shape\r\n",
      "  (height, width, channels), where channels=3 for RGB.\r\n",
      "\r\n",
      "  Args:\r\n",
      "    path: a file path (this can be local or on colossus)\r\n",
      "\r\n",
      "  Returns:\r\n",
      "    uint8 numpy array with shape (img_height, img_width, 3)\r\n",
      "  \"\"\"\r\n",
      "  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n",
      "  image = Image.open(BytesIO(img_data))\r\n",
      "  (im_width, im_height) = image.size\r\n",
      "  return np.array(image.getdata()).reshape(\r\n",
      "      (im_height, im_width, 3)).astype(np.uint8)\r\n",
      "\r\n",
      "category_index = label_map_util.create_category_index_from_labelmap('training/label_map.pbtxt', use_display_name=True)\r\n",
      "\r\n",
      "tf.keras.backend.clear_session()\r\n",
      "model = tf.saved_model.load(f'inference_graph/saved_model')\r\n",
      "\r\n",
      "def run_inference_for_single_image(model, image):\r\n",
      "  image = np.asarray(image)\r\n",
      "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n",
      "  input_tensor = tf.convert_to_tensor(image)\r\n",
      "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n",
      "  input_tensor = input_tensor[tf.newaxis,...]\r\n",
      "\r\n",
      "  # Run inference\r\n",
      "  model_fn = model.signatures['serving_default']\r\n",
      "  output_dict = model_fn(input_tensor)\r\n",
      "\r\n",
      "  # All outputs are batches tensors.\r\n",
      "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n",
      "  # We're only interested in the first num_detections.\r\n",
      "  num_detections = int(output_dict.pop('num_detections'))\r\n",
      "  output_dict = {key:value[0, :num_detections].numpy() \r\n",
      "                 for key,value in output_dict.items()}\r\n",
      "  output_dict['num_detections'] = num_detections\r\n",
      "\r\n",
      "  # detection_classes should be ints.\r\n",
      "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\r\n",
      "   \r\n",
      "  # Handle models with masks:\r\n",
      "  if 'detection_masks' in output_dict:\r\n",
      "    # Reframe the the bbox mask to the image size.\r\n",
      "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n",
      "              output_dict['detection_masks'], output_dict['detection_boxes'],\r\n",
      "               image.shape[0], image.shape[1])      \r\n",
      "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\r\n",
      "                                       tf.uint8)\r\n",
      "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\r\n",
      "    \r\n",
      "  return output_dict\r\n",
      "  \r\n",
      "for image_path in glob.glob('images/test/*.jpg'):\r\n",
      "  image_np = load_image_into_numpy_array(image_path)\r\n",
      "  output_dict = run_inference_for_single_image(model, image_np)\r\n",
      "  vis_util.visualize_boxes_and_labels_on_image_array(\r\n",
      "      image_np,\r\n",
      "      output_dict['detection_boxes'],\r\n",
      "      output_dict['detection_classes'],\r\n",
      "      output_dict['detection_scores'],\r\n",
      "      category_index,\r\n",
      "      instance_masks=output_dict.get('detection_masks_reframed', None),\r\n",
      "      use_normalized_coordinates=True,\r\n",
      "      line_thickness=8)\r\n",
      "  display(Image.fromarray(image_np))\r\n",
      "```\r\n",
      "\r\n",
      "### After run the python file I got below output in cmd:\r\n",
      "\r\n",
      "> <PIL.Image.Image image mode=RGB size=500x625 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=242x239 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=238x238 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=489x368 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=433x358 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=486x486 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=492x487 at 0x2090689B040>\r\n",
      "> <PIL.Image.Image image mode=RGB size=155x357 at 0x2090689B040>\r\n",
      "\r\n",
      "**_I didn't get expected output which is shown [here](https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb#scrollTo=EEX-m3P1yp4y&line=5&uniqifier=1)._** Please help me to solve this.\n",
      "issue labels - \n",
      "\n",
      "\n",
      "issue title -  tf.errors.UnknownError should include __cause__\n",
      "issue body -  **System information**\r\n",
      "- TensorFlow version (you are using): 2.4.1\r\n",
      "- Are you willing to contribute it (Yes/No): No\r\n",
      "\r\n",
      "**Describe the feature and the current behavior/state.**\r\n",
      "\r\n",
      "When a [`tf.errors.UnknownError`](https://www.tensorflow.org/api_docs/python/tf/errors/UnknownError) is raised, the `exception.__cause__` is not set (it is `None`), so if someone wants to find the underlying error, the best they can do is trying to infer it through the `exception.message` attribute, which is suboptimal at best.\r\n",
      "\r\n",
      "`exception.__cause__` should be set to the chained exception when known. See https://docs.python.org/3/library/exceptions.html.\r\n",
      "\r\n",
      "**Will this change the current api? How?**\r\n",
      "\r\n",
      "It will change the `tf.errors.UnknownError` behaviour to include more information.\r\n",
      "\r\n",
      "**Who will benefit with this feature?**\r\n",
      "\r\n",
      "Everyone who wants more control over `UnknownError`. For example, it is currently not possible for me to detect that the `UnknownError` is caused due to a `PIL.UnidentifiedImageError` unless I find the string in the `message`.\r\n",
      "\r\n",
      "**Any Other info.**\r\n",
      "\r\n",
      "Code causing the `UnknownError` that prompted the request:\r\n",
      "\r\n",
      "```python\r\n",
      "def my_generator(img):\r\n",
      "    img = Image.open(io.BytesIO(img))  # <- here's the `PIL.UnidentifiedImageError`\r\n",
      "    img = tf.image.convert_image_dtype(img, tf.float32)\r\n",
      "    yield img, tf.constant([[]], dtype=tf.float32), tf.constant([], dtype=tf.int32)\r\n",
      "\r\n",
      "ds = tf.data.Dataset.from_generator(lambda: my_generator((image_bytes))\r\n",
      "# ...trying to use ds...\r\n",
      "```\r\n",
      "\n",
      "issue labels - \n",
      "comp:apis\n",
      "stat:awaiting tensorflower\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  TypeError: tensor_equals() missing 1 required positional argument: 'other'\n",
      "issue body -  \r\n",
      "![image](https://user-images.githubusercontent.com/18486587/109113616-895ce900-7762-11eb-9882-5f86a866d871.png)\r\n",
      "\r\n",
      "On loading the saved model, it gives an error. \r\n",
      "Tensorflow version is 2.4.1\r\n",
      "[Notebook to reproduce it. ](https://colab.research.google.com/drive/1w5QAIeG6rUpSWUbHEJJjNLfp1FYzCwff?usp=sharing)\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Libcudnn Major Version Variable attached\n",
      "issue body -  The libcudnn Major Version was not used in for getting the Packages with apt-get\n",
      "issue labels - \n",
      "cla: yes\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  [XLA:GPU] Build failure\n",
      "issue body -  This commit:\r\n",
      "\r\n",
      "```\r\n",
      "commit 9f8d5d0ef4e990ab2398d573a14aaa8ed02a10e2\r\n",
      "Author: Rahul Joshi <jurahul@google.com>\r\n",
      "Date:   Mon Feb 22 08:41:59 2021 -0800\r\n",
      "\r\n",
      "    [MLIR:LHLO] Add optional call target arg mapping to LMHLO CustomCall operations.\r\n",
      "\r\n",
      "    - XLA:HLO -> LMHLO conversion drops all token arguments and return values, however\r\n",
      "      custom calls that users write still expect to get buffer pointers for these token types.\r\n",
      "    - To be able to support this, add an optional call target argument mapping attribute to\r\n",
      "      LMHLO custom calls. When this attribute is present, it indicates the number of\r\n",
      "      arguments and returns that the custom call expects and also indicates which LMHLO\r\n",
      "      arg() or output() maps to which arg or result number of the custom call.\r\n",
      "\r\n",
      "    PiperOrigin-RevId: 358826664\r\n",
      "    Change-Id: I36e839e9ff5b73890715b71717a4c13631955fba\r\n",
      "```\r\n",
      "\r\n",
      "Introduced a compilation regression. Before that commit, this command line works:\r\n",
      "\r\n",
      "```\r\n",
      "bazel test -c opt --config=cuda //tensorflow/compiler/xla/tests:conv_depthwise_test_gpu //tensorflow/compiler/xla/tests:grouped_convolution_test_gpu\r\n",
      "```\r\n",
      "\r\n",
      "Starting at this commit, it gives this error:\r\n",
      "```\r\n",
      "ERROR: /home/fbastien/github/tensorflow-tf2-upstream2/tensorflow/compiler/mlir/hlo/BUILD:485:11: undeclared inclusion(s) in rule '//tensorflow/compiler/mlir/hlo:lhlo':\r\n",
      "this rule is missing dependency declarations for the following files included by 'tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/IR/lhlo_ops_structs.cc':\r\n",
      "  'bazel-out/k8-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen/mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc'\r\n",
      "  'bazel-out/k8-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen/mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.cc.inc'\r\n",
      "cc1plus: warning: command line option ‘-Wno-pointer-sign’ is valid for C/ObjC but not for C++\r\n",
      "```\r\n",
      "\r\n",
      "@jurahul that authored it.\n",
      "issue labels - \n",
      "\n",
      "\n",
      "issue title -  Port micro op EXPAND_DIMS for it to pass the tests\n",
      "issue body -  PR4 for Issue #46258. Please review this PR carefully. Several notes about the implementation:\r\n",
      "1. Only constant tensors are supported; dynamic ones are not. This is different from the TFLite counterpart, which supports both.\r\n",
      "2. For constant tensors, the TFLite op calls GetAxisValueFromTensor() and ExpandTensorDim() in the Prepare function. The TFLM op does not call either of them in Prepare, but in the Eval function.\r\n",
      "3. The code to check the output tensor's shape starts at line 57, lite/micro/kernels/expand_dims_test.cc.\r\n",
      "4. The output_dims used to configure the output tensor must have the right dimension number.\r\n",
      "\n",
      "issue labels - \n",
      "awaiting review\n",
      "cla: yes\n",
      "comp:micro\n",
      "size:L\n",
      "\n",
      "\n",
      "issue title -  ModifyGraphWithDelegate(delegate) running very slow (ubuntu with USB accelerator)\n",
      "issue body -  Hi, \r\n",
      "I wrote a minimal C++ code loading the mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite\r\n",
      "and doing some inferencing.\r\n",
      "When running on a ubuntu-16.04 notebook (i7, SSD, 12G) with USB accelerator,\r\n",
      "interpreter_->ModifyGraphWithDelegate\r\n",
      "runs substantially (50x) slower than the same(see below) code on the dev-board.\r\n",
      "\r\n",
      "Dev-board:\r\n",
      "Code line: interpreter_->ModifyGraphWithDelegate({delegate, edgetpu_free_delegate});\r\n",
      "libedgetpu version: libedgetpu1-std:arm64                14.1\r\n",
      "run time: 0.07sec (incl. loading network etc)\r\n",
      "\r\n",
      "Ubuntu 16.04, \r\n",
      "Code line: interpreter_->ModifyGraphWithDelegate(delegate);\r\n",
      "[ the version above with the 2 delegates can't be compiled]\r\n",
      "libedgetpu: libedgetpu1-max/coral-edgetpu-stable,now 15.0 amd64 [installed]\r\n",
      "TENSORFLOW: tensorflow_src cloned today and built tflite library\r\n",
      "runtime:  3.2sec (!)\r\n",
      "\r\n",
      "After that, the inference is running about only half as fast as on the devboard. \r\n",
      "(slower USB speed??? or problem with the delegate?)\r\n",
      "\r\n",
      "Code snippet:\r\n",
      " std::unique_ptr<tflite::FlatBufferModel> model;\r\n",
      "  model = tflite::FlatBufferModel::BuildFromFile(model_path.c_str());\r\n",
      "\r\n",
      "  tflite::ops::builtin::BuiltinOpResolver resolver;\r\n",
      "  tflite::InterpreterBuilder(*model, resolver)(&interpreter_);\r\n",
      "\r\n",
      "  size_t num_devices;\r\n",
      "  std::unique_ptr<edgetpu_device, decltype(&edgetpu_free_devices)> devices(\r\n",
      "      edgetpu_list_devices(&num_devices), &edgetpu_free_devices);\r\n",
      "  TFLITE_MINIMAL_CHECK(num_devices);\r\n",
      "  const auto& device = devices.get()[0];\r\n",
      "  auto* delegate = edgetpu_create_delegate(device.type, device.path, nullptr, 0);\r\n",
      "  ON DEVBOARD:  interpreter_->ModifyGraphWithDelegate({delegate, edgetpu_free_delegate});\r\n",
      "  ON UBUNTU/USB: interpreter_->ModifyGraphWithDelegate(delegate);\r\n",
      "\r\n",
      "Thank you!\r\n",
      "-johann\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "comp:lite\n",
      "comp:runtime\n",
      "type:performance\n",
      "\n",
      "\n",
      "issue title -  Generating the descriptors of constant shape\n",
      "issue body -  The local features generated by tensorflowv1 is different from tensorflowv2.5\r\n",
      "\r\n",
      "```\r\n",
      "def generate_vectors(paths):\r\n",
      "    \r\n",
      "    ops.reset_default_graph()\r\n",
      "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.FATAL)\r\n",
      "\r\n",
      "    model = hub.Module('https://tfhub.dev/google/delf/1')\r\n",
      "\r\n",
      "    image_placeholder = tf.compat.v1.placeholder(tf.float32, shape=(None, None, 3), name='input_image')\r\n",
      "\r\n",
      "    module_inputs = {\r\n",
      "        'image': image_placeholder,\r\n",
      "        'score_threshold': 100.0,\r\n",
      "        'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\r\n",
      "        'max_feature_num': 1000,\r\n",
      "    }\r\n",
      "\r\n",
      "    module_outputs = model(module_inputs, as_dict=True)\r\n",
      "    image_tf = paths_to_image_loader(list(paths))\r\n",
      "    img_paths = []\r\n",
      "    with tf.compat.v1.train.MonitoredSession() as sess:\r\n",
      "        features = []\r\n",
      "\r\n",
      "        for i in tqdm(range(len(paths))):\r\n",
      "            image = sess.run(image_tf)\r\n",
      "            local_feature = sess.run([module_outputs['locations'], module_outputs['descriptors']],\r\n",
      "                                     feed_dict={image_placeholder: image})\r\n",
      "\r\n",
      "```\r\n",
      "\r\n",
      "The local_feature[1] and local_feature[0] has got a constant shape of 1000 with the above code that has the legacy cide,.\r\n",
      "\r\n",
      "I used the latest code to generate vectors as follow,\r\n",
      "\r\n",
      "```\r\n",
      "def run_delf(image):\r\n",
      "    np_image = np.array(image)\r\n",
      "    float_image = tf.image.convert_image_dtype(np_image, tf.float32)\r\n",
      "\r\n",
      "    return delf(\r\n",
      "        image=float_image,\r\n",
      "        score_threshold=tf.constant(100.0),\r\n",
      "        image_scales=tf.constant([0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0]),\r\n",
      "        max_feature_num=tf.constant(1000))\r\n",
      "```\r\n",
      "\r\n",
      "Unfortunately `result[\"locations\"].numpy()` and `result[\"descriptors\"].numpy()` always has got a different shapes for every image inputs while it is intended to have 1000 features. How can I fix it?\n",
      "issue labels - \n",
      "TF 2.5\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Fixed docstring formatting for api_docs\n",
      "issue body -  The api_docs website formatting of [leaky_relu](https://www.tensorflow.org/api_docs/python/tf/nn/leaky_relu) was wrong due to a missing newline\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:ops\n",
      "ready to pull\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  tf_upgrade_v2: UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 385: character maps to <undefined>\n",
      "issue body -  **System information**\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n",
      "- TensorFlow installed from (source or binary): pip\r\n",
      "- TensorFlow version (use command below): 2.4.0\r\n",
      "- Python version: 3.6.1\r\n",
      "- CUDA/cuDNN version: 11.1\r\n",
      "- GPU model and memory: RTX3070 8GB\r\n",
      "\r\n",
      "I tried to update my project with script tf_upgrade_v2 and command:\r\n",
      "```\r\n",
      "tf_upgrade_v2  --intree D:\\Work\\in_dir --outtree D:\\Work\\out_dir --reportfile D:\\Work\\report.txt --print_all\r\n",
      "```\r\n",
      "but I get error:\r\n",
      "```\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"c:\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"c:\\python36\\lib\\runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"C:\\python36\\Scripts\\tf_upgrade_v2.exe\\__main__.py\", line 7, in <module>\r\n",
      "  File \"c:\\python36\\lib\\site-packages\\tensorflow\\tools\\compatibility\\tf_upgrade_v2_main.py\", line 178, in main\r\n",
      "    args.input_tree, output_tree, args.copy_other_files)\r\n",
      "  File \"c:\\python36\\lib\\site-packages\\tensorflow\\tools\\compatibility\\ast_edits.py\", line 1076, in process_tree\r\n",
      "    _, l_report, l_errors = self.process_file(input_path, output_path)\r\n",
      "  File \"c:\\python36\\lib\\site-packages\\tensorflow\\tools\\compatibility\\ast_edits.py\", line 921, in process_file\r\n",
      "    temp_file)\r\n",
      "  File \"c:\\python36\\lib\\site-packages\\tensorflow\\tools\\compatibility\\ast_edits.py\", line 982, in process_opened_file\r\n",
      "    lines = in_file.readlines()\r\n",
      "  File \"c:\\python36\\lib\\encodings\\cp1250.py\", line 23, in decode\r\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\r\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 385: character maps to <undefined>\r\n",
      "```\r\n",
      "\r\n",
      "How to check which file in my project is troublesome?\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "stat:awaiting response\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  True loss values\n",
      "issue body -  <em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n",
      "\r\n",
      "\r\n",
      "**System information**\r\n",
      "- TensorFlow version (you are using): 1.15.3 and 2.4.0\r\n",
      "- Are you willing to contribute it (Yes/No): Yes\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the feature and the current behavior/state.**\r\n",
      "The log loss values of the training dataset recorded during model fitting are not the actual loss values obtained when evaluating the resulting model. I explain this througly in https://github.com/sparklingdew/keras_loss_discrepancy.\r\n",
      "\r\n",
      "**Will this change the current api? How?**\r\n",
      "The only change that I suggest is to give the actual loss value for the training dataset, rather than this other internal value which is difficult to understand. It should be calculated similarly to the validation loss, which is obtained from evaluating the resulting model. I understand that this may go in detriment to running time. In that case, this new feature could be optional.\r\n",
      "\r\n",
      "**Who will benefit with this feature?**\r\n",
      "NN users will be benefitted, since model tunning is performed based on loss and accuaracy results. If these values are misleading, the models are difficult to tune.\r\n",
      "\r\n",
      "**Any Other info.**\r\n",
      "Many thanks for your time!\n",
      "issue labels - \n",
      "comp:keras\n",
      "stat:awaiting tensorflower\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  Tensorflow is ignoring `tf.config.set_soft_device_placement(True)`\n",
      "issue body -  <em>Please make sure that this is a bug. As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:bug_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (GPU)\r\n",
      "- TensorFlow installed from (source or binary): Google Colab (GPU)\r\n",
      "- TensorFlow version (use command below): 2.4.1\r\n",
      "- Python version: 3.7.10\r\n",
      "- CUDA/cuDNN version: Google Colab (GPU)\r\n",
      "- GPU model and memory: Google Colab (GPU)\r\n",
      "\r\n",
      "You can collect some of this information using our environment capture\r\n",
      "[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n",
      "You can also obtain the TensorFlow version with:\r\n",
      "\r\n",
      "**Describe the current behaviour**\r\n",
      "\r\n",
      "I'm training a neural network with embedding layer using GPU-distributed strategy (TF's MirroredStrategy), and I'm getting the following error:\r\n",
      "\r\n",
      "```\r\n",
      "Colocation Debug Info:\r\n",
      "Colocation group had the following types and supported devices: \r\n",
      "Root Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\r\n",
      "GatherV2: GPU CPU \r\n",
      "Cast: GPU CPU \r\n",
      "Const: GPU CPU \r\n",
      "ResourceSparseApplyAdagradV2: CPU \r\n",
      "_Arg: GPU CPU \r\n",
      "ReadVariableOp: GPU CPU \r\n",
      "\r\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\r\n",
      "  model_6_user_embedding_embedding_lookup_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n",
      "  adagrad_adagrad_update_1_update_0_resourcesparseapplyadagradv2_accum (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n",
      "  model_6/User-Embedding/embedding_lookup/ReadVariableOp (ReadVariableOp) \r\n",
      "  model_6/User-Embedding/embedding_lookup/axis (Const) \r\n",
      "  model_6/User-Embedding/embedding_lookup (GatherV2) \r\n",
      "  gradient_tape/model_6/User-Embedding/embedding_lookup/Shape (Const) \r\n",
      "  gradient_tape/model_6/User-Embedding/embedding_lookup/Cast (Cast) \r\n",
      "  Adagrad/Adagrad/update_1/update_0/ResourceSparseApplyAdagradV2 (ResourceSparseApplyAdagradV2) /job:localhost/replica:0/task:0/device:GPU:0\r\n",
      "\r\n",
      "     [[{{node model_6/User-Embedding/embedding_lookup/ReadVariableOp}}]] [Op:__inference_train_function_2997]\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "From the error log, it looks like the embedding_lookup/ReadVariableOp is not GPU compatible - which I can understand why. \r\n",
      "\r\n",
      "But I've set `tf.config.set_soft_device_placement(True)` so I'm expecting TF to use CPU for CPU only operations, and that doesn't seemed to have worked. Is TF ignoring that config setting? Or does that setting doesn't yet support some other conditions? \r\n",
      "\r\n",
      "\r\n",
      "**Describe the expected behaviour**\r\n",
      "\r\n",
      "I'd expect MirroredStrategy to default to CPU for CPU only computations by setting `tf.config.set_soft_device_placement(True)` but that doesn't seem to be happening.\r\n",
      "\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "Provide a reproducible test case that is the bare minimum necessary to generate\r\n",
      "the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n",
      "\r\n",
      "\r\n",
      "Link to Google Colab notebook:\r\n",
      "https://colab.research.google.com/drive/1ZN1HzSTTfvA_zstuI-EsKjw7Max1f73v?usp=sharing\r\n",
      "\r\n",
      "Dataset can be found on Kaggle:\r\n",
      "https://www.kaggle.com/zygmunt/goodbooks-10k\r\n",
      "\r\n",
      "\r\n",
      "**Other info / logs** Include any logs or source code that would be helpful to\r\n",
      "diagnose the problem. If including tracebacks, please include the full\r\n",
      "traceback. Large logs and files should be attached.\r\n",
      "\r\n",
      "Full log can be seen on Google Colab by downloading the dataset from kaggle, uploading to google colab, and running the code on GPU. The neural network is really small -takes less than 5 seconds to execute the whole notebook.\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:gpu\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Add a status badge for Arduino examples\n",
      "issue body -  This PR adds a status badge to TFLite Micro Readme.\r\n",
      "\r\n",
      "The graphic style is slightly different to the current badges, but it's auto-generated by GitHub, so it requires no additional handling on the CI side.\r\n",
      "\r\n",
      "cc @advaitjain \n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:micro\n",
      "ready to pull\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  metrics values don't match between custom metric function and model.fit callbacks\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n",
      "- TensorFlow installed from (source or binary): Google Colab default installed\r\n",
      "- TensorFlow version (use command below): 2.4.1\r\n",
      "- Python version: 3.7.10\r\n",
      "- Bazel version (if compiling from source):\r\n",
      "- GCC/Compiler version (if compiling from source):\r\n",
      "- CUDA/cuDNN version:\r\n",
      "- GPU model and memory:\r\n",
      "\r\n",
      "**Describe the current behavior**  \r\n",
      "returned metrics value from custom metrics functions and callback printed metrics from model.fit doesn't match.\r\n",
      "\r\n",
      "**Describe the expected behavior**  \r\n",
      "returned metrics value from custom metrics functions and callback printed metrics from model.fit match.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**  \r\n",
      "[Google Colab gist](https://gist.github.com/asterisk37n/9e8c492fc7f01a9f37f9d5fb33ee3406)\r\n",
      "\r\n",
      "**Other info / logs**  \r\n",
      "I opened a quesiton on stackoverflow.  \r\n",
      "[https://stackoverflow.com/questions/66311611/when-and-how-keras-calculate-metrics-for-each-batch-of-samples](https://stackoverflow.com/questions/66311611/when-and-how-keras-calculate-metrics-for-each-batch-of-samples)\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Getting ERROR: Could not find a version that satisfies the requirement tensorflow==2.4.1\n",
      "issue body -  <em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n",
      "- MacBook pro\r\n",
      "- processor: 2GHz Quad-Core Intel Core i5,  \r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n",
      "- TensorFlow installed from (source or binary):\r\n",
      "- TensorFlow version:\r\n",
      "- Python version:\r\n",
      "- Installed using virtualenv? pip? conda?:\r\n",
      "- Bazel version (if compiling from source):\r\n",
      "- GCC/Compiler version (if compiling from source):\r\n",
      "- CUDA/cuDNN version:\r\n",
      "- GPU model and memory:\r\n",
      "\r\n",
      "I'm successfully able to install 1.8.0, \r\n",
      "getting below error with all available wheel from mac os, supported wheel for my mac is cp39, which is not avilable. \r\n",
      "tensorflow-2.4.1-cp36-cp36m-macosx_10_11_x86_64.whl is not a supported wheel on this platform.\r\n",
      "\r\n",
      "\r\n",
      "**Describe the problem**\r\n",
      "\r\n",
      "**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n",
      "\r\n",
      "\r\n",
      "**Any other info / logs**\r\n",
      "Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "stat:awaiting response\n",
      "subtype:macOS\n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  Any suggestion to use tensorflow feasibly?\n",
      "issue body -  I am currently doing a research while it is based on a project written with Tensorflow. While I could not implement the dynamic time wrapping easily since it is a dynamic method. With pytorch I could implement it very quickly (since pytorch supports dynamic graph). \r\n",
      "\r\n",
      "Could anyone help me choose the correct version and documents of Tensorflow that supports dynamic graph? I checked on Tensorflow official website while the document is kind of messy. \n",
      "issue labels - \n",
      "stat:awaiting response\n",
      "type:others\n",
      "\n",
      "\n",
      "issue title -  Ampere bfloat16 support\n",
      "issue body -  <em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n",
      "\r\n",
      "\r\n",
      "**System information**\r\n",
      "- TensorFlow version (you are using): 2.4.1/built from head\r\n",
      "- Are you willing to contribute it (Yes/No): If you point me at the necessary code, I'll take a crack at it.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the feature and the current behavior/state.**\r\n",
      "I attempted to use bfloat16 training by setting:\r\n",
      "\r\n",
      "```\r\n",
      "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\r\n",
      "```\r\n",
      "\r\n",
      "I got this error message:\r\n",
      "\r\n",
      "```\r\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'Conv2D' used by {{node model/conv2d/Conv2D}} with these attrs: [dilations=[1, 1, 1, 1], T=DT_BFLOAT16, data_format=\"NHWC\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, explicit_paddings=[], padding=\"SAME\"]\r\n",
      "Registered devices: [CPU, GPU]\r\n",
      "Registered kernels:\r\n",
      "  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\r\n",
      "  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]\r\n",
      "  device='GPU'; T in [DT_INT32]\r\n",
      "  device='GPU'; T in [DT_DOUBLE]\r\n",
      "  device='GPU'; T in [DT_FLOAT]\r\n",
      "  device='GPU'; T in [DT_HALF]\r\n",
      "  device='CPU'; T in [DT_INT32]\r\n",
      "  device='CPU'; T in [DT_DOUBLE]\r\n",
      "  device='CPU'; T in [DT_FLOAT]\r\n",
      "  device='CPU'; T in [DT_HALF]\r\n",
      "```\r\n",
      "\r\n",
      "I read the [cuDNN release notes](https://docs.nvidia.com/deeplearning/cudnn/release-notes/rel_8.html#rel-810) which said that support for bfloat16 came with cuDNN version 8.1, so I built tensorflow from scratch, using CUDA 11.2 and cuDNN 8.1.0.77.\r\n",
      "\r\n",
      "However, I got the same error message.  I've tried this on a trival example (the fashion mnist tutorial) with the same result, so it's not some advanced kernel that I'm using in my code.\r\n",
      "\r\n",
      "I am a little confused that I'm getting this error message even when running with XLA, since the error message says that XLA_GPU_JIT supports DT_BFLOAT16.\r\n",
      "\r\n",
      "\r\n",
      "**Will this change the current api? How?**\r\n",
      "No, you can already specify a bfloat16 mixed precision policy.\r\n",
      "**Who will benefit with this feature?**\r\n",
      "Anyone with Ampere gpus who wants the speed of 16 bit floats and the numerical stability of bfloat16.\r\n",
      "\n",
      "issue labels - \n",
      "comp:gpu\n",
      "comp:keras\n",
      "stat:awaiting tensorflower\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  Support tf.IsFinite lowering\n",
      "issue body -  ### 1. System information\r\n",
      "\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n",
      "- TensorFlow installation (pip package or built from source): pip\r\n",
      "- TensorFlow library (version, if pip package or github SHA, if built from source): nightly\r\n",
      "\r\n",
      "### 2. Code\r\n",
      "\r\n",
      "```python\r\n",
      "import tensorflow as tf\r\n",
      "\r\n",
      "@tf.function\r\n",
      "def func(x):\r\n",
      "  return tf.is_finite(x)\r\n",
      "\r\n",
      "converter = tf.lite.TFLiteConverter.from_concrete_functions([func.get_concrete_function(tf.TensorSpec(shape=(1, 2, 3)))])\r\n",
      "converter.convert()\r\n",
      "```\r\n",
      "\r\n",
      "### 3. Failure after conversion\r\n",
      "\r\n",
      "It will fail if flex is not enabled. However, `tf.is_inf()` is supported without flex because it is lowered to other ops in `lower_tf.cc`. It should be easy to support lowering pattern of `tf.is_finite`. Note that `tf.is_finite` is also being used in `tf.keras.layers.Softmax` with multi-axes reduction. I understand that I can enable flex to use it, but it should be a minimum work to lower it directly.\r\n",
      "\r\n",
      "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/advanced_activations.py#L328-L345\n",
      "issue labels - \n",
      "TF 2.5\n",
      "TFLiteConverter\n",
      "comp:lite\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  The comparing with memory by 1080 ti and 3090\n",
      "issue body -  - Unet by tensorflow.keras (not include tf.compat.v1 code)\r\n",
      "- Both of these are ubuntu18\r\n",
      "- 2.4.0 (A computer) 2.0.0 (B computer)\r\n",
      "- Both of these are python 3.6.12\r\n",
      "- 11.1/8.0.5 (A computer) 10.0/7.6.5 (B computer)\r\n",
      "- 3090 24265MiB (A computer) 1080 ti 11178MiB (B computer)\r\n",
      "- Driver version 460.39\r\n",
      "\r\n",
      "### current behavior\r\n",
      "\r\n",
      "I ran the code using Unet to do segmentation project.\r\n",
      "I found the using of memory is very diffecent.\r\n",
      "It is the setting of model when I had trained the model:\r\n",
      "\r\n",
      "batch_size = 20\r\n",
      "epochs = 2\r\n",
      "\r\n",
      "When I had trained the model, I inspect the htop and nvidia-smi:\r\n",
      "\r\n",
      "The using resource by 3090 (A computer)\r\n",
      "cpu memory 4.4G -> 12G\r\n",
      "gpu memory 457MiB -> 18307MiB \r\n",
      "\r\n",
      "The using resource by 1080 ti: (B computer)\r\n",
      "cpu memory 0.79G  -> 3.4G\r\n",
      "gpu memory 0MiB -> 10867MiB\r\n",
      "\r\n",
      "### expected behavior\r\n",
      "\r\n",
      "I expected 3090(tf2.4) should be faster than 1080(tf2.0).\r\n",
      "\r\n",
      "Thank you to read this issue!\n",
      "issue labels - \n",
      "comp:gpu\n",
      "type:performance\n",
      "\n",
      "\n",
      "issue title -  tflite interpreter on android crashes on a model downloaded from tfhub\n",
      "issue body -  **System information**\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android\r\n",
      "- TensorFlow installed from (source or binary): maven build\r\n",
      "- TensorFlow version (or github SHA if from source): ``org.tensorflow:tensorflow-lite:2.4.0``\r\n",
      "\r\n",
      "\r\n",
      "**Provide the text output from tflite_convert**\r\n",
      "\r\n",
      "```\r\n",
      "# N/A - as the model is downloaded from tfhub\r\n",
      "```\r\n",
      "\r\n",
      "I am trying the simple style-transfer application using tflite. I am downloading the ``style-predict`` and ``style-transfer`` models from tfhub: https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/fp16/predict/1\r\n",
      "\r\n",
      "The problem is that when using the ``style transfer`` model, the app crashes with the following:\r\n",
      "\r\n",
      "```\r\n",
      "signal 6 (SIGABRT), code -1 (SI_QUEUE), fault addr --------\r\n",
      "Abort message: '/buildbot/src/android/ndk-release-r18/external/libcxx/../../external/libcxxabi/src/abort_message.cpp:73: abort_message: assertion \"terminating with uncaught exception of type std::bad_alloc: std::bad_alloc\" failed'\r\n",
      "    eax 00000000  ebx 00001e3b  ecx 00001e3b  edx 00000006\r\n",
      "    edi e83c333e  esi ff88e7f0\r\n",
      "    ebp ea340ad0  esp ff88e798  eip ea340ad9\r\n",
      "backtrace:\r\n",
      "      #00 pc 00000ad9  [vdso] (__kernel_vsyscall+9)\r\n",
      "      #01 pc 00092328  /apex/com.android.runtime/lib/bionic/libc.so (syscall+40) (BuildId: 76290498408016ad14f4b98c3ab6c65c)\r\n",
      "      #02 pc 000ad651  /apex/com.android.runtime/lib/bionic/libc.so (abort+193) (BuildId: 76290498408016ad14f4b98c3ab6c65c)\r\n",
      "      #03 pc 000adb88  /apex/com.android.runtime/lib/bionic/libc.so (__assert2+56) (BuildId: 76290498408016ad14f4b98c3ab6c65c)\r\n",
      "      #04 pc 002ba9a4  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #05 pc 002baab7  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #06 pc 002b82d9  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #07 pc 002b7c0e  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #08 pc 002b7b63  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #09 pc 002ba578  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #10 pc 000f7e76  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #11 pc 000fedd9  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #12 pc 000fd993  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #13 pc 000fc1e8  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #14 pc 000f1280  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #15 pc 000efe3b  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #16 pc 0012dfab  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #17 pc 0012c6a5  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #18 pc 000ee7d6  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #19 pc 0028acc0  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #20 pc 0028e326  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so\r\n",
      "      #21 pc 0004224f  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+63)\r\n",
      "      #22 pc 00144f67  /apex/com.android.runtime/lib/libart.so (art_quick_generic_jni_trampoline+71) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #23 pc 0013e9a2  /apex/com.android.runtime/lib/libart.so (art_quick_invoke_static_stub+418) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #24 pc 00149a7a  /apex/com.android.runtime/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+298) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #25 pc 00332502  /apex/com.android.runtime/lib/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+386) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #26 pc 0032c19c  /apex/com.android.runtime/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+988) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #27 pc 00684d03  /apex/com.android.runtime/lib/libart.so (MterpInvokeStatic+643) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #28 pc 001389a1  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_static+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #29 pc 00296a70  [anon:dalvik-classes.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk] (org.tensorflow.lite.NativeInterpreterWrapper.run+156)\r\n",
      "      #30 pc 00681adc  /apex/com.android.runtime/lib/libart.so (MterpInvokeVirtual+1612) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #31 pc 00138821  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_virtual+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #32 pc 0029603a  [anon:dalvik-classes.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk] (org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs+10)\r\n",
      "      #33 pc 00681adc  /apex/com.android.runtime/lib/libart.so (MterpInvokeVirtual+1612) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #34 pc 00138821  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_virtual+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #35 pc 00007b6e  [anon:dalvik-classes2.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk!classes2.dex] (com.companyName.mytflite_app.MainActivity.runTransform+102)\r\n",
      "      #36 pc 006845ac  /apex/com.android.runtime/lib/libart.so (MterpInvokeDirect+1324) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #37 pc 00138921  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_direct+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #38 pc 00007bc0  [anon:dalvik-classes2.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk!classes2.dex] (com.companyName.mytflite_app.MainActivity.StyleTransfer+16)\r\n",
      "      #39 pc 006845ac  /apex/com.android.runtime/lib/libart.so (MterpInvokeDirect+1324) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #40 pc 00138921  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_direct+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #41 pc 000080cc  [anon:dalvik-classes2.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk!classes2.dex] (com.companyName.mytflite_app.MainActivity.lambda$configureFlutterEngine$0$MainActivity+236)\r\n",
      "      #42 pc 00681adc  /apex/com.android.runtime/lib/libart.so (MterpInvokeVirtual+1612) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #43 pc 00138821  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_virtual+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #44 pc 00007944  [anon:dalvik-classes2.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk!classes2.dex] (com.companyName.mytflite_app.-$$Lambda$MainActivity$rQ-TPneqhLnrlPUSt3FsQ1A3iA8.onMethodCall+4)\r\n",
      "      #45 pc 006837bc  /apex/com.android.runtime/lib/libart.so (MterpInvokeInterface+1980) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #46 pc 00138a21  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_interface+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #47 pc 001fc346  [anon:dalvik-classes.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk] (io.flutter.plugin.common.MethodChannel$IncomingMethodCallHandler.onMessage+34)\r\n",
      "      #48 pc 006837bc  /apex/com.android.runtime/lib/libart.so (MterpInvokeInterface+1980) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #49 pc 00138a21  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_interface+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #50 pc 001f245a  [anon:dalvik-classes.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk] (io.flutter.embedding.engine.dart.DartMessenger.handleMessageFromDart+114)\r\n",
      "      #51 pc 006837bc  /apex/com.android.runtime/lib/libart.so (MterpInvokeInterface+1980) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #52 pc 00138a21  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_interface+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #53 pc 001f1128  [anon:dalvik-classes.dex extracted in memory from /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/base.apk] (io.flutter.embedding.engine.FlutterJNI.handlePlatformMessage+8)\r\n",
      "      #54 pc 002f8e0a  /apex/com.android.runtime/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEbb.llvm.12194892193087984976+298) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #55 pc 002ffcc5  /apex/com.android.runtime/lib/libart.so (art::interpreter::EnterInterpreterFromEntryPoint(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*)+181) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #56 pc 0066fbd9  /apex/com.android.runtime/lib/libart.so (artQuickToInterpreterBridge+1209) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #57 pc 0014503d  /apex/com.android.runtime/lib/libart.so (art_quick_to_interpreter_bridge+77) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #58 pc 0013e7d2  /apex/com.android.runtime/lib/libart.so (art_quick_invoke_stub+338) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #59 pc 00149a69  /apex/com.android.runtime/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+281) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #60 pc 0055a513  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+99) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #61 pc 0055bc7a  /apex/com.android.runtime/lib/libart.so (art::InvokeVirtualOrInterfaceWithVarArgs(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jmethodID*, char*)+474) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #62 pc 0040962f  /apex/com.android.runtime/lib/libart.so (art::JNI::CallVoidMethodV(_JNIEnv*, _jobject*, _jmethodID*, char*)+943) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #63 pc 003d8f44  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::CheckJNI::CallMethodV(char const*, _JNIEnv*, _jobject*, _jclass*, _jmethodID*, char*, art::Primitive::Type, art::InvokeType)+1700) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #64 pc 003c53f9  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::CheckJNI::CallVoidMethodV(_JNIEnv*, _jobject*, _jmethodID*, char*)+73) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #65 pc 0123628f  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #66 pc 012361c3  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #67 pc 0123073e  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #68 pc 012b14a3  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #69 pc 01255e05  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #70 pc 01258bf3  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #71 pc 01258b04  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #72 pc 0125f3fa  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #73 pc 0125f428  /data/app/com.companyName.mytflite_app-UCzFh7iFvc8i5Gni7pzrnA==/lib/x86/libflutter.so (BuildId: 8229a066e8159a187906d17af0b2738960128f78)\r\n",
      "      #74 pc 00018487  /system/lib/libutils.so (android::SimpleLooperCallback::handleEvent(int, int, void*)+39) (BuildId: 288ba3aff5b46dbd7e74be954af88b83)\r\n",
      "      #75 pc 00019414  /system/lib/libutils.so (android::Looper::pollInner(int)+1044) (BuildId: 288ba3aff5b46dbd7e74be954af88b83)\r\n",
      "      #76 pc 00018f4e  /system/lib/libutils.so (android::Looper::pollOnce(int, int*, int*, void**)+62) (BuildId: 288ba3aff5b46dbd7e74be954af88b83)\r\n",
      "      #77 pc 0013299b  /system/lib/libandroid_runtime.so (android::android_os_MessageQueue_nativePollOnce(_JNIEnv*, _jobject*, long long, int)+59) (BuildId: 6ceb9761bceb97a18c92f8a4b7072247)\r\n",
      "      #78 pc 002b86f8  /system/framework/x86/boot-framework.oat (art_jni_trampoline+136) (BuildId: ff6ec03dd8445d20788424c92ba8ea28ad0f54f4)\r\n",
      "      #79 pc 02001f56  /memfd:/jit-cache (deleted) (android.os.MessageQueue.next+230)\r\n",
      "      #80 pc 0013e7d2  /apex/com.android.runtime/lib/libart.so (art_quick_invoke_stub+338) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #81 pc 00149a69  /apex/com.android.runtime/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+281) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #82 pc 00332502  /apex/com.android.runtime/lib/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+386) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #83 pc 0032c19c  /apex/com.android.runtime/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+988) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #84 pc 0068186d  /apex/com.android.runtime/lib/libart.so (MterpInvokeVirtual+989) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #85 pc 00138821  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_virtual+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #86 pc 00319d8a  /system/framework/framework.jar (android.os.Looper.loop+130)\r\n",
      "      #87 pc 00684f6c  /apex/com.android.runtime/lib/libart.so (MterpInvokeStatic+1260) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #88 pc 001389a1  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_static+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #89 pc 0018945e  /system/framework/framework.jar (android.app.ActivityThread.main+194)\r\n",
      "      #90 pc 002f8e0a  /apex/com.android.runtime/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEbb.llvm.12194892193087984976+298) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #91 pc 002ffcc5  /apex/com.android.runtime/lib/libart.so (art::interpreter::EnterInterpreterFromEntryPoint(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*)+181) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #92 pc 0066fbd9  /apex/com.android.runtime/lib/libart.so (artQuickToInterpreterBridge+1209) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #93 pc 0014503d  /apex/com.android.runtime/lib/libart.so (art_quick_to_interpreter_bridge+77) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #94 pc 0013e9a2  /apex/com.android.runtime/lib/libart.so (art_quick_invoke_static_stub+418) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #95 pc 00149a7a  /apex/com.android.runtime/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+298) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #96 pc 0055a513  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+99) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #97 pc 0055c32f  /apex/com.android.runtime/lib/libart.so (art::InvokeMethod(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jobject*, _jobject*, unsigned int)+1327) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #98 pc 004c9153  /apex/com.android.runtime/lib/libart.so (art::Method_invoke(_JNIEnv*, _jobject*, _jobject*, _jobjectArray*)+83) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #99 pc 000c6bf8  /system/framework/x86/boot.oat (art_jni_trampoline+168) (BuildId: 7913dbaef2e8d9971cb7619ef0d566987f8326a7)\r\n",
      "      #100 pc 0013e7d2  /apex/com.android.runtime/lib/libart.so (art_quick_invoke_stub+338) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #101 pc 00149a69  /apex/com.android.runtime/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+281) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #102 pc 00332502  /apex/com.android.runtime/lib/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+386) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #103 pc 0032c19c  /apex/com.android.runtime/lib/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+988) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #104 pc 0068186d  /apex/com.android.runtime/lib/libart.so (MterpInvokeVirtual+989) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #105 pc 00138821  /apex/com.android.runtime/lib/libart.so (mterp_op_invoke_virtual+33) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #106 pc 0034cd36  /system/framework/framework.jar (com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run+22)\r\n",
      "      #107 pc 002f8e0a  /apex/com.android.runtime/lib/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEbb.llvm.12194892193087984976+298) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #108 pc 002ffcc5  /apex/com.android.runtime/lib/libart.so (art::interpreter::EnterInterpreterFromEntryPoint(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*)+181) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #109 pc 0066fbd9  /apex/com.android.runtime/lib/libart.so (artQuickToInterpreterBridge+1209) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #110 pc 0014503d  /apex/com.android.runtime/lib/libart.so (art_quick_to_interpreter_bridge+77) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #111 pc 00998b08  /system/framework/x86/boot-framework.oat (com.android.internal.os.ZygoteInit.main+1816) (BuildId: ff6ec03dd8445d20788424c92ba8ea28ad0f54f4)\r\n",
      "      #112 pc 0013e9a2  /apex/com.android.runtime/lib/libart.so (art_quick_invoke_static_stub+418) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #113 pc 00149a7a  /apex/com.android.runtime/lib/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+298) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #114 pc 0055a513  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+99) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #115 pc 0055a1ae  /apex/com.android.runtime/lib/libart.so (art::InvokeWithVarArgs(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jmethodID*, char*)+430) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #116 pc 004305cd  /apex/com.android.runtime/lib/libart.so (art::JNI::CallStaticVoidMethodV(_JNIEnv*, _jclass*, _jmethodID*, char*)+893) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #117 pc 003d93bf  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::CheckJNI::CallMethodV(char const*, _JNIEnv*, _jobject*, _jclass*, _jmethodID*, char*, art::Primitive::Type, art::InvokeType)+2847) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #118 pc 003c7509  /apex/com.android.runtime/lib/libart.so (art::(anonymous namespace)::CheckJNI::CallStaticVoidMethodV(_JNIEnv*, _jclass*, _jmethodID*, char*)+73) (BuildId: 895645e5113da057f27d9b2ec11eb3bf)\r\n",
      "      #119 pc 000b25fe  /system/lib/libandroid_runtime.so (_JNIEnv::CallStaticVoidMethod(_jclass*, _jmethodID*, ...)+62) (BuildId: 6ceb9761bceb97a18c92f8a4b7072247)\r\n",
      "      #120 pc 000b628a  /system/lib/libandroid_runtime.so (android::AndroidRuntime::start(char const*, android::Vector<android::String8> const&, bool)+794) (BuildId: 6ceb9761bceb97a18c92f8a4b7072247)\r\n",
      "      #121 pc 00003632  /system/bin/app_process32 (main+1490) (BuildId: b7a60bc7d078521421fd5a8d201915ae)\r\n",
      "      #122 pc 000898e8  /apex/com.android.runtime/lib/bionic/libc.so (__libc_init+120) (BuildId: 76290498408016ad14f4b98c3ab6c65c)\r\n",
      "```\r\n",
      "\r\n",
      "The ``style-predict`` model works fine and generates the expected output. But when I try to use the input image and the ``bottleneck`` from the ``style-predict`` in the ``style-transfer`` model the app crashes. \r\n",
      "\r\n",
      "Whats interesting is that when I use the [other style transfer model that is not based on inceptionv3](https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/fp16/transfer/1), the app works fine and everything works great. But I want to make the inception model work as its result is far superior.\r\n",
      "\r\n",
      "Below is my code in java that I am using to make this work:\r\n",
      "\r\n",
      "```java\r\n",
      "    protected Interpreter predictInterpreter;\r\n",
      "    protected Interpreter transformInterpreter;\r\n",
      "    protected Interpreter.Options interpreterOptions = new Interpreter.Options();\r\n",
      "    private final static int IMAGE_MEAN = 0;\r\n",
      "    private final static int IMAGE_STD = 255;\r\n",
      "    private final static int STYLE_IMG_SIZE = 256;\r\n",
      "    private final static int CONTENT_IMG_SIZE = 384;\r\n",
      "    private final static int DIM_BATCH_SIZE = 1;\r\n",
      "    private final static int DIM_PIXEL_SIZE = 3;\r\n",
      "\r\n",
      "// non-relevant code removed for easy reading\r\n",
      "\r\n",
      "try {\r\n",
      "            interpreterOptions.setNumThreads(4);\r\n",
      "            predictInterpreter = new Interpreter(loadModelFile(\"inceptionv3_fp16_predict_1.tflite\"), interpreterOptions);\r\n",
      "            transformInterpreter = new Interpreter(loadModelFile(\"inceptionv3_fp16_transfer_1.tflite\"), interpreterOptions);\r\n",
      "        } catch (Exception e) {\r\n",
      "            e.printStackTrace();\r\n",
      "        }\r\n",
      "\r\n",
      "// input contentImage is already downscaled to 384*384 and ``bottleneck`` is the output from the ``style-predict`` model.\r\n",
      "private Bitmap runTransform(Interpreter tflite, Bitmap contentImage, ByteBuffer bottleneck) {\r\n",
      "        TensorImage inputTensorImage = getInputTensorImage(tflite, contentImage);\r\n",
      "        Object[] inputs = new Object[2];\r\n",
      "        inputs[0] = inputTensorImage.getBuffer();\r\n",
      "        inputs[1] = bottleneck;\r\n",
      "\r\n",
      "        int[] outputShape =\r\n",
      "                new int[] {DIM_BATCH_SIZE, CONTENT_IMG_SIZE, CONTENT_IMG_SIZE, DIM_PIXEL_SIZE};\r\n",
      "        DataType outputDataType = tflite.getOutputTensor(/* outputTensorIndex */ 0).dataType();\r\n",
      "        TensorBuffer outputTensorBuffer = TensorBuffer.createFixedSize(outputShape, outputDataType);\r\n",
      "        Map<Integer, Object> outputs = new HashMap<>();\r\n",
      "        outputs.put(0, outputTensorBuffer.getBuffer());\r\n",
      "        tflite.runForMultipleInputsOutputs(inputs, outputs);    /// on this line app crashes with above error messages.\r\n",
      "        Bitmap outputBitmap = convertOutputToBmp(outputTensorBuffer.getFloatArray());\r\n",
      "        return outputBitmap;\r\n",
      "    }\r\n",
      "\r\n",
      "private TensorImage getInputTensorImage(Interpreter tflite, Bitmap inputBitmap) {\r\n",
      "        DataType imageDataType = tflite.getInputTensor(/* imageTensorIndex */0).dataType();\r\n",
      "        TensorImage inputTensorImage = new TensorImage(imageDataType);\r\n",
      "        inputTensorImage.load(inputBitmap);\r\n",
      "        ImageProcessor imageProcessor =\r\n",
      "                new ImageProcessor.Builder().add(new NormalizeOp(IMAGE_MEAN, IMAGE_STD)).build();\r\n",
      "        return imageProcessor.process(inputTensorImage);\r\n",
      "    }\r\n",
      "```\r\n",
      "\r\n",
      "I hope someone can help me figure out what the problem is please.\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:lite\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  [Kernel C API] Fix inplacement issue in C API\n",
      "issue body -  This commit is intended to fix two inplace issue in kernel C API:\r\n",
      "1. RefCountIsOne\r\n",
      "   tensor.RefCountIsOne() is the condition to decide whether the op can\r\n",
      "   do inplacement(e.g. forward_input), however, TF_Tensor retrieved through\r\n",
      "   TF_GetInput(), TF_AllocateOutput() makes the refcount always > 1, in\r\n",
      "   TF_TensorFromTensor, it will call tensor.CopyFrom() and increment the refcount\r\n",
      "\r\n",
      "2. TF_TensorBitcastFrom()\r\n",
      "   Currently, this API only modifies TF_Tensor's buf pointer, but the src c++ tensor it\r\n",
      "   copied from is not modified, that makes the TF_Tensor inconsistent with src c++ tensor,\r\n",
      "   see the following example, it allocated an output TF_Tensor and modified its buffer through\r\n",
      "   TF_TensorBitcastFrom(), however, src c++ tensor in Op_KernelContext is not modified.\r\n",
      "   ```c++\r\n",
      "    // Example:\r\n",
      "    TF_Tensor* a = TF_AllocateOutput(ctx, 0); // src c++ tensor: x\r\n",
      "    TF_Tensor* b = TF_AllocateTemp(ctx);\r\n",
      "    TF_TensorBitcastFrom(b, a); // a->buf_ = b_buf;\r\n",
      "    // src c++ tensor x's buf is not modified, thus x->buf_ != a->buf_\r\n",
      "   ```\n",
      "issue labels - \n",
      "cla: yes\n",
      "size:M\n",
      "\n",
      "\n",
      "issue title -  ImportError traceback in VScode\n",
      "issue body -  ImportError                               Traceback (most recent call last)\r\n",
      "~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in swig_import_helper()\r\n",
      "     17         try:\r\n",
      "---> 18             fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n",
      "     19         except ImportError:\r\n",
      "\r\n",
      "C:\\Program Files\\Python39\\lib\\imp.py in find_module(name, path)\r\n",
      "    295     else:\r\n",
      "--> 296         raise ImportError(_ERR_MSG.format(name), name=name)\r\n",
      "    297 \r\n",
      "\r\n",
      "ImportError: No module named '_pywrap_tensorflow'\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "ModuleNotFoundError                       Traceback (most recent call last)\r\n",
      "~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n",
      "     53     # use `dlopen()` for dynamic loading.\r\n",
      "---> 54     from tensorflow.python import pywrap_tensorflow\r\n",
      "     55 except ImportError:\r\n",
      "\r\n",
      "~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n",
      "     27             return _mod\r\n",
      "---> 28     _pywrap_tensorflow = swig_import_helper()\r\n",
      "     29     del swig_import_helper\r\n",
      "\r\n",
      "~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in swig_import_helper()\r\n",
      "     19         except ImportError:\r\n",
      "---> 20             import _pywrap_tensorflow\r\n",
      "     21             return _pywrap_tensorflow\r\n",
      "\r\n",
      "ModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "ImportError                               Traceback (most recent call last)\r\n",
      "c:\\Users\\tarang mehta\\Desktop\\introtodeeplearning-master\\Deep_lizard\\First_ANN.py in \r\n",
      "----> 2 import tensorflow as tf\r\n",
      "      3 from tensorflow import keras\r\n",
      "      4 from tensorflow.keras.models import Sequential\r\n",
      "      5 from tensorflow.keras.layers import Activation, Dense\r\n",
      "      6 from tensorflow.keras.optimizers import Adam\r\n",
      "\r\n",
      "~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\__init__.py in <module>\r\n",
      "     22 \r\n",
      "     23 # pylint: disable=wildcard-import\r\n",
      "---> 24 from tensorflow.python import *\r\n",
      "     25 # pylint: enable=wildcard-import\r\n",
      "     26 \r\n",
      "\r\n",
      "~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n",
      "     58 please exit the tensorflow source tree, and relaunch your python interpreter\r\n",
      "     59 from there.\"\"\" % traceback.format_exc()\r\n",
      "---> 60   raise ImportError(msg)\r\n",
      "     61 \r\n",
      "     62 # Protocol buffers\r\n",
      "\r\n",
      "ImportError: Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\tarang mehta\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n",
      "    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n",
      "  File \"C:\\Program Files\\Python39\\lib\\imp.py\", line 296, in find_module\r\n",
      "    raise ImportError(_ERR_MSG.format(name), name=name)\r\n",
      "ImportError: No module named '_pywrap_tensorflow'\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"C:\\Users\\tarang mehta\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n",
      "    from tensorflow.python import pywrap_tensorflow\r\n",
      "  File \"C:\\Users\\tarang mehta\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n",
      "    _pywrap_tensorflow = swig_import_helper()\r\n",
      "  File \"C:\\Users\\tarang mehta\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n",
      "    import _pywrap_tensorflow\r\n",
      "ModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n",
      "\r\n",
      "\r\n",
      "Error importing tensorflow.  Unless you are using bazel,\r\n",
      "you should not try to import tensorflow from its source directory;\r\n",
      "please exit the tensorflow source tree, and relaunch your python interpreter\r\n",
      "from there.\r\n",
      "2 cells were canceled due to an error in the previous cell.\n",
      "issue labels - \n",
      "stat:awaiting response\n",
      "type:build/install\n",
      "\n",
      "\n",
      "issue title -  fix Windows build errors\n",
      "issue body -  fix some more build errors of the kind already addressed in #42676:\r\n",
      "\r\n",
      "compiler doesn't get that LOG(FATAL) macro eventually calls std::abort() and complains with \"method doesn't return a value\", so call abort explicitely\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:xla\n",
      "size:S\n",
      "\n",
      "\n",
      "issue title -  Custom objects in tf.keras have conflicting interface\n",
      "issue body -  Custom tf.keras layers (tf.2.4.)  use `call` for invocation.  However, custom constraints use `__call__`.  This seems confusing.  Furthermore, if you implement a constraint using `call` instead of `__ call __` no warning or error given. I wonder if its reasonable to expect a Not Implemented error to occur in this case of `__call__` missing.\r\n",
      "\r\n",
      "Ref: \r\n",
      "1. Custom layer documentation: https://keras.io/guides/making_new_layers_and_models_via_subclassing/\r\n",
      "2. Custom constraint documentation: https://keras.io/api/layers/constraints/\r\n",
      "\r\n",
      "EDIT 1. Fixed link.\r\n",
      "EDIT 2. Added tensorflow version. Updated ticket title to reflect tf.keras.\n",
      "issue labels - \n",
      "comp:keras\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  In-batch-negatives and distributed traning\n",
      "issue body -  I'm training a model using triplet loss. This means that my loss function aims to minimize the distance to a positive observation (let's say a sentence with the same semantic meaning) and maximize the distance to the negative observation. \r\n",
      "Im using [TripletHardLoss](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/losses/triplet.py#L348) from tensorflow-addons to do so. TripletHardLoss mines the batch to find the positive observation with the largest distance and the negative observation with the smallest distance in the batch and then applies the triplet loss.\r\n",
      "\r\n",
      "Now when I train this model using `tf.distribute.MirroredStrategy` on a batch of 128 sentences and 8 GPUs the batches on my devices will only contain 14 (not counting the positive observation and the observation itself) potential negatives for each datapoint in the batch.\r\n",
      "\r\n",
      "Is there any distribution strategy to concatenate all the 128 embeddings, run the triplet mining on this global batch, distribute the observation losses back to the devices and calculate the gradients (or even calculate the gradients on the device that runs the triplet mining) to utilize the negatives of the global batch?\n",
      "issue labels - \n",
      "comp:dist-strat\n",
      "stat:awaiting tensorflower\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Assert if y_pred and y_true have same shape in categorical_accuracy()\n",
      "issue body -  Refer this [issue](https://github.com/tensorflow/tensorflow/issues/46953) for details. \n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:keras\n",
      "size:XS\n",
      "\n",
      "\n",
      "issue title -  Give Grappler hints about function XLA compilation so it can selectively apply compatible optimizations\n",
      "issue body -  Some Grappler optimizations can cause problems for XLA. This was first discovered by the MemoryOptimizer pass creating TemporaryVariable ops without knowing if the later compiling XLA device implemented the TemporaryVariable OpKernel [[issue](https://github.com/tensorflow/tensorflow/issues/30580)].\r\n",
      "\r\n",
      "The first fix for this was to disable Grappler for any functions called from an XlaLaunch node [[commit 1](https://github.com/tensorflow/tensorflow/commit/471b73c238709fb796929eb412f1dab763b3f8cc)].\r\n",
      "It was found that this isn't sufficient, as some functions can be encapsulated out of the main XlaLaunch cluster function e.g. While ops, so a later fix was added to also disable Grappler for any functions transitively called by an XlaLaunch function [[commit 2](https://github.com/tensorflow/tensorflow/commit/e0bb74087f440394f6df00c5c7ff36e50d23132a)].\r\n",
      "\r\n",
      "However, a more general approach may be to introduce hints which Grappler can use to avoid making certain XLA-incompatible optimizations, allowing them to work together.\r\n",
      "This PR introduces a GrapplerXlaHints struct which is populated by a GenerateXlaHints function, which allows individual Grappler optimizers to switch themselves off depending on the GrapplerItem's XLA hints.\r\n",
      "Currently the PR disables the constant_folding, arithmetic_optimizer and the SchedulingPass of the MemoryOptimizer based on these hints.\r\n",
      "\r\n",
      "Note that this will cause a change in behaviour where the immediate XlaLaunch functions will now go through Grappler where they otherwise weren't before commit 1 (with appropriate passes selectively disabling themselves).\r\n",
      "\r\n",
      "I have added a test which passes locally that checks the hints are generated properly for an example call tree.\r\n",
      "I have also linted all files according to [this guide](https://www.tensorflow.org/community/contribute/code_style).\n",
      "issue labels - \n",
      "cla: yes\n",
      "comp:core\n",
      "size:L\n",
      "\n",
      "\n",
      "issue title -  Calling model.test_on_batch after model.evaluate returns corrupted values for the loss and the metrics\n",
      "issue body -  **System information**\r\n",
      "- Google colab with tf 2.4.1 (v2.4.1-0-g85c8b2a817f )\r\n",
      "- with CPU or GPU runtimes, it does not matter\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "\r\n",
      "Calling `model.test_on_batch` after calling `model.evaluate` gives incorrect results.\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "\r\n",
      "Calling `model.test_on_batch` should  return the a value that does not depend on whether`model.evaluate`  was called before.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "\r\n",
      "Let's define a randomly initialized model evaluated on randomly generated data. If we call `model.test_on_batch` directly, everything is fine:\r\n",
      "\r\n",
      "```python\r\n",
      "import numpy as np\r\n",
      "from tensorflow.keras.models import Sequential\r\n",
      "from tensorflow.keras.layers import Dense\r\n",
      "\r\n",
      "rng = np.random.RandomState(0)\r\n",
      "batch_size = 32\r\n",
      "n_samples, n_features = batch_size * 10, 5\r\n",
      "X = rng.normal(size=(n_samples, n_features))\r\n",
      "y = rng.randint(low=0, high=2, size=X.shape[0])\r\n",
      "\r\n",
      "model = Sequential([Dense(1, input_shape=(n_features,),\r\n",
      "                          activation=\"sigmoid\")])\r\n",
      "model.compile(optimizer=\"adam\", loss='binary_crossentropy',\r\n",
      "              metrics=['accuracy'])\r\n",
      "\r\n",
      "print(\"model.test_on_batch without model.evaluate\")\r\n",
      "for i in range(3):\r\n",
      "    loss, acc = model.test_on_batch(X[:batch_size], y[:batch_size])\r\n",
      "    print(loss, acc)\r\n",
      "```\r\n",
      "\r\n",
      "output:\r\n",
      "\r\n",
      "```\r\n",
      "model.test_on_batch without model.evaluate\r\n",
      "6.294709205627441 0.5625\r\n",
      "6.294709205627441 0.5625\r\n",
      "6.294709205627441 0.5625\r\n",
      "```\r\n",
      "\r\n",
      "If we then call `evaluate`, the fist call of `model.test_on_batch` return an incorrect value:\r\n",
      "\r\n",
      "```python\r\n",
      "normal_loss, normal_acc = model.evaluate(\r\n",
      "    X, y, batch_size=batch_size, verbose=0)\r\n",
      "\r\n",
      "print(\"model.test_on_batch *after* model.evaluate\")\r\n",
      "for i in range(3):\r\n",
      "    loss, acc = model.test_on_batch(X[:batch_size], y[:batch_size])\r\n",
      "    print(loss, acc)\r\n",
      "```\r\n",
      "\r\n",
      "output:\r\n",
      "\r\n",
      "```\r\n",
      "model.test_on_batch *after* model.evaluate\r\n",
      "6.585799694061279 0.4801136255264282\r\n",
      "6.294709205627441 0.5625\r\n",
      "6.294709205627441 0.5625\r\n",
      "```\r\n",
      "\r\n",
      "Note: this is a minimal reproducer of the report found in the comments of a similar standalone keras issue: https://github.com/keras-team/keras/issues/14086\r\n",
      "\r\n",
      "It is probably also the cause or at least related to corrupted loss/metric values reported when using `evaluate_generator`:\r\n",
      "https://github.com/keras-team/keras/issues/13780\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:keras\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  SparseTensorDenseMatMul adjoint_a takes transpose, not adjoint\n",
      "issue body -  **System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n",
      "- TensorFlow installed from (source or binary): binary\r\n",
      "- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1\r\n",
      "- Python version: 3.7.6\r\n",
      "- Bazel version (if compiling from source): N/A\r\n",
      "- GCC/Compiler version (if compiling from source): N/A\r\n",
      "- CUDA/cuDNN version: N/A\r\n",
      "- GPU model and memory: N/A\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "On CPU (haven't checked GPU), the `adjoint_a` argument to `SparseTensorDenseMatMul` op (accessed via `tf.sparse.sparse_dense_matmul`) takes the transpose of the argument but not the conjugate.\r\n",
      "\r\n",
      "Looks like the issue is here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_tensor_dense_matmul_op.h#L55; shouldn't that be taking a conjugate?\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "`adjoint_a` takes the adjoint of `a`.\r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "```\r\n",
      "import tensorflow as tf\r\n",
      "x = tf.sparse.from_dense([[1j]])\r\n",
      "y = tf.constant([[1]], dtype=tf.complex128)\r\n",
      "print(tf.sparse.sparse_dense_matmul(x, y, adjoint_a=True).numpy()) # Gives [[1j]]\r\n",
      "```\r\n",
      "See gist here: https://colab.research.google.com/drive/1qRZo4q1qwwt_pt6EfxRJPVohXmDUrdvN?usp=sharing\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:ops\n",
      "type:bug\n",
      "\n",
      "\n",
      "issue title -  Slower on a Nvidia 1080TI GPU than on CPU \n",
      "issue body -  **System information**\r\n",
      "- Linux Ubuntu 18.04\r\n",
      "- TensorFlow installed from binary\r\n",
      "- TensorFlow version 2.4.1\r\n",
      "- Python version : 3.8\r\n",
      "- CUDA V 11.0/cuDNN version 8:\r\n",
      "- GPU model: Nvidia 1080TI 11gb RAM\r\n",
      "\r\n",
      "Running same script is 2x slower on GPU than CPU \r\n",
      "\r\n",
      "Steps to reproduce the problem :\r\n",
      "\r\n",
      "obj = DeepFace.analyze(img_path = \"target.jpg\", actions = ['age', 'gender', 'race'])\r\n",
      "\r\n",
      "This framework uses several models but in this case VGG Face was used for analysis .\r\n",
      "\r\n",
      "Log from GPU run  :\r\n",
      "\r\n",
      "2021-02-23 04:35:18.719513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n",
      "2021-02-23 04:35:18.719590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n",
      "2021-02-23 04:35:19.596969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2021-02-23 04:35:19.597049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n",
      "2021-02-23 04:35:19.597068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n",
      "2021-02-23 04:35:19.597404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2021-02-23 04:35:19.598430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2021-02-23 04:35:19.599326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2021-02-23 04:35:19.600166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10271 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:00:05.0, compute capability: 6.1)\r\n",
      "Action: age:   0%|                                                                                                                     | 0/3 [00:00<?, ?it/s]2021-02-23 04:35:23.409541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n",
      "2021-02-23 04:35:23.410483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199965000 Hz\r\n",
      "2021-02-23 04:35:23.581168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n",
      "2021-02-23 04:35:24.535674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n",
      "2021-02-23 04:35:24.910561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n",
      "Action: race: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.80s/it]\r\n",
      "29  years old  asian     Woman\r\n",
      "10.368096351623535  seconds\r\n",
      "\r\n",
      "************** CPU RUn log :\r\n",
      "\r\n",
      "2021-02-22 21:37:27.379054: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "2021-02-22 21:37:27.382967: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n",
      "2021-02-22 21:37:27.385962: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n",
      "2021-02-22 21:37:27.394354: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-101PVLV\r\n",
      "2021-02-22 21:37:27.398139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-101PVLV\r\n",
      "2021-02-22 21:37:27.400591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2021-02-22 21:37:27.408451: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "Action: age:   0%|                                                                               | 0/3 [00:00<?, ?it/s]2021-02-22 21:37:31.366069: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n",
      "Action: race: 100%|██████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.63it/s]\r\n",
      "29  years old  asian     Woman\r\n",
      "5.869304418563843  seconds\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:gpu\n",
      "stat:awaiting response\n",
      "type:performance\n",
      "\n",
      "\n",
      "issue title -  ERROR: Didn't find op for builtin opcode 'ADD' version '1'\n",
      "issue body -  @tensorflow/micro\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, with MCU Expresso\r\n",
      "- TensorFlow installed from (source or binary): source\r\n",
      "- Tensorflow version (commit SHA if source): 2.3.1\r\n",
      "- Target platform (e.g. Arm Mbed OS, Arduino Nano 33, etc.): IMX RT 1060\r\n",
      "\r\n",
      "**Describe the problem**\r\n",
      "The application as per [this code](https://github.com/kavyaprasad22/MNV3) is saved as .pb file and converted to .tflite using [this convert.py](https://github.com/kavyaprasad22/MNV3/blob/main/conver.py). After uploading this to IMX RT 1060, the debugger throws an ```ERROR: Didn't find op for built-in opcode 'ADD' version '1'```. Is the opcode ADD failed to  be converted by the tflite or is it because of any missing header files in the client end?\r\n",
      "\r\n",
      "**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n",
      "```\r\n",
      "python train_RJ.py\r\n",
      "python conver.py\r\n",
      "``` \r\n",
      "after this converted to *.h using ``` xxd -i model.tflite > model.h``` \r\n",
      "and uploaded with MCU Xpresso to IMX RT 1060 using tensorflow_lite_cifar_10 example provided under eiq folder from SDK 2.9.1 build from [this builder](https://mcuxpresso.nxp.com/en/builder?hw=EVK-MIMXRT1060).\r\n",
      "\r\n",
      "\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.3\n",
      "comp:lite\n",
      "comp:micro\n",
      "type:support\n",
      "\n",
      "\n",
      "issue title -  Adabound feature request \n",
      "issue body -  <em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n",
      "\r\n",
      "\r\n",
      "**System information**\r\n",
      "- TensorFlow version (you are using): 2.4.1\r\n",
      "- Are you willing to contribute it (Yes/No):\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "**Describe the feature and the current behavior/state.**\r\n",
      "[Adabound](https://arxiv.org/abs/1902.09843) is a powerful optimizer for training models combining the advantages of SGD and Adam/momentum. Currently, there are no official TF/pytorch implementations available. Some projects in PYPI [keras-adabound](https://pypi.org/project/keras-adabound/) [torch-optimizer](https://pypi.org/project/torch-optimizer/) provides implementaions, but why not support an official Adabound and amsbound optimizer!\r\n",
      "\r\n",
      "**Will this change the current api? How?**\r\n",
      "\r\n",
      "**Who will benefit with this feature?**\r\n",
      "Everyone hoping to experiment adabound for accelerated training.\r\n",
      "**Any Other info.**\r\n",
      "\n",
      "issue labels - \n",
      "comp:keras\n",
      "stat:awaiting tensorflower\n",
      "type:feature\n",
      "\n",
      "\n",
      "issue title -  memory increasing slowly and largely at the beginning of model.fit() in tf.keras\n",
      "issue body -  **System information**\r\n",
      "    Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n",
      "    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows\r\n",
      "    TensorFlow installed from (source or binary):github release\r\n",
      "    TensorFlow version (use command below):2.3.1\r\n",
      "    Python version:3.8.1\r\n",
      "    CUDA/cuDNN version:10.1, 7.6.\r\n",
      "    GPU model and memory: RTX2080Ti x4 \r\n",
      "**Describe the current behavior**\r\n",
      "It takes to much time for memory increasing before keras logs come and sometimes shows W:\"multi-device function optimization failure\"\r\n",
      "**Describe the expected behavior**\r\n",
      "Less time for memory increasing\r\n",
      "\r\n",
      "**Code to reproduce the issue**\r\n",
      "\r\n",
      "> main.py:\r\n",
      "\r\n",
      "`\r\n",
      "\r\n",
      "    import tensorflow as tf\r\n",
      "    import tensorflow_addons as tfa\r\n",
      "    import tensorflow_datasets as tfds\r\n",
      "    from tensorflow.keras.callbacks import TensorBoard\r\n",
      "    from model import VisionTransformer\r\n",
      "    AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
      "\r\n",
      "    ds = tfds.load(\"imagenet_resized/32x32\", as_supervised=True)\r\n",
      "    ds_train = (\r\n",
      "        ds[\"train\"]\r\n",
      "        .cache()\r\n",
      "        .shuffle(5 * 4096)\r\n",
      "        .batch(4096)\r\n",
      "        .prefetch(AUTOTUNE)\r\n",
      "    )\r\n",
      "    ds_test = (\r\n",
      "        ds[\"validation\"]\r\n",
      "        .cache()\r\n",
      "        .batch(4096)\r\n",
      "        .prefetch(AUTOTUNE)\r\n",
      "    )\r\n",
      "\r\n",
      "    strategy = tf.distribute.MirroredStrategy()\r\n",
      "\r\n",
      "    with strategy.scope():\r\n",
      "        model = VisionTransformer(\r\n",
      "            image_size=32,\r\n",
      "            patch_size=4,\r\n",
      "            num_layers=4,\r\n",
      "            num_classes=1000,\r\n",
      "            d_model=64,\r\n",
      "            num_heads=4,\r\n",
      "            mlp_dim=128,\r\n",
      "            channels=3,\r\n",
      "            dropout=0.1,\r\n",
      "        )\r\n",
      "        model.compile(\r\n",
      "            loss=tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
      "                from_logits=True\r\n",
      "            ),\r\n",
      "            optimizer=tfa.optimizers.AdamW(\r\n",
      "                learning_rate=3e-4, weight_decay=1e-4\r\n",
      "            ),\r\n",
      "            metrics=[\"accuracy\"],\r\n",
      "        )\r\n",
      "\r\n",
      "    model.fit(\r\n",
      "        ds_train,\r\n",
      "        validation_data=ds_test,\r\n",
      "        epochs=300,\r\n",
      "    )\r\n",
      "`\r\n",
      "\r\n",
      "> model.py:\r\n",
      "\r\n",
      "`\r\n",
      "import tensorflow as tf\r\n",
      "import tensorflow_addons as tfa\r\n",
      "from tensorflow.keras.layers import (\r\n",
      "    Dense,\r\n",
      "    Dropout,\r\n",
      "    LayerNormalization,\r\n",
      ")\r\n",
      "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\r\n",
      "\r\n",
      "class MultiHeadSelfAttention(tf.keras.layers.Layer):\r\n",
      "    def __init__(self, embed_dim, num_heads=8):\r\n",
      "        super(MultiHeadSelfAttention, self).__init__()\r\n",
      "        self.embed_dim = embed_dim\r\n",
      "        self.num_heads = num_heads\r\n",
      "        if embed_dim % num_heads != 0:\r\n",
      "            raise ValueError(\r\n",
      "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\r\n",
      "            )\r\n",
      "        self.projection_dim = embed_dim // num_heads\r\n",
      "        self.query_dense = Dense(embed_dim)\r\n",
      "        self.key_dense = Dense(embed_dim)\r\n",
      "        self.value_dense = Dense(embed_dim)\r\n",
      "        self.combine_heads = Dense(embed_dim)\r\n",
      "\r\n",
      "    def attention(self, query, key, value):\r\n",
      "        score = tf.matmul(query, key, transpose_b=True)\r\n",
      "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\r\n",
      "        scaled_score = score / tf.math.sqrt(dim_key)\r\n",
      "        weights = tf.nn.softmax(scaled_score, axis=-1)\r\n",
      "        output = tf.matmul(weights, value)\r\n",
      "        return output, weights\r\n",
      "\r\n",
      "    def separate_heads(self, x, batch_size):\r\n",
      "        x = tf.reshape(\r\n",
      "            x, (batch_size, -1, self.num_heads, self.projection_dim)\r\n",
      "        )\r\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\r\n",
      "\r\n",
      "    def call(self, inputs):\r\n",
      "        batch_size = tf.shape(inputs)[0]\r\n",
      "        query = self.query_dense(inputs)\r\n",
      "        key = self.key_dense(inputs)\r\n",
      "        value = self.value_dense(inputs)\r\n",
      "        query = self.separate_heads(query, batch_size)\r\n",
      "        key = self.separate_heads(key, batch_size)\r\n",
      "        value = self.separate_heads(value, batch_size)\r\n",
      "        attention, weights = self.attention(query, key, value)\r\n",
      "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\r\n",
      "        concat_attention = tf.reshape(\r\n",
      "            attention, (batch_size, -1, self.embed_dim)\r\n",
      "        )\r\n",
      "        output = self.combine_heads(concat_attention)\r\n",
      "        return output\r\n",
      "\r\n",
      "\r\n",
      "class TransformerBlock(tf.keras.layers.Layer):\r\n",
      "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\r\n",
      "        super(TransformerBlock, self).__init__()\r\n",
      "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\r\n",
      "        self.mlp = tf.keras.Sequential(\r\n",
      "            [\r\n",
      "                Dense(mlp_dim, activation=tfa.activations.gelu),\r\n",
      "                Dropout(dropout),\r\n",
      "                Dense(embed_dim),\r\n",
      "                Dropout(dropout),\r\n",
      "            ]\r\n",
      "        )\r\n",
      "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\r\n",
      "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\r\n",
      "        self.dropout1 = Dropout(dropout)\r\n",
      "        self.dropout2 = Dropout(dropout)\r\n",
      "\r\n",
      "    def call(self, inputs, training):\r\n",
      "        inputs_norm = self.layernorm1(inputs)\r\n",
      "        attn_output = self.att(inputs_norm)\r\n",
      "        attn_output = self.dropout1(attn_output, training=training)\r\n",
      "        out1 = attn_output + inputs\r\n",
      "        out1_norm = self.layernorm2(out1)\r\n",
      "        mlp_output = self.mlp(out1_norm)\r\n",
      "        mlp_output = self.dropout2(mlp_output, training=training)\r\n",
      "        return mlp_output + out1\r\n",
      "\r\n",
      "class VisionTransformer(tf.keras.Model):\r\n",
      "    def __init__(\r\n",
      "        self,\r\n",
      "        image_size,\r\n",
      "        patch_size,\r\n",
      "        num_layers,\r\n",
      "        num_classes,\r\n",
      "        d_model,\r\n",
      "        num_heads,\r\n",
      "        mlp_dim,\r\n",
      "        channels=3,\r\n",
      "        dropout=0.1,\r\n",
      "    ):\r\n",
      "        super(VisionTransformer, self).__init__()\r\n",
      "        num_patches = (image_size // patch_size) ** 2\r\n",
      "        self.patch_dim = channels * patch_size ** 2\r\n",
      "        self.patch_size = patch_size\r\n",
      "        self.d_model = d_model\r\n",
      "        self.num_layers = num_layers\r\n",
      "\r\n",
      "        self.rescale = Rescaling(1.0 / 255)\r\n",
      "        self.pos_emb = self.add_weight(\r\n",
      "            \"pos_emb\", shape=(1, num_patches + 1, d_model)\r\n",
      "        )\r\n",
      "        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\r\n",
      "        self.patch_proj = Dense(d_model)\r\n",
      "        self.enc_layers = [\r\n",
      "            TransformerBlock(d_model, num_heads, mlp_dim, dropout)\r\n",
      "            for _ in range(num_layers)\r\n",
      "        ]\r\n",
      "        self.mlp_head = tf.keras.Sequential(\r\n",
      "            [\r\n",
      "                LayerNormalization(epsilon=1e-6),\r\n",
      "                Dense(mlp_dim, activation=tfa.activations.gelu),\r\n",
      "                Dropout(dropout),\r\n",
      "                Dense(num_classes),\r\n",
      "            ]\r\n",
      "        )\r\n",
      "\r\n",
      "    def extract_patches(self, images):\r\n",
      "        batch_size = tf.shape(images)[0]\r\n",
      "        patches = tf.image.extract_patches(\r\n",
      "            images=images,\r\n",
      "            sizes=[1, self.patch_size, self.patch_size, 1],\r\n",
      "            strides=[1, self.patch_size, self.patch_size, 1],\r\n",
      "            rates=[1, 1, 1, 1],\r\n",
      "            padding=\"VALID\",\r\n",
      "        )\r\n",
      "        patches = tf.reshape(patches, [batch_size, -1, self.patch_dim])\r\n",
      "        return patches\r\n",
      "\r\n",
      "    def call(self, x, training):\r\n",
      "        batch_size = tf.shape(x)[0]\r\n",
      "        x = self.rescale(x)\r\n",
      "        patches = self.extract_patches(x)\r\n",
      "        x = self.patch_proj(patches)\r\n",
      "\r\n",
      "        class_emb = tf.broadcast_to(\r\n",
      "            self.class_emb, [batch_size, 1, self.d_model]\r\n",
      "        )\r\n",
      "        x = tf.concat([class_emb, x], axis=1)\r\n",
      "        x = x + self.pos_emb\r\n",
      "\r\n",
      "        for layer in self.enc_layers:\r\n",
      "            x = layer(x, training)\r\n",
      "\r\n",
      "        # First (class token) is used for classification\r\n",
      "        x = self.mlp_head(x[:, 0])\r\n",
      "        return x\r\n",
      "`\r\n",
      "**Other info / logs**\r\n",
      "\r\n",
      "> Epoch 1/20\r\n",
      "2021-02-23 09:54:36.039640: W tensorflow/core/common_runtime/process_function_library_runtime.cc:675] Ignoring multi-device function optimization failure: Deadline exceeded: meta_optimizer exceeded deadline.\r\n",
      "\r\n",
      "Usually it takes too much time from 'Epoch 1/20' log to progress bar log. By the way, could you tell me what things the increasing memory consists of?\n",
      "issue labels - \n",
      "TF 2.3\n",
      "comp:dist-strat\n",
      "comp:keras\n",
      "type:performance\n",
      "\n",
      "\n",
      "issue title -  tf.nn.depth_to_space with NCHW argument works in TF 2.3 but fails in TF 2.4\n",
      "issue body -  <em>Please make sure that this is a bug. As per our\r\n",
      "[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\n",
      "we only address code/doc bugs, performance issues, feature requests and\r\n",
      "build/installation issues on GitHub. tag:bug_template</em>\r\n",
      "\r\n",
      "**System information**\r\n",
      "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n",
      "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.7\r\n",
      "- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n",
      "- TensorFlow installed from (source or binary): Source\r\n",
      "- TensorFlow version (use command below): 2.4.0\r\n",
      "- Python version: 3.8.5\r\n",
      "- Bazel version (if compiling from source):\r\n",
      "- GCC/Compiler version (if compiling from source):\r\n",
      "- CUDA/cuDNN version:\r\n",
      "- GPU model and memory: Intel CPU, Macbook Pro 2019\r\n",
      "\r\n",
      "You can collect some of this information using our environment capture\r\n",
      "[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n",
      "You can also obtain the TensorFlow version with:\r\n",
      "1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n",
      "2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n",
      "\r\n",
      "\r\n",
      "**Describe the current behavior**\r\n",
      "In TF 2.4, the tf.nn.depth_to_space command fails with any data_format parameter of \"NCHW\". \r\n",
      "\r\n",
      "```\r\n",
      "python test_d2l.py\r\n",
      "2021-02-22 15:37:05.145218: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "2021-02-22 15:37:05.145510: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"test_d2l.py\", line 4, in <module>\r\n",
      "    tf.nn.depth_to_space(x, block_size=2, data_format=\"NCHW\")\r\n",
      "  File \"/usr/local/anaconda3/envs/keras2onnx/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n",
      "    return target(*args, **kwargs)\r\n",
      "  File \"/usr/local/anaconda3/envs/keras2onnx/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 3922, in depth_to_space_v2\r\n",
      "    return gen_array_ops.depth_to_space(input, block_size, data_format, name=name)\r\n",
      "  File \"/usr/local/anaconda3/envs/keras2onnx/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1625, in depth_to_space\r\n",
      "    return depth_to_space_eager_fallback(\r\n",
      "  File \"/usr/local/anaconda3/envs/keras2onnx/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1661, in depth_to_space_eager_fallback\r\n",
      "    _result = _execute.execute(b\"DepthToSpace\", 1, inputs=_inputs_flat,\r\n",
      "  File \"/usr/local/anaconda3/envs/keras2onnx/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node DepthToSpace}} = DepthToSpace[T=DT_FLOAT, block_size=2, data_format=\"NCHW\"]\r\n",
      "All kernels registered for op DepthToSpace:\r\n",
      "  device='CPU'; T in [DT_UINT64]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_INT64]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_UINT32]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_UINT16]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_INT16]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_UINT8]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_INT8]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_INT32]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_HALF]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_BFLOAT16]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_FLOAT]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_DOUBLE]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_COMPLEX64]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_COMPLEX128]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_BOOL]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_STRING]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_RESOURCE]; data_format in [\"NHWC\"]\r\n",
      "  device='CPU'; T in [DT_VARIANT]; data_format in [\"NHWC\"]\r\n",
      " [Op:DepthToSpace]\r\n",
      "```\r\n",
      "\r\n",
      "\r\n",
      "**Describe the expected behavior**\r\n",
      "Code block below runs without error in TF 2.3 (compiles cluster with XLA). \r\n",
      "\r\n",
      "**Standalone code to reproduce the issue**\r\n",
      "Provide a reproducible test case that is the bare minimum necessary to generate\r\n",
      "the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n",
      "\r\n",
      "```\r\n",
      "import tensorflow as tf\r\n",
      "import numpy as np\r\n",
      "x =  np.random.rand(3, 4, 6, 8).astype(np.float32)\r\n",
      "tf.nn.depth_to_space(x, block_size=2, data_format=\"NCHW\")\r\n",
      "```\r\n",
      "\r\n",
      "**Other info / logs** Include any logs or source code that would be helpful to\r\n",
      "diagnose the problem. If including tracebacks, please include the full\r\n",
      "traceback. Large logs and files should be attached.\r\n",
      "\n",
      "issue labels - \n",
      "TF 2.4\n",
      "comp:apis\n",
      "type:bug\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(issues_list)):\n",
    "    issue=issues_list[i]\n",
    "    issue_title=issue[\"title\"]\n",
    "    issue_body=issue[\"body\"]\n",
    "    print(\"\\n\\nissue title - \",issue_title)\n",
    "    print(\"issue body - \",issue_body)\n",
    "    print(\"issue labels - \")\n",
    "    issue_labels_list = issue[\"labels\"]\n",
    "    for j in range(len(issue_labels_list)):\n",
    "        label=issue_labels_list[j]\n",
    "        label_name=label[\"name\"]\n",
    "        print(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels_list=[]\n",
    "for i in range(len(issues_list)):\n",
    "    single_data=[]\n",
    "    issue=issues_list[i]\n",
    "    issue_title=issue[\"title\"]\n",
    "    issue_body=issue[\"body\"]\n",
    "    \n",
    "    single_data=single_data+[issue_title,issue_body];\n",
    "    \n",
    "    data=data+[single_data];\n",
    "    \n",
    "    issue_labels_list = issue[\"labels\"]\n",
    "    single_label_list=[]\n",
    "    for j in range(len(issue_labels_list)):\n",
    "        label=issue_labels_list[j]\n",
    "        label_name=label[\"name\"]\n",
    "        single_label_list=single_label_list+[label_name]\n",
    "    labels_list=labels_list+[single_label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(data),len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type:bug']\n",
      "['type:bug']\n",
      "['cla: yes', 'size:M']\n",
      "['cla: yes', 'comp:micro', 'size:M']\n",
      "['type:performance']\n",
      "['type:others']\n",
      "['comp:micro', 'type:bug']\n",
      "['TF 1.15', 'comp:dist-strat', 'stat:awaiting response', 'type:support']\n",
      "['TF 2.4', 'comp:keras', 'type:docs-bug']\n",
      "['type:others']\n",
      "['comp:lite', 'stat:awaiting response', 'type:docs-bug']\n",
      "['stat:awaiting response', 'type:others']\n",
      "['type:bug']\n",
      "['TF 2.4', 'comp:data', 'stat:awaiting response', 'type:support']\n",
      "['comp:data', 'stat:awaiting response', 'type:bug']\n",
      "['type:bug']\n",
      "['TF 2.4', 'stat:awaiting response', 'subtype: ubuntu/linux', 'type:build/install']\n",
      "['TF 2.4', 'comp:keras', 'type:bug']\n",
      "['TF 2.4', 'comp:gpu', 'stat:awaiting response', 'type:support']\n",
      "['TF 2.4', 'comp:lite', 'type:support']\n",
      "['TF 2.4', 'stat:awaiting response', 'type:bug']\n",
      "['TF 2.2', 'comp:keras', 'stat:awaiting response', 'type:bug']\n",
      "['cla: yes', 'comp:keras', 'size:XS']\n",
      "['comp:lite', 'type:support']\n",
      "[]\n",
      "['cla: yes', 'comp:micro', 'comp:micro:arm', 'prtype:bugfix', 'size:M']\n",
      "['TF 2.4', 'comp:ops', 'regression issue', 'type:bug']\n",
      "['cla: yes', 'comp:core', 'size:XS']\n",
      "['cla: yes', 'comp:micro', 'size:L']\n",
      "['TF 2.4', 'comp:apis', 'stat:awaiting response', 'type:support']\n",
      "['TF 2.2', 'comp:gpu', 'stat:awaiting response', 'type:support']\n",
      "['cla: yes', 'size:L']\n",
      "['cla: yes', 'comp:keras', 'size:S']\n",
      "['cla: yes', 'ready to pull', 'size:S']\n",
      "['cla: yes', 'comp:lite', 'size:S']\n",
      "['TF 2.2', 'comp:dist-strat', 'stat:awaiting response', 'type:performance']\n",
      "['cla: yes', 'comp:keras', 'size:XS']\n",
      "['cla: yes', 'comp:micro', 'ready to pull', 'size:S']\n",
      "['TF 2.4', 'comp:keras', 'type:bug']\n",
      "['awaiting review', 'cla: yes', 'size:XS']\n",
      "['TF 2.3', 'comp:apis', 'type:support']\n",
      "['TF 2.4', 'comp:apis', 'type:support']\n",
      "['cla: yes', 'comp:keras', 'size:XS']\n",
      "['TF 2.4', 'comp:keras', 'type:bug']\n",
      "['TFLiteConverter', 'comp:lite', 'type:feature']\n",
      "['TFLiteConverter', 'type:feature']\n",
      "['comp:micro', 'type:feature']\n",
      "['cla: yes', 'comp:core', 'size:XS', 'stat:awaiting tensorflower']\n",
      "['stat:awaiting response', 'subtype: ubuntu/linux', 'type:build/install']\n",
      "['cla: yes', 'comp:core', 'ready to pull', 'size:S']\n",
      "['comp:micro']\n",
      "['comp:mkl', 'stat:awaiting tensorflower', 'type:feature']\n",
      "['comp:micro']\n",
      "['cla: yes', 'comp:keras', 'size:S']\n",
      "['TF 2.4', 'comp:gpu', 'type:support']\n",
      "['cla: yes', 'comp:keras', 'size:M']\n",
      "['TF 2.4', 'comp:ops', 'type:bug']\n",
      "['type:build/install']\n",
      "['TF 2.4', 'comp:keras', 'type:bug']\n",
      "['type:bug']\n",
      "['comp:lite', 'type:build/install']\n",
      "['comp:lite', 'comp:micro', 'type:build/install']\n",
      "['cla: yes', 'comp:xla', 'size:L']\n",
      "['cla: yes', 'comp:keras', 'size:XS']\n",
      "['stat:awaiting response', 'type:bug']\n",
      "['TF 2.4', 'comp:keras', 'stat:awaiting tensorflower', 'type:bug']\n",
      "[]\n",
      "['comp:apis', 'stat:awaiting tensorflower', 'type:feature']\n",
      "['TF 2.4', 'comp:keras', 'type:bug']\n",
      "['cla: yes', 'size:XS']\n",
      "[]\n",
      "['awaiting review', 'cla: yes', 'comp:micro', 'size:L']\n",
      "['comp:lite', 'comp:runtime', 'type:performance']\n",
      "['TF 2.5', 'type:bug']\n",
      "['cla: yes', 'comp:ops', 'ready to pull', 'size:XS']\n",
      "['TF 2.4', 'stat:awaiting response', 'type:bug']\n",
      "['comp:keras', 'stat:awaiting tensorflower', 'type:feature']\n",
      "['TF 2.4', 'comp:gpu', 'comp:keras', 'type:bug']\n",
      "['cla: yes', 'comp:micro', 'ready to pull', 'size:XS']\n",
      "['TF 2.4', 'comp:keras', 'type:support']\n",
      "['TF 2.4', 'stat:awaiting response', 'subtype:macOS', 'type:build/install']\n",
      "['stat:awaiting response', 'type:others']\n",
      "['comp:gpu', 'comp:keras', 'stat:awaiting tensorflower', 'type:feature']\n",
      "['TF 2.5', 'TFLiteConverter', 'comp:lite', 'type:feature']\n",
      "['comp:gpu', 'type:performance']\n",
      "['TF 2.4', 'comp:lite', 'type:support']\n",
      "['cla: yes', 'size:M']\n",
      "['stat:awaiting response', 'type:build/install']\n",
      "['cla: yes', 'comp:xla', 'size:S']\n",
      "['comp:keras', 'type:support']\n",
      "['comp:dist-strat', 'stat:awaiting tensorflower', 'type:support']\n",
      "['cla: yes', 'comp:keras', 'size:XS']\n",
      "['cla: yes', 'comp:core', 'size:L']\n",
      "['TF 2.4', 'comp:keras', 'type:bug']\n",
      "['TF 2.4', 'comp:ops', 'type:bug']\n",
      "['TF 2.4', 'comp:gpu', 'stat:awaiting response', 'type:performance']\n",
      "['TF 2.3', 'comp:lite', 'comp:micro', 'type:support']\n",
      "['comp:keras', 'stat:awaiting tensorflower', 'type:feature']\n",
      "['TF 2.3', 'comp:dist-strat', 'comp:keras', 'type:performance']\n",
      "['TF 2.4', 'comp:apis', 'type:bug']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels_list)):\n",
    "    print(labels_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-563e955c1485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    print(data[i][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0640f0b8e8da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mlb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_list' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels_list)):\n",
    "    lb=labels_list[i]\n",
    "    print(len(lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
